@InProceedings{10.1007/3-540-44645-1_14,
author="de Vries, Arjen P.",
editor="Peters, Carol",
title="A Poor Man's Approach to CLEF",
booktitle="Cross-Language Information Retrieval and Evaluation",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="149--155",
abstract="The primary goal of our participation in CLEF is to acquire experience with supporting cross-lingual retrieval. We submitted runs for all four target languages, but our main interest has been in the bilingual Dutch to English runs. We investigated whether we can obtain a reasonable performance without expensive (but high quality) resources; we have used only `off-the-shelf', freely available tools for stopping, stemming, compound-splitting (only for Dutch) and translation. Although our results are encouraging, we must conclude that a poor man's approach should not expect to result in rich men's retrieval results.",
isbn="978-3-540-44645-3"
}


@InProceedings{10.1007/978-3-540-78135-6_11,
author="Holz, Florian
and Biemann, Chris",
editor="Gelbukh, Alexander",
title="Unsupervised and Knowledge-Free Learning of Compound Splits and Periphrases",
booktitle="Computational Linguistics and Intelligent Text Processing",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="117--127",
abstract="We present an approach for knowledge-free and unsupervised recognition of compound nouns for languages that use one-word-compounds such as Germanic and Scandinavian languages. Our approach works by creating a candidate list of compound splits based on the word list of a large corpus. Then, we filter this list using the following criteria: (a) frequencies of compounds and parts,(b) length of parts.",
isbn="978-3-540-78135-6"
}


@InProceedings{10.1007/11816508_61,
author="Popovi{\'{c}}, Maja
and Stein, Daniel
and Ney, Hermann",
editor="Salakoski, Tapio
and Ginter, Filip
and Pyysalo, Sampo
and Pahikkala, Tapio",
title="Statistical Machine Translation of German Compound Words",
booktitle="Advances in Natural Language Processing",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="616--624",
abstract="German compound words pose special problems to statistical machine translation systems: the occurence of each of the components in the training data is not sufficient for successful translation. Even if the compound itself has been seen during training, the system may not be capable of translating it properly into two or more words. If German is the target language, the system might generate only separated components or may not be capable of choosing the correct compound. In this work, we investigate and compare different strategies for the treatment of German compound words in statistical machine translation systems. For translation from German, we compare linguistic-based and corpus-based compound splitting. For translation into German, we investigate splitting and rejoining German compounds, as well as joining English potential components. Additionaly, we investigate word alignments enhanced with knowledge about the splitting points of German compounds. The translation quality is consistently improved by all methods for both translation directions.",
isbn="978-3-540-37336-0"
}


@Article{Kettunen2007,
author="Kettunen, Kimmo
and Airio, Eija
and J{\"a}rvelin, Kalervo",
title="Restricted inflectional form generation in management of morphological keyword variation",
journal="Information Retrieval",
year="2007",
month="Oct",
day="01",
volume="10",
number="4",
pages="415--444",
abstract="Word form normalization through lemmatization or stemming is a standard procedure in information retrieval because morphological variation needs to be accounted for and several languages are morphologically non-trivial. Lemmatization is effective but often requires expensive resources. Stemming is also effective in most contexts, generally almost as good as lemmatization and typically much less expensive; besides it also has a query expansion effect. However, in both approaches the idea is to turn many inflectional word forms to a single lemma or stem both in the database index and in queries. This means extra effort in creating database indexes. In this paper we take an opposite approach: we leave the database index un-normalized and enrich the queries to cover for surface form variation of keywords. A potential penalty of the approach would be long queries and slow processing. However, we show that it only matters to cover a negligible number of possible surface forms even in morphologically complex languages to arrive at a performance that is almost as good as that delivered by stemming or lemmatization. Moreover, we show that, at least for typical test collections, it only matters to cover nouns and adjectives in queries. Furthermore, we show that our findings are particularly good for short queries that resemble normal searches of web users. Our approach is called FCG (for Frequent Case (form) Generation). It can be relatively easily implemented for Latin/Greek/Cyrillic alphabet languages by examining their (typically very skewed) nominal form statistics in a small text sample and by creating surface form generators for the 3--9 most frequent forms. We demonstrate the potential of our FCG approach for several languages of varying morphological complexity: Swedish, German, Russian, and Finnish in well-known test collections. Applications include in particular Web IR in languages poor in morphological resources.",
issn="1573-7659",
doi="10.1007/s10791-007-9030-z",
url="https://doi.org/10.1007/s10791-007-9030-z"
}


@InProceedings{10.1007/3-540-44645-1_20,
author="Hedlund, Turid
and Keskustalo, Heikki
and Pirkola, Ari
and Sepponen, Mikko
and J{\"a}rvelin, Kalervo",
editor="Peters, Carol",
title="Bilingual Tests with Swedish, Finnish, and German Queries: Dealing with Morphology, Compound Words, and Query Structure",
booktitle="Cross-Language Information Retrieval and Evaluation",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="210--223",
abstract="We designed, implemented and evaluated an automated method for query construction for CLIR from Finnish, Swedish and German to English. This method seeks to automatically extract topical information from request sentences written in one of the source languages and to create a target language query, based on translations given by a translation dictionary. We paid particular attention to morphology, compound words and query structure. we tested this approach in the bilingual track of CLEF. All the source languages are compound languages, i.e., languages rich in compound words. A compound word refers to a multi-word expression where the component words are written together. Because source language request words may appear in various inflected forms not included in a translation dictionary, morphological normalization was used to aid dictionary translation. The query resulting from this process may be structured according to the translation alternatives of each source language word or remain as an unstructured word list.",
isbn="978-3-540-44645-3"
}


@Article{Airio2006,
author="Airio, Eija",
title="Word normalization and decompounding in mono- and bilingual IR",
journal="Information Retrieval",
year="2006",
month="Jun",
day="01",
volume="9",
number="3",
pages="249--271",
abstract="The present research studies the impact of decompounding and two different word normalization methods, stemming and lemmatization, on monolingual and bilingual retrieval. The languages in the monolingual runs are English, Finnish, German and Swedish. The source language of the bilingual runs is English, and the target languages are Finnish, German and Swedish. In the monolingual runs, retrieval in a lemmatized compound index gives almost as good results as retrieval in a decompounded index, but in the bilingual runs differences are found: retrieval in a lemmatized decompounded index performs better than retrieval in a lemmatized compound index. The reason for the poorer performance of indexes without decompounding in bilingual retrieval is the difference between the source language and target languages: phrases are used in English, while compounds are used instead of phrases in Finnish, German and Swedish. No remarkable performance differences could be found between stemming and lemmatization.",
issn="1573-7659",
doi="10.1007/s10791-006-0884-2",
url="https://doi.org/10.1007/s10791-006-0884-2"
}


@InProceedings{10.1007/978-3-642-15760-8_28,
author="Zeman, Daniel",
editor="Sojka, Petr
and Hor{\'a}k, Ale{\v{s}}
and Kope{\v{c}}ek, Ivan
and Pala, Karel",
title="Using TectoMT as a Preprocessing Tool for Phrase-Based Statistical Machine Translation",
booktitle="Text, Speech and Dialogue",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="216--223",
abstract="We present a systematic comparison of preprocessing techniques for two language pairs: English-Czech and English-Hindi. The two target languages, although both belonging to the Indo-European language family, show significant differences in morphology, syntax and word order. We describe how TectoMT, a successful framework for analysis and generation of language, can be used as preprocessor for a phrase-based MT system.We compare the two language pairs and the optimal sets of source-language transformations applied to them. The following transformations are examples of possible preprocessing steps: lemmatization; retokenization, compound splitting; removing/adding words lacking counterparts in the other language; phrase reordering to resemble the target word order; marking syntactic functions. TectoMT, as well as all other tools and data sets we use, are freely available on the Web.",
isbn="978-3-642-15760-8"
}


@InProceedings{10.1007/978-3-642-40802-1_14,
author="Ganguly, Debasis
and Leveling, Johannes
and Jones, Gareth J. F.",
editor="Forner, Pamela
and M{\"u}ller, Henning
and Paredes, Roberto
and Rosso, Paolo
and Stein, Benno",
title="A Case Study in Decompounding for Bengali Information Retrieval",
booktitle="Information Access Evaluation. Multilinguality, Multimodality, and Visualization",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="108--119",
abstract="Decompounding has been found to improve information retrieval (IR) effectiveness for compounding languages such as Dutch, German, or Finnish. No previous studies, however, exist on the effect of decomposition of compounds in IR for Indian languages. In this case study, we investigate the effect of decompounding for Bengali, a highly agglutinative Indian language. The standard approach of decompounding for IR, i.e. indexing compound parts (constituents) in addition to compound words, has proven beneficial for European languages. Our experiments reported in this paper show that such a standard approach does not work particularly well for Bengali IR. Some unique characteristics of Bengali compounds are: i) only one compound constituent may be a valid word in contrast to the stricter requirement of both being so; and ii) the first character of the right constituent can be modified by the rules of Sandhi in contrast to simple concatenation. As a solution, we firstly propose a more relaxed decompounding where a compound word is decomposed into only one constituent if the other constituent is not a valid word, and secondly we perform selective decompounding by ensuring that constituents often co-occur with the compound word, which indicates how related the constituents and the compound are. We perform experiments on Bengali ad-hoc IR collections from FIRE 2008 to 2012. Our experiments show that both the relaxed decomposition and the co-occurrence-based constituent selection proves more effective than the standard frequency-based decomposition method, improving mean average precision (MAP) up to 2.72{\%} and recall up to 1.8{\%}, compared to not decompounding words.",
isbn="978-3-642-40802-1"
}


@InProceedings{10.1007/978-3-642-20161-5_77,
author="Herbert, Benjamin
and Szarvas, Gy{\"o}rgy
and Gurevych, Iryna",
editor="Clough, Paul
and Foley, Colum
and Gurrin, Cathal
and Jones, Gareth J. F.
and Kraaij, Wessel
and Lee, Hyowon
and Mudoch, Vanessa",
title="Combining Query Translation Techniques to Improve Cross-Language Information Retrieval",
booktitle="Advances in Information Retrieval",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="712--715",
abstract="In this paper we address the combination of query translation approaches for cross-language information retrieval (CLIR). We translate queries with Google Translate and extend them with new translations obtained by mapping noun phrases in the query to concepts in the target language using Wikipedia. For two CLIR collections, we show that the proposed model provides meaningful translations that improve the strong baseline CLIR model based on a top performing SMT system.",
isbn="978-3-642-20161-5"
}


@Article{Alkula2001,
author="Alkula, Riitta",
title="From Plain Character Strings to Meaningful Words: Producing Better Full Text Databases for Inflectional and Compounding Languages with Morphological Analysis Software",
journal="Information Retrieval",
year="2001",
month="Sep",
day="01",
volume="4",
number="3",
pages="195--208",
abstract="The paper deals with linguistic processing and retrieval techniques in fulltext databases. Special attention is focused on the characteristics of highly inflectional languages, and how morphological structure of a language should be taken into account, when designing and developing information retrieval systems. Finnish is used as an example of a language, which has a more complicated inflectional structure than the English language. In the FULLTEXT project, natural language analysis modules for Finnish were incorporated into the commercial BASIS information retrieval system, which is based on inverted files and Boolean searching. Several test databases were produced, each using one or two Finnish morphological analysis programs.",
issn="1573-7659",
doi="10.1023/A:1011942104443",
url="https://doi.org/10.1023/A:1011942104443"
}


@InProceedings{10.1007/978-3-540-78135-6_12,
author="Alfonseca, Enrique
and Bilac, Slaven
and Pharies, Stefan",
editor="Gelbukh, Alexander",
title="German Decompounding in a Difficult Corpus",
booktitle="Computational Linguistics and Intelligent Text Processing",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="128--139",
abstract="Splitting compound words has proved to be useful in areas such as Machine Translation, Speech Recognition or Information Retrieval (IR). In the case of IR systems, they usually have to cope with noisy data, as user queries are usually written quickly and submitted without review. This work attempts at improving the current approaches for German decompounding when applied to query keywords. The results show an increase of more than 10{\%} in accuracy compared to other state-of-the-art methods.",
isbn="978-3-540-78135-6"
}


@InProceedings{10.1007/3-540-36271-1_16,
author="Dalianis, Hercules",
editor="Andersson, Birger
and Bergholtz, Maria
and Johannesson, Paul",
title="Evaluating a Spelling Support in a Search Engine",
booktitle="Natural Language Processing and Information Systems",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="183--190",
abstract="The information in a database is usually accessed using SQL or some other query language, but if one uses a free text retrieval system the retrieval of text based information becomes much easier and user friendly, since one can use natural languages techniques such as automatic spell checking and stemming. The free text retrieval system needs first to index the database but then it is just to search the database. Normally a search engine does not give any answers to queries when the search words does not exist in the index, therefore we connected a spell checker module into a search engine and evaluated it. The domain used was the web site of the Swedish National Tax Board (Riksskatteverket, RSV), where the search engine was used between April and Sept 2001. One million queries were made by the public. Of these queries 10 percent were ``misspelled'' or erroneous and our spell checker corrected around 90 percent of these.",
isbn="978-3-540-36271-5"
}


@Article{Hedlund2004,
author="Hedlund, Turid
and Airio, Eija
and Keskustalo, Heikki
and Lehtokangas, Raija
and Pirkola, Ari
and J{\"a}rvelin, Kalervo",
title="Dictionary-Based Cross-Language Information Retrieval: Learning Experiences from CLEF 2000--2002",
journal="Information Retrieval",
year="2004",
month="Jan",
day="01",
volume="7",
number="1",
pages="99--119",
abstract="In this study the basic framework and performance analysis results are presented for the three year long development process of the dictionary-based UTACLIR system. The tests expand from bilingual CLIR for three language pairs Swedish, Finnish and German to English, to six language pairs, from English to French, German, Spanish, Italian, Dutch and Finnish, and from bilingual to multilingual. In addition, transitive translation tests are reported. The development process of the UTACLIR query translation system will be regarded from the point of view of a learning process. The contribution of the individual components, the effectiveness of compound handling, proper name matching and structuring of queries are analyzed. The results and the fault analysis have been valuable in the development process. Overall the results indicate that the process is robust and can be extended to other languages. The individual effects of the different components are in general positive. However, performance also depends on the topic set and the number of compounds and proper names in the topic, and to some extent on the source and target language. The dictionaries used affect the performance significantly.",
issn="1573-7659",
doi="10.1023/B:INRT.0000009442.34054.55",
url="https://doi.org/10.1023/B:INRT.0000009442.34054.55"
}


@Article{Haque2019,
author="Haque, Rejwanul
and Hasanuzzaman, Mohammed
and Way, Andy",
title="Ruslan Mitkov, Johanna Monti, Gloria Corpas Pastor, and Violeta Seretan (eds): Multiword units in machine translation and translation technology",
journal="Machine Translation",
year="2019",
month="Aug",
day="28",
issn="1573-0573",
doi="10.1007/s10590-019-09239-4",
url="https://doi.org/10.1007/s10590-019-09239-4"
}


@InProceedings{10.1007/978-3-642-40087-2_25,
author="Loponen, Aki
and Paik, Jiaul H.
and J{\"a}rvelin, Kalervo",
editor="Majumder, Prasenjit
and Mitra, Mandar
and Bhattacharyya, Pushpak
and Subramaniam, L. Venkata
and Contractor, Danish
and Rosso, Paolo",
title="UTA Stemming and Lemmatization Experiments in the FIRE Bengali Ad Hoc Task",
booktitle="Multilingual Information Access in South Asian Languages",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="258--268",
abstract="UTA participated in the monolingual Bengali ad hoc Track at FIRE 2010. As Bengali is highly inflectional, we experimented with three language normalizers: one stemmer, YASS, and two lemmatizers, GRALE and StaLe. YASS is a corpus-based unsupervised statistical stemmer capable of handling several languages through suffix removal. GRALE is a novel graph-based lemmatizer for Bengali, but extendable for other agglutinative languages. StaLe is a statistical rule-based lemmatizer that has been implemented for several languages. We analyze 9 runs, using the three systems for the title (T) and title-and-description (TD) and title-description-and-narrative (TDN). The T runs were the least effective with MAP about 0.34 (P@10 about 0.30). All the TD runs delivered a MAP close to 0.45 (P@10 about 0.37), while the TDN runs gave a MAP of 0.50 to 0.52 (P@10 about 0.41). The performances of the three normalizers are close to each other, but they have different strengths in other aspects. The performances compare well with the ones other groups obtained in the monolingual Bengali ad hoc Track at FIRE 2010.",
isbn="978-3-642-40087-2"
}


@InProceedings{10.1007/978-3-642-54903-8_23,
author="Durrani, Nadir
and Al-Onaizan, Yaser
and Ittycheriah, Abraham",
editor="Gelbukh, Alexander",
title="Improving Egyptian-to-English SMT by Mapping Egyptian into MSA",
booktitle="Computational Linguistics and Intelligent Text Processing",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="271--282",
abstract="One of the aims of DARPA BOLT project is to translate the Egyptian blog data into English. While the parallel data for MSA-English is abundantly available, sparsely exists for Egyptian-English and Egyptian-MSA. A notable drop in the translation quality is observed when translating Egyptian to English in comparison with translating from MSA to English. One of the reasons for this drop is the high OOV rate, where as another is the dialectal differences between training and test data. This work is focused on improving Egyptian-to-English translation by bridging the gap between Egyptian and MSA. First we try to reduce the OOV rate by proposing MSA candidates for the unknown Egyptian words through different methods such as spelling correction, suggesting synonyms based on context etc. Secondly we apply convolution model using English as a pivot to map Egyptian words into MSA. We then evaluate our edits by running decoder built on MSA-to-English data. Our spelling-based correction shows an improvement of  1.7 BLEU points over the baseline system, that translates unedited Egyptian into English.",
isbn="978-3-642-54903-8"
}


@Article{Sebastiani2004,
author="Sebastiani, Fabrizio",
title="Introduction: Special Issue on the 25th European Conference on Information Retrieval Research",
journal="Information Retrieval",
year="2004",
month="Sep",
day="01",
volume="7",
number="3",
pages="235--237",
issn="1573-7659",
doi="10.1023/B:INRT.0000011242.39361.cb",
url="https://doi.org/10.1023/B:INRT.0000011242.39361.cb"
}


@InProceedings{10.1007/3-540-44645-1_17,
author="Oard, Douglas W.
and Levow, Gina-Anne
and Cabezas, Clara I.",
editor="Peters, Carol",
title="CLEF Experiments at Maryland: Statistical Stemming and Backoff Translation",
booktitle="Cross-Language Information Retrieval and Evaluation",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="176--187",
abstract="The University of Maryland participated in the CLEF 2000 multilingual task, submitting three official runs that explored the impact of applying language-independent stemming techniques to dictionarybased cross-language information retrieval. The paper begins by describing a cross-language information retrieval architecture based on balanced document translation. A four-stage backoff strategy for improving the coverage of dictionary-based translation techniques is then introduced, and an implementation based on automatically trained statistical stemming is presented. Results indicate that competitive performance can be achieved using four-stage backoff translation in conjunction with freely available bilingual dictionaries, but that the the usefulness of the statistical stemming algorithms that were tried varies considerably across the three languages to which they were applied.",
isbn="978-3-540-44645-3"
}


@Inbook{Nivre2006,
title="Dependency Parsing",
bookTitle="Inductive Dependency Parsing",
year="2006",
publisher="Springer Netherlands",
address="Dordrecht",
pages="45--86",
isbn="978-1-4020-4889-0",
doi="10.1007/1-4020-4889-0_3",
url="https://doi.org/10.1007/1-4020-4889-0_3"
}


@InProceedings{10.1007/978-3-642-34456-5_17,
author="Zhang, Jiajun
and Zhai, Feifei
and Zong, Chengqing",
editor="Zhou, Ming
and Zhou, Guodong
and Zhao, Dongyan
and Liu, Qun
and Zou, Lei",
title="Handling Unknown Words in Statistical Machine Translation from a New Perspective",
booktitle="Natural Language Processing and Chinese Computing",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="176--187",
abstract="Unknown words are one of the key factors which drastically impact the translation quality. Traditionally, nearly all the related research work focus on obtaining the translation of the unknown words in different ways. In this paper, we propose a new perspective to handle unknown words in statistical machine translation. Instead of trying great effort to find the translation of unknown words, this paper focuses on determining the semantic function the unknown words serve as in the test sentence and keeping the semantic function unchanged in the translation process. In this way, unknown words will help the phrase reordering and lexical selection of their surrounding words even though they still remain untranslated. In order to determine the semantic function of each unknown word, this paper employs the distributional semantic model and the bidirectional language model. Extensive experiments on Chinese-to-English translation show that our methods can substantially improve the translation quality.",
isbn="978-3-642-34456-5"
}


@InProceedings{10.1007/3-540-49478-2_42,
author="Oard, Douglas W.",
editor="Farwell, David
and Gerber, Laurie
and Hovy, Eduard",
title="A Comparative Study of Query and Document Translation for Cross-Language Information Retrieval",
booktitle="Machine Translation and the Information Soup",
year="1998",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="472--483",
abstract="Cross-language retrieval systems use queries in one natural language to guide retrieval of documents that might be written in another. Acquisition and representation of translation knowledge plays a central role in this process. This paper explores the utility of two sources of translation knowledge for cross-language retrieval. We have implemented six query translation techniques that use bilingual term lists and one based on direct use of the translation output from an existing machine translation system; these are compared with a document translation technique that uses output from the same machine translation system. Average precision measures on a TREC collection suggest that arbitrarily selecting a single dictionary translation is typically no less effective than using every translation in the dictionary, that query translation using a machine translation system can achieve somewhat better effectiveness than simpler techniques, and that document translation may result in further improvements in retrieval effectiveness under some conditions.",
isbn="978-3-540-49478-2"
}


@InProceedings{10.1007/3-540-44645-1_27,
author="Goldsmith, John A.
and Higgins, Derrick
and Soglasnova, Svetlana",
editor="Peters, Carol",
title="Automatic Language-Specific Stemming in Information Retrieval",
booktitle="Cross-Language Information Retrieval and Evaluation",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="273--283",
abstract="We employ Automorphology, an MDL-based algorithm that determines the suffixes present in a language-sample with no prior knowledge of the language in question, and describe our experiments on the usefulness of this approach for Information Retrieval, employing this stemmer in a SMARTbased IR engine.",
isbn="978-3-540-44645-3"
}


@InProceedings{10.1007/3-540-44645-1_9,
author="Braschler, Martin",
editor="Peters, Carol",
title="CLEF 2000 --- Overview of Results",
booktitle="Cross-Language Information Retrieval and Evaluation",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="89--101",
abstract="The first CLEF campaign was a big success in attracting increased participation when compared to its predecessor, the TREC8 cross-language track. Both the number of participants and of experiments has grown considerably. This paper presents details of the various subtasks, and attempts to summarize the main results and research directions that were observed. Additionally, the CLEF collection is examined with respect to the completeness of its relevance assessments. The analysis indicates that the CLEF relevance assessments are of comparable quality to those of the well-known and trusted TREC ad-hoc collections.",
isbn="978-3-540-44645-3"
}


@InProceedings{10.1007/11519645_11,
author="Moulinier, Isabelle
and Williams, Ken",
editor="Peters, Carol
and Clough, Paul
and Gonzalo, Julio
and Jones, Gareth J. F.
and Kluck, Michael
and Magnini, Bernardo",
title="Report on Thomson Legal and Regulatory Experiments at CLEF-2004",
booktitle="Multilingual Information Access for Text, Speech and Images",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="110--122",
abstract="Thomson Legal and Regulatory participated in the CLEF-2004 monolingual and bilingual tracks. Monolingual experiments included Portuguese, Russian and Finnish. We investigated a new query structure to handle Finnish compounds. Our main focus was bilingual search from German to French. Our approach used query translation and post-translation pseudo-relevance feedback. We compared two translation models for query translation, and captured compound translations through fertility probabilities. While the fertility-based approach picks good terms, it does not help improve bilingual retrieval. Pseudo-relevance feedback, on the other hand, resulted in improved average precision.",
isbn="978-3-540-32051-7"
}


@InProceedings{10.1007/978-3-319-10888-9_23,
author="Bick, Eckhard",
editor="Przepi{\'o}rkowski, Adam
and Ogrodniczuk, Maciej",
title="Constraint Grammar-Based Swedish-Danish Machine Translation",
booktitle="Advances in Natural Language Processing",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="216--227",
abstract="This paper describes and evaluates a grammar-based machine translation system for the Swedish-Danish language pair. Source-language structural analysis, polysemy resolution, syntactic movement rules and target-language agreement are based on Constraint Grammar morphosyntactic tags and dependency trees. Lexical transfer rules exploit dependency links to access contextual information, such as syntactic argument function, semantic type and quantifiers, or to integrate verbal features, e.g. diathesis and auxiliaries. Out-of-vocabulary words are handled by derivational and compound analysis with a combined coverage of 99.3{\%}, as well as systematic morpho-phonemic transliterations for the remaining cases. The system achieved BLEU scores of 0.65-0.8 depending on references and outperformed both STMT and RBMT competitors by a large margin.",
isbn="978-3-319-10888-9"
}


@InProceedings{10.1007/11519645_23,
author="Tomlinson, Stephen",
editor="Peters, Carol
and Clough, Paul
and Gonzalo, Julio
and Jones, Gareth J. F.
and Kluck, Michael
and Magnini, Bernardo",
title="Finnish, Portuguese and Russian Retrieval with Hummingbird SearchServerTM at CLEF 2004",
booktitle="Multilingual Information Access for Text, Speech and Images",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="221--232",
abstract="Hummingbird participated in the Finnish, Portuguese, Russian and French monolingual information retrieval tasks of the Cross-Language Evaluation Forum (CLEF) 2004. SearchServer's experimental lexical stemmers significantly increased mean average precision for each of the 4 languages. For Finnish, mean average precision was significantly higher with SearchServer's experimental decompounding option enabled. Using the stemming interpretations which led to the highest score in each document instead of using the same interpretations for all documents was of significant benefit for Russian.",
isbn="978-3-540-32051-7"
}


@InProceedings{10.1007/3-540-46154-X_49,
author="Hecht, Robert
and Riedler, J{\"u}rgen
and Backfried, Gerhard",
editor="Sojka, Petr
and Kope{\v{c}}ek, Ivan
and Pala, Karel",
title="Fitting German into N-Gram Language Models",
booktitle="Text, Speech and Dialogue",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="341--346",
abstract="We report on a series of experiments addressing the fact that German is less suited than English for word-based n-gram language models. Several systems were trained at different vocabulary sizes using various sets of lexical units. They were evaluated against a newly created corpus of German and Austrian broadcast news.",
isbn="978-3-540-46154-8"
}


@InProceedings{10.1007/978-3-642-20095-3_31,
author="Blancafort, Helena
and de Loupy, Claude",
editor="Vetulani, Zygmunt",
title="Clues to Compare Languages for Morphosyntactic Analysis: A Study Run on Parallel Corpora and Morphosyntactic Lexicons",
booktitle="Human Language Technology. Challenges for Computer Science and Linguistics",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="339--350",
abstract="The aim of the present work is to find clues on how to compare the difficulties of five languages for morphosyntactic analysis and the development of lexicographic resources running a corpora and lexical comparative study on multilingual parallel corpora and morphosyntactic lexicons. First, we ran some corpus-based experiments without any other type of knowledge, following classical measures used in lexical statistics. Then we carried out further experiments on the corpora using morphosyntactic lexicons. Finally, we plotted given diagrams using different clues to offer an overview of the difficulty of a language for the development of morphosyntactic resources.",
isbn="978-3-642-20095-3"
}


@InProceedings{10.1007/3-540-44645-1_24,
author="Gollins, Tim
and Sanderson, Mark",
editor="Peters, Carol",
title="Sheffield University CLEF 2000 Submission --- Bilingual Track: German to English",
booktitle="Cross-Language Information Retrieval and Evaluation",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="245--252",
abstract="We investigated dictionary based cross language information retrieval using lexical triangulation. Lexical triangulation combines the results of different transitive translations. Transitive translation uses a pivot language to translate between two languages when no direct translation resource is available. We took German queries and translated them via Spanish, or Dutch into English. We compared the results of retrieval experiments using these queries, with other versions created by combining the transitive translations or created by direct translation. Direct dictionary translation of a query introduces considerable ambiguity that damages retrieval, an average precision 79{\%} below monolingual in this research. Transitive translation introduces more ambiguity, giving results worse than 88{\%} below direct translation. We have shown that lexical triangulation between two transitive translations can eliminate much of the additional ambiguity introduced by transitive translation.",
isbn="978-3-540-44645-3"
}


@Article{Simpson2018,
author="Simpson, Andrew
and Ngo, Binh",
title="Classifier syntax in Vietnamese",
journal="Journal of East Asian Linguistics",
year="2018",
month="Aug",
day="01",
volume="27",
number="3",
pages="211--246",
abstract="Vietnamese is a language with a three-way split in the appearance of numeral classifiers when nouns are counted: some nouns always require classifiers (obligatory-classifier nouns), others occur only optionally with classifiers (optional-classifier nouns), and a third group never combines with a classifier (non-classified nouns). This distribution provides potentially important information on the much debated question of whether classifiers functionally combine with numerals (Bale and Coon in Linguist Inq 45:695--707, 2014) or with nouns (Li in Linguist Inq 29(4):693--702, 1998; Cheng and Sybesma in Linguist Inq 30:509--542, 1999). It also appears to challenge Chierchia's (Nat Lang Semant 6(4):339--405, 1998) characterization of the basic semantic type of nouns found in different languages, which assumes a uniform pattern of classifier occurrence in numeral classifier languages. Having described the broad distribution of classifiers in Vietnamese and the questions this raises, the article probes the syntactic properties of classifiers with the three types of noun in the language, considering double classifier patterns, fragment answers, passive constructions, and the use of classifiers with certain compound nouns. Evidence from such phenomena is shown to support the hypothesis that a uniform syntactic structure is actually projected with nouns of all types in Vietnamese, but sometimes masked by the use of nouns to overtly lexicalize both the N and CL positions in nominal projections through N-to-Cl movement.",
issn="1572-8560",
doi="10.1007/s10831-018-9181-5",
url="https://doi.org/10.1007/s10831-018-9181-5"
}


@InProceedings{10.1007/11519645_10,
author="Nadeau, David
and Jarmasz, Mario
and Barri{\`e}re, Caroline
and Foster, George
and St-Jacques, Claude",
editor="Peters, Carol
and Clough, Paul
and Gonzalo, Julio
and Jones, Gareth J. F.
and Kluck, Michael
and Magnini, Bernardo",
title="Using COTS Search Engines and Custom Query Strategies at CLEF",
booktitle="Multilingual Information Access for Text, Speech and Images",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="100--109",
abstract="This paper presents a system for bilingual information retrieval using commercial off-the-shelf search engines (COTS). Several custom query construction, expansion and translation strategies are compared. We present the experiments and the corresponding results for the CLEF 2004 event.",
isbn="978-3-540-32051-7"
}


@InProceedings{10.1007/11519645_12,
author="Kamps, Jaap
and Adafre, Sisay Fissaha
and de Rijke, Maarten",
editor="Peters, Carol
and Clough, Paul
and Gonzalo, Julio
and Jones, Gareth J. F.
and Kluck, Michael
and Magnini, Bernardo",
title="Effective Translation, Tokenization and Combination for Cross-Lingual Retrieval",
booktitle="Multilingual Information Access for Text, Speech and Images",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="123--134",
abstract="Our approach to cross-lingual document retrieval starts from the assumption that effective monolingual retrieval is at the core of any cross-language retrieval system. We devote particular attention to three crucial ingredients of our approach to cross-lingual retrieval. First, effective tokenization techniques are essential to cope with morphological variations common in many European languages. Second, effective combination methods allow us to combine the best of different strategies. Finally, effective translation methods for translating queries or documents turn a monolingual retrieval system into a cross-lingual retrieval system proper. The viability of our approach is shown by a series of experiments in monolingual, bilingual, and multilingual retrieval.",
isbn="978-3-540-32051-7"
}


@InProceedings{10.1007/11816508_44,
author="Mishne, Gilad
and de Rijke, Maarten",
editor="Salakoski, Tapio
and Ginter, Filip
and Pyysalo, Sampo
and Pahikkala, Tapio",
title="Language Model Mixtures for Contextual Ad Placement in Personal Blogs",
booktitle="Advances in Natural Language Processing",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="435--446",
abstract="We introduce a method for content-based advertisement selection for personal blog pages, based on combining multiple representations of the blog. The core idea behind the method is that personal blogs represent individuals, whose interests can be modeled by the language used in the blog itself combined with the language used in related sources of information, such as comments posted to a blog post or the blogger's community. An evaluation of our ad placement method shows improvement over state-of-the-art ad placement methods which were not designed for blog pages.",
isbn="978-3-540-37336-0"
}


@InProceedings{10.1007/978-3-319-97571-9_23,
author="Zuters, J{\={a}}nis
and Strazds, Gus
and Immers, K{\={a}}rlis",
editor="Lupeikiene, Audrone
and Vasilecas, Olegas
and Dzemyda, Gintautas",
title="Semi-automatic Quasi-morphological Word Segmentation for Neural Machine Translation",
booktitle="Databases and Information Systems",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="289--301",
abstract="This paper proposes the Prefix-Root-Postfix-Encoding (PRPE) algorithm, which performs close-to-morphological segmentation of words as part of text pre-processing in machine translation. PRPE is a cross-language algorithm requiring only minor tweaking to adapt it for any particular language, a property which makes it potentially useful for morphologically rich languages with no morphological analysers available. As a key part of the proposed algorithm we introduce the `Root alignment' principle to extract potential sub-words from a corpus, as well as a special technique for constructing words from potential sub-words. We conducted experiments with two different neural machine translation systems, training them on parallel corpora for English-Latvian and Latvian-English translation. Evaluation of translation quality showed improvements in BLEU scores when the data were pre-processed using the proposed algorithm, compared to a couple of baseline word segmentation algorithms. Although we were able to demonstrate improvements in both translation directions and for both NMT systems, they were relatively minor, and our experiments show that machine translation with inflected languages remains challenging, especially with translation direction towards a highly inflected language.",
isbn="978-3-319-97571-9"
}


@InProceedings{10.1007/11878773_20,
author="Tordai, Anna
and de Rijke, Maarten",
editor="Peters, Carol
and Gey, Fredric C.
and Gonzalo, Julio
and M{\"u}ller, Henning
and Jones, Gareth J. F.
and Kluck, Michael
and Magnini, Bernardo
and de Rijke, Maarten",
title="Four Stemmers and a Funeral: Stemming in Hungarian at CLEF 2005",
booktitle="Accessing Multilingual Information Repositories",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="179--186",
abstract="We developed algorithmic stemmers for Hungarian and used them for the ad-hoc monolingual task for CLEF 2005. Our goal was to determine what degree of stemming is the most effective. Although on average the stemmers did not perform as well as the the best n-gram, we found that stemming over a broad range of suffixes especially on nouns is highly useful.",
isbn="978-3-540-45700-8"
}


@Article{Cha2017,
author="Cha, Myung-Hoon
and Kim, Dong-Oh
and Kim, Hong-Yeon
and Kim, Young-Kyun",
title="Adaptive metadata rebalance in exascale file system",
journal="The Journal of Supercomputing",
year="2017",
month="Apr",
day="01",
volume="73",
number="4",
pages="1337--1359",
abstract="This paper presents an effective method of metadata rebalance in exascale distributed file systems. Exponential data growth has led to the need for an adaptive and robust distributed file system whose typical architecture is composed of a large cluster of metadata servers and data servers. Though each metadata server can have an equally divided subset from the entire metadata set at first, there will eventually be a global imbalance in the placement of metadata among metadata servers, and this imbalance worsens over time. To ensure that disproportionate metadata placement will not have a negative effect on the intrinsic performance of a metadata server cluster, it is necessary to recover the balanced performance of the cluster periodically. However, this cannot be easily done because rebalancing seriously hampers the normal operation of a file system. This situation continues to get worse with both an ever-present heavy workload on the file system and frequent failures of server components at exascale. As one of the primary reasons for such a degraded performance, file system clients frequently fail to look up metadata from the metadata server cluster during the period of metadata rebalance; thus, metadata operations cannot proceed at their normal speed. We propose a metadata rebalance model that minimizes failures of metadata operations during the metadata rebalance period and validate the proposed model through a cost analysis. The analysis results demonstrate that our model supports the feasibility of online metadata rebalance without the normal operation obstruction and increases the chances of maintaining balance in a huge cluster of metadata servers.",
issn="1573-0484",
doi="10.1007/s11227-016-1812-x",
url="https://doi.org/10.1007/s11227-016-1812-x"
}


@InProceedings{10.1007/978-3-319-77113-7_30,
author="Kohail, Sarah
and Biemann, Chris",
editor="Gelbukh, Alexander",
title="Matching, Re-Ranking and Scoring: Learning Textual Similarity by Incorporating Dependency Graph Alignment and Coverage Features",
booktitle="Computational Linguistics and Intelligent Text Processing",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="377--390",
abstract="In this work, we introduce a supervised model for learning textual similarity, which can identify and score similarity between a set of candidate texts and a given query text. By combining dependency graph similarity and coverage features with lexical similarity measures using neural networks, we show that most relevant documents to a given text can be more accurately ranked and scored than if the lexical similarity measures were used in isolation. Additionally, we introduce an approximate dependency subgraph alignment approach allowing node gaps and mismatch, where a certain word in one dependency graph cannot be mapped to any word in the other graph. We apply our model to two different applications, namely re-ranking for improving document retrieval precision on a new dataset, and automatic short answer scoring on a standard dataset. Experimental results indicate that our approach is easily adaptable to different tasks and languages, and works well for long texts as well as short texts.",
isbn="978-3-319-77113-7"
}


@InProceedings{10.1007/11506157_40,
author="Aura, Tuomas
and Nagarajan, Aarthi
and Gurtov, Andrei",
editor="Boyd, Colin
and Gonz{\'a}lez Nieto, Juan Manuel",
title="Analysis of the HIP Base Exchange Protocol",
booktitle="Information Security and Privacy",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="481--493",
abstract="The Host Identity Protocol (HIP) is an Internet security and multi-addressing mechanism specified by the IETF. HIP introduces a new layer between the transport and network layers of the TCP/IP stack that maps host identifiers to network locations, thus separating the two conflicting roles that IP addresses have in the current Internet. This paper analyzes the security and functionality of the HIP base exchange, which is a classic key exchange protocol with some novel features for authentication and DoS protection. The base exchange is the most stable part of the HIP specification with multiple existing implementations. We point out several security issues in the current protocol and propose changes that are compatible with the goals of HIP.",
isbn="978-3-540-31684-8"
}


@Inbook{Downing1998,
author="Downing, Laura J.",
editor="Booij, Geert
and Van Marle, Jaap",
title="Prosodic misalignment and reduplication",
bookTitle="Yearbook of Morphology 1997",
year="1998",
publisher="Springer Netherlands",
address="Dordrecht",
pages="83--120",
abstract="In KiHehe and IsiXhosa, the verb stem is the base for reduplication, and the reduplicant is prefixed to the stem ((la; 2a). As in other languages (McCarthy {\&} Prince 1986, 1993a,b, 1995), the reduplicant (RED) is misaligned with vowel-initial stems: infixed after the initial vowel, in IsiXhosa (lb) and ``exfixed'' before a prefix which is syllabified with the initial vowel in KiHehe ((2b); notice the infinitive prefix ku- /kw-is also reduplicated):",
isbn="978-94-011-4998-3",
doi="10.1007/978-94-011-4998-3_4",
url="https://doi.org/10.1007/978-94-011-4998-3_4"
}


