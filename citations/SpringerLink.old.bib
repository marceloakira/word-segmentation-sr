@InProceedings{10.1007/978-3-642-17578-7_17,
author="Belli, Fevzi
and G{\"u}ler, Nevin
and Hollmann, Axel
and Suna, G{\"o}khan
and Y{\i}ld{\i}z, Esra",
editor="Kim, Tai-hoon
and Kim, Haeng-Kon
and Khan, Muhammad Khurram
and Kiumi, Akingbehin
and Fang, Wai-chi
and {\'{S}}l{\k{e}}zak, Dominik",
title="Model-Based Higher-Order Mutation Analysis",
booktitle="Advances in Software Engineering",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="164--173",
abstract="Mutation analysis is widely used as an implementation-oriented method for software testing and test adequacy assessment. It is based on creating different versions of the software by seeding faults into its source code and constructing test cases to reveal these changes. However, in case that source code of software is not available, mutation analysis is not applicable. In such cases, the approach introduced in this paper suggests the alternative use of a model of the software under test. The objectives of this approach are (i) introduction of a new technique for first-order and higher-order mutation analysis using two basic mutation operators on graph-based models, (ii) comparison of the fault detection ability of first-order and higher-order mutants, and (iii) validity assessment of the coupling effect.",
isbn="978-3-642-17578-7"
}


@InProceedings{10.1007/978-3-319-47106-8_2,
author="Wu, Fan
and Harman, Mark
and Jia, Yue
and Krinke, Jens",
editor="Sarro, Federica
and Deb, Kalyanmoy",
title="HOMI: Searching Higher Order Mutants for Software Improvement",
booktitle="Search Based Software Engineering",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="18--33",
abstract="This paper introduces HOMI, a Higher Order Mutation based approach for Genetic Improvement of software, in which the code modification granularity is finer than in previous work while scalability remains. HOMI applies the NSGAII algorithm to search for higher order mutants that improve the non-functional properties of a program while passing all its regression tests. Experimental results on four real-world C programs shows that up to 14.7 {\%} improvement on time and 19.7 {\%} on memory are found using only First Order Mutants. By combining these First Order Mutants, HOMI found further improvement in Higher Order Mutants, giving an 18.2 {\%} improvement on the time performance while keeping the memory improvement. A further manual analysis suggests that 88 {\%} of the mutation changes cannot be generated using line based `plastic surgery' Genetic Improvement approaches.",
isbn="978-3-319-47106-8"
}


@Article{Gu2000,
author="Gu, Jing
and Shuai, Dianxun",
title="The faster higher-order cellular automaton for hyper-parallel undistorted data compression",
journal="Journal of Computer Science and Technology",
year="2000",
month="Mar",
day="01",
volume="15",
number="2",
pages="126",
abstract="This paper defines second-order and third-order permutation global functions and presents the corresponding higher-order cellular automaton approach to the hyper-parallel undistorted data compression. The genetic algorithm is successfully devoted to finding out all the correct local compression rules for the higher-order cellular automaton. The correctness of the higher-order compression rules, the time complexity, and the systolic hardware implementation issue are discussed. In comparison with the first-order automaton method reported, the proposed higher-order approach has much faster compression speed with almost the same degree of cellular structure complexity for hardware implementation.",
issn="1860-4749",
doi="10.1007/BF02948796",
url="https://doi.org/10.1007/BF02948796"
}


@InProceedings{10.1007/978-3-642-02674-4_3,
author="Tisi, Massimo
and Jouault, Fr{\'e}d{\'e}ric
and Fraternali, Piero
and Ceri, Stefano
and B{\'e}zivin, Jean",
editor="Paige, Richard F.
and Hartman, Alan
and Rensink, Arend",
title="On the Use of Higher-Order Model Transformations",
booktitle="Model Driven Architecture - Foundations and Applications",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="18--33",
abstract="The level of maturity that has been reached by model transformation technologies is proved by the growing literature on transformation libraries that address an increasingly wide spectrum of applications.",
isbn="978-3-642-02674-4"
}


@InProceedings{10.1007/978-3-319-49094-6_14,
author="Mo{\v{z}}ucha, Jakub
and Rossi, Bruno",
editor="Abrahamsson, Pekka
and Jedlitschka, Andreas
and Nguyen Duc, Anh
and Felderer, Michael
and Amasaki, Sousuke
and Mikkonen, Tommi",
title="Is Mutation Testing Ready to Be Adopted Industry-Wide?",
booktitle="Product-Focused Software Process Improvement",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="217--232",
abstract="Mutation Testing has a long research history as a way to improve the quality of software tests. However, it has not yet reached wide consensus for industry-wide adoption, mainly due to missing clear benefits and computational complexity for the application to large systems. In this paper, we investigate the current state of mutation testing support for Java Virtual Machine (JVM) environments. By running an experimental evaluation, we found out that while default configurations are unbearable for larger projects, using strategies such as selective operators, second order mutation and multi-threading can increase the applicability of the approach. However, there is a trade-off in terms of quality of the achieved results of the mutation analysis process that needs to be taken into account.",
isbn="978-3-319-49094-6"
}


@InProceedings{10.1007/978-3-642-14052-5_11,
author="Blanchette, Jasmin Christian
and Nipkow, Tobias",
editor="Kaufmann, Matt
and Paulson, Lawrence C.",
title="Nitpick: A Counterexample Generator for Higher-Order Logic Based on a Relational Model Finder",
booktitle="Interactive Theorem Proving",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="131--146",
abstract="Nitpick is a counterexample generator for Isabelle/HOL that builds on Kodkod, a SAT-based first-order relational model finder. Nitpick supports unbounded quantification, (co)inductive predicates and datatypes, and (co)recursive functions. Fundamentally a finite model finder, it approximates infinite types by finite subsets. As case studies, we consider a security type system and a hotel key card system. Our experimental results on Isabelle theories and the TPTP library indicate that Nitpick generates more counterexamples than other model finders for higher-order logic, without restrictions on the form of the formulas to falsify.",
isbn="978-3-642-14052-5"
}


@InProceedings{10.1007/978-3-642-39038-8_29,
author="Maier, Ingo
and Odersky, Martin",
editor="Castagna, Giuseppe",
title="Higher-Order Reactive Programming with Incremental Lists",
booktitle="ECOOP 2013 -- Object-Oriented Programming",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="707--731",
abstract="Reactive programming with first class time-varying values as in Functional Reactive Programming (FRP) is a powerful paradigm for designing and implementing event-based applications. Existing implementations deal with simple values. Time-varying collections can only propagate whether they have changed or not but not what has changed. This is inefficient compared to fine-grained callback driven logic that propagates incremental changes. In this work, we present a framework, Scala.React, with reactive abstractions for event streams, time-varying values as well as an incremental reactive list. Our reactive lists support both first-order reactivity by means of composition similar to functional collections via |map|, |filter|, |fold| and alike, as well as higher-order reactivity with support for time-varying collection elements. The framework automatically propagates incremental changes and guarantees strong data consistency. We show in examples that our system is convenient to use and performs well.",
isbn="978-3-642-39038-8"
}


@InProceedings{10.1007/978-3-642-20282-7_29,
author="Ko{\l}odziej, Marcin
and Majkowski, Andrzej
and Rak, Remigiusz J.",
editor="Dobnikar, Andrej
and Lotri{\v{c}}, Uro{\v{s}}
and {\v{S}}ter, Branko",
title="A New Method of EEG Classification for BCI with Feature Extraction Based on Higher Order Statistics of Wavelet Components and Selection with Genetic Algorithms",
booktitle="Adaptive and Natural Computing Algorithms",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="280--289",
abstract="A new method of feature extraction and selection of EEG signal for brain-computer interface design is presented. The proposed feature selection method is based on higher order statistics (HOS) calculated for the details of discrete wavelets transform (DWT) of EEG signal. Then a genetic algorithm is used for feature selection. During the experiment classification is conducted on a single trial of EEG signals. The proposed novel method of feature extraction using HOS and DWT gives more accurate results then the algorithm based on discrete Fourier transform (DFT).",
isbn="978-3-642-20282-7"
}


@InProceedings{10.1007/11924661_9,
author="Koopman, Pieter
and Plasmeijer, Rinus",
editor="Kobayashi, Naoki",
title="Automatic Testing of Higher Order Functions",
booktitle="Programming Languages and Systems",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="148--164",
abstract="This paper tackles a problem often overlooked in functional programming community: that of testing. Fully automatic test tools like Quickcheck and G{\thinspace}∀{\thinspace}ST can test first order functions successfully. Higher order functions, HOFs, are an essential and distinguishing part of functional languages. Testing HOFs automatically is still troublesome since it requires the generation of functions as test argument for the HOF to be tested. Also the functions that are the result of the higher order function needs to be identified. If a counter example is found, the generated and resulting functions should be printed, but that is impossible in most functional programming languages. Yet, bugs in HOFs do occur and are usually more subtle due to the high abstraction level.",
isbn="978-3-540-48938-2"
}


@InProceedings{10.1007/978-3-642-37075-5_12,
author="Czajka, {\L}ukasz",
editor="Pfenning, Frank",
title="Partiality and Recursion in Higher-Order Logic",
booktitle="Foundations of Software Science and Computation Structures",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="177--192",
abstract="We present an illative system {\$}{\backslash}ensuremath{\{}{\{}{\backslash}cal I{\}}{\}}{\_}s{\$}of classical higher-order logic with subtyping and basic inductive types. The system {\$}{\backslash}ensuremath{\{}{\{}{\backslash}cal I{\}}{\}}{\_}s{\$}allows for direct definitions of partial and general recursive functions, and provides means for handling functions whose termination has not been proven. We give examples of how properties of some recursive functions may be established in our system. In a technical appendix to the paper we prove consistency of {\$}{\backslash}ensuremath{\{}{\{}{\backslash}cal I{\}}{\}}{\_}s{\$}. The proof is by model construction. We then use this construction to show conservativity of {\$}{\backslash}ensuremath{\{}{\{}{\backslash}cal I{\}}{\}}{\_}s{\$}over classical first-order logic. Conservativity over higher-order logic is conjectured, but not proven.",
isbn="978-3-642-37075-5"
}


@Article{Kropík2013,
author="Krop{\'i}k, Petr
and {\v{S}}roubov{\'a}, Lenka
and Hamar, Roman",
title="Higher-order finite element modeling and optimization of actuator with non-linear materials",
journal="Computing",
year="2013",
month="May",
day="01",
volume="95",
number="1",
pages="487--499",
abstract="An electromagnetic actuator with nonlinear structural parts is modelled and optimized. The aim of the optimization is to obtain a flat static characteristic and reach the highest possible force acting on its plunger (manufactured of permanent magnet) at the smallest possible dimensions. The solution of the problem is carried out numerically by the professional software package COMSOL Multiphysics fully controlled by a number of special in-house scripts and procedures. First, two deterministic optimization algorithms are applied to evaluate several different actuator configurations and determine the optimal actuator design from the viewpoint of the maximum force acting on its movable part. Then, a genetic algorithm is used for a multiobjective optimization providing the flattest possible static characteristic. The methodology is illustrated by a typical example whose results are discussed.",
issn="1436-5057",
doi="10.1007/s00607-013-0302-8",
url="https://doi.org/10.1007/s00607-013-0302-8"
}


@InProceedings{10.1007/978-3-319-39696-5_20,
author="Granda, Maria Fernanda
and Condori-Fern{\'a}ndez, Nelly
and Vos, Tanja E. J.
and Pastor, Oscar",
editor="Nurcan, Selmin
and Soffer, Pnina
and Bajec, Marko
and Eder, Johann",
title="Mutation Operators for UML Class Diagrams",
booktitle="Advanced Information Systems Engineering",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="325--341",
abstract="Mutation Testing is a well-established technique for assessing the quality of test cases by checking how well they detect faults injected into a software artefact (mutant). Using this technique, the most critical activity is the adequate design of mutation operators so that they reflect typical defects of the artefact under test. This paper presents the design of a set of mutation operators for Conceptual Schemas (CS) based on UML Class Diagrams (CD). In this paper, the operators are defined in accordance with an existing defects classification for UML CS and relevant elements identified from the UML-CD meta-model. The operators are subsequently used to generate first order mutants for a CS under test. Finally, in order to analyse the usefulness of the mutation operators, we measure some basic characteristics of mutation operators with three different CSs under test.",
isbn="978-3-319-39696-5"
}


@Inbook{Zhu2005,
author="Zhu, Hong
and He, Xudong",
editor="Beydeda, Sami
and Gruhn, Volker",
title="A Methodology of Component Integration Testing",
bookTitle="Testing Commercial-off-the-Shelf Components and Systems",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="239--269",
abstract="Integration testing plays a crucial role in component-based software development. It is also very difficult due to the common problem of lack of information about the design of the components and the unavailability of source code of commercial off-the-shelf (COTS) components. Addressing this problem, we investigate how to observe system's dynamic behavior in component integration testing. Based on a theory of behavioral observation developed in our previous work, this chapter proposes a formal model of component integration testing methods and a hierarchy of behavioral observation schemes suitable for component integration testing. Their properties and interrelations are studied. Incremental integration testing strategies are also investigated. The requirements for proper uses of test drivers and component stubs in incremental integration are analyzed.",
isbn="978-3-540-27071-3",
doi="10.1007/3-540-27071-X_12",
url="https://doi.org/10.1007/3-540-27071-X_12"
}


@InProceedings{10.1007/978-3-540-31848-4_14,
author="Kapoor, Kalpesh
and Bowen, Jonathan P.",
editor="Grabowski, Jens
and Nielsen, Brian",
title="Ordering Mutants to Minimise Test Effort in Mutation Testing",
booktitle="Formal Approaches to Software Testing",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="195--209",
abstract="Mutation testing is a fault-based testing approach based on the competent programmer, and coupling effect hypotheses. One of the main difficulties faced in practice is due to the large number of mutants that can be generated for a given implementation. Earlier research to solve this problem has suggested variants of mutation testing, and finding an effective set of mutation operators. This paper presents an alternative approach for reducing the cost of testing by the identification of hierarchies among first-order mutants. The theory described here is also applicable to the quantitative assessment of testing effort and can be used to guide successive testing steps in fault-based testing.",
isbn="978-3-540-31848-4"
}


@InProceedings{10.1007/978-3-319-47443-4_10,
author="Enoiu, Eduard P.
and Sundmark, Daniel
and {\v{C}}au{\v{s}}evi{\'{c}}, Adnan
and Feldt, Robert
and Pettersson, Paul",
editor="Wotawa, Franz
and Nica, Mihai
and Kushik, Natalia",
title="Mutation-Based Test Generation for PLC Embedded Software Using Model Checking",
booktitle="Testing Software and Systems",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="155--171",
abstract="Testing is an important activity in engineering of industrial embedded software. In certain application domains (e.g., railway industry) engineering software is certified according to safety standards that require extensive software testing procedures to be applied for the development of reliable systems. Mutation analysis is a technique for creating faulty versions of a software for the purpose of examining the fault detection ability of a test suite. Mutation analysis has been used for evaluating existing test suites, but also for generating test suites that detect injected faults (i.e., mutation testing). To support developers in software testing, we propose a technique for producing test cases using an automated test generation approach that operates using mutation testing for software written in IEC 61131-3 language, a programming standard for safety-critical embedded software, commonly used for Programmable Logic Controllers (PLCs). This approach uses the Uppaal model checker and is based on a combined model that contains all the mutants and the original program. We applied this approach in a tool for testing industrial PLC programs and evaluated it in terms of cost and fault detection. For realistic validation we collected industrial experimental evidence on how mutation testing compares with manual testing as well as automated decision-coverage adequate test generation. In the evaluation, we used manually seeded faults provided by four industrial engineers. The results show that even if mutation-based test generation achieves better fault detection than automated decision coverage-based test generation, these mutation-adequate test suites are not better at detecting faults than manual test suites. However, the mutation-based test suites are significantly less costly to create, in terms of testing time, than manually created test suites. Our results suggest that the fault detection scores could be improved by considering some new and improved mutation operators (e.g., Feedback Loop Insertion Operator (FIO)) for PLC programs as well as higher-order mutations.",
isbn="978-3-319-47443-4"
}


@InProceedings{10.1007/978-3-642-11319-2_20,
author="Might, Matthew",
editor="Barthe, Gilles
and Hermenegildo, Manuel",
title="Shape Analysis in the Absence of Pointers and Structure",
booktitle="Verification, Model Checking, and Abstract Interpretation",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="263--278",
abstract="Shape analyses (Chase et al. 1990, Sagiv et al. 2002) discover properties of dynamic and/or mutable structures. We ask, ``Is there an equivalent to shape analysis for purely functional programs, and if so, what `shapes' does it discover?'' By treating binding environments as dynamically allocated structures, by treating bindings as addresses, and by treating value environments as heaps, we argue that we can analyze the ``shape'' of higher-order functions. To demonstrate this, we enrich an abstract-interpretive control-flow analysis with principles from shape analysis. In particular, we promote ``anodization'' as a way to generalize both singleton abstraction and the notion of focusing, and we promote ``binding invariants'' as the analog of shape predicates. Our analysis enables two optimizations known to be beyond the reach of control-flow analysis (globalization and super-$\beta$ inlining) and one previously unknown optimization (higher-order rematerialization).",
isbn="978-3-642-11319-2"
}


@InProceedings{10.1007/978-3-319-43177-2_15,
author="Ahmad, Tanwir
and Abbors, Fredrik
and Truscan, Dragos",
editor="Altmann, J{\"o}rn
and Silaghi, Gheorghe Cosmin
and Rana, Omer F.",
title="Automatic Performance Space Exploration of Web Applications",
booktitle="Economics of Grids, Clouds, Systems, and Services",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="223--235",
abstract="Web applications have become crucial components of current service-oriented business applications. Therefore, it is very important for the company's reputation that the performance of a web application has been tested thoroughly before deployment. We present a tool-supported performance exploration approach to investigate how potential user behavioral patterns affect the performance of the system under test. This work builds on our previous work in which we generate load from workload models describing the expected behavior of the users. We mutate a given workload model (specified using Probabilistic Timed Automata) in order to generate different mutants. Each mutant is used for load generation using the MBPeT tool and the resource utilization of the system under test is monitored. At the end of an experiment, we analyze the mutants in two ways: cluster the mutants based on the resource utilization of the system under test and identify those mutants that satisfy the criteria of given objective functions.",
isbn="978-3-319-43177-2"
}


@InProceedings{10.1007/978-3-540-30217-9_19,
author="Auger, Anne
and Schoenauer, Marc
and Vanhaecke, Nicolas",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="LS-CMA-ES: A Second-Order Algorithm for Covariance Matrix Adaptation",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="182--191",
abstract="Evolution Strategies, a class of Evolutionary Algorithmsbased on Gaussian mutation and deterministic selection, are today considered the best choice as far as parameter optimization is concerned. However, there are multiple ways to tune the covariance matrix of the Gaussian mutation. After reviewing the state of the art in covariance matrix adaptation, a new approach is proposed, in which the update of the covariance matrix is based on a quadratic approximation of the target function, obtained by some Least-Square minimization. A dynamic criterion is designed to detect situations where the approximation is not accurate enough, and original Covariance Matrix Adaptation (CMA) should rather be directly used. The resulting algorithm is experimentally validated on benchmark functions, outperforming CMA-ES on a large class of problems.",
isbn="978-3-540-30217-9"
}


@InProceedings{10.1007/978-3-642-30561-0_5,
author="Derezi{\'{n}}ska, Anna
and Rudnik, Marcin",
editor="Furia, Carlo A.
and Nanz, Sebastian",
title="Quality Evaluation of Object-Oriented and Standard Mutation Operators Applied to C{\#} Programs",
booktitle="Objects, Models, Components, Patterns",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="42--57",
abstract="Mutation testing is a kind of fault injection approach that can be used to generate tests or to assess the quality of test sets. For object-oriented languages, like C{\#}, both object-oriented and standard (traditional) mutation operators should be applied. The methods that can contribute to reducing the number of applied operators and lowering the costs of mutation testing were experimentally investigated. We extended the CREAM mutation tool to support selective testing, sampling and clustering of mutants, and combining code coverage with mutation testing. We propose an approach to quality evaluation and present experimental results of mutation operators applied to C{\#} programs.",
isbn="978-3-642-30561-0"
}


@InProceedings{10.1007/978-3-642-28038-2_18,
author="Derezi{\'{n}}ska, Anna
and Szustek, Anna",
editor="Szmuc, Tomasz
and Szpyrka, Marcin
and Zendulka, Jaroslav",
title="Object-Oriented Testing Capabilities and Performance Evaluation of the C{\#} Mutation System",
booktitle="Advances in Software Engineering Techniques",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="229--242",
abstract="The main purpose of mutation testing approach is to check a test suite quality in terms of the adequacy to killing programs with inserted programming faults. We present advances in the C{\#} mutation testing system that supports object-oriented mutation operators. The system enhancements related to functional requirements (mutation operators, avoiding generation of invalid and partially of equivalent mutants) and non-functional ones (speed-up using a new parser and reflection, space reduction storing mutant updates). Mutation testing of six widely used open source programs is discussed. The quality of the tests supplied with these programs was experimentally determined. Performance measures were evaluated to assess system enhancements (2-4 faster mutants creation, 10-100 times disk space reduction, tradeoff of time overhead for storing mutants of different size in a local or remote repository).",
isbn="978-3-642-28038-2"
}


@InProceedings{10.1007/978-3-319-39570-8_15,
author="Petrenko, Alexandre
and Nguena Timo, Omer
and Ramesh, S.",
editor="Albert, Elvira
and Lanese, Ivan",
title="Multiple Mutation Testing from FSM",
booktitle="Formal Techniques for Distributed Objects, Components, and Systems",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="222--238",
abstract="Fault model based testing receives constantly growing interest of both, researchers and test practitioners. A fault model is typically a tuple of a specification, fault domain, and conformance relation. In the context of testing from finite state machines, the specification is an FSM of a certain type. Conformance relation is specific to the type of FSM and for complete deterministic machines it is equivalence relation. Fault domain is a set of implementation machines each of which models some faults, such as output, transfer or transition faults. In the traditional checking experiment theory the fault domain is the universe of all machines with a given number of states and input and output sets of the specification. Another way of defining fault domains similar to the one used in classical program mutation is to list a number of FSM mutants obtained by changing transitions of the specification. We follow in this paper the approach of defining fault domain as a set of all possible deterministic submachines of a given nondeterministic FSM, called a mutation machine, proposed in our previous work. The mutation machine contains a specification machine and extends it with a number of mutated transitions modelling potential faults. Thus, a single mutant represents multiple mutations and mutation machine represents numerous mutants. We propose a method for analyzing mutation coverage of tests which we cast as a constraint satisfaction problem. The approach is based on logical encoding and SMT-solving, it avoids enumeration of mutants while still offering a possibility to estimate the test adequacy (mutation score). The preliminary experiments performed on an industrial controller indicate that the approach scales sufficiently well.",
isbn="978-3-319-39570-8"
}


@InProceedings{10.1007/978-3-642-33636-2_5,
author="Batmanov, Kirill
and Kuttler, Celine
and Lemaire, Francois
and Lhoussaine, C{\'e}dric
and Versari, Cristian",
editor="Gilbert, David
and Heiner, Monika",
title="Symmetry-Based Model Reduction for Approximate Stochastic Analysis",
booktitle="Computational Methods in Systems Biology",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="49--68",
abstract="For models of cell-to-cell communication, with many reactions and species per cell, the computational cost of stochastic simulation soon becomes intractable. Deterministic methods, while computationally more efficient, may fail to contribute reliable approximations for those models. In this paper, we suggest a reduction for models of cell-to-cell communication, based on symmetries of the underlying reaction network. To carry out a stochastic analysis that otherwise comes at an excessive computational cost, we apply a moment closure (MC) approach. We illustrate with a community effect, that allows synchronization of a group of cells in animal development. Comparing the results of stochastic simulation with deterministic and MC approximation, we show the benefits of our approach. The reduction presented here is potentially applicable to a broad range of highly regular systems.",
isbn="978-3-642-33636-2"
}


@InProceedings{10.1007/978-3-319-51963-0_35,
author="Legay, Axel
and Perrouin, Gilles
and Devroey, Xavier
and Cordy, Maxime
and Schobbens, Pierre-Yves
and Heymans, Patrick",
editor="Steffen, Bernhard
and Baier, Christel
and van den Brand, Mark
and Eder, Johann
and Hinchey, Mike
and Margaria, Tiziana",
title="On Featured Transition Systems",
booktitle="SOFSEM 2017: Theory and Practice of Computer Science",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="453--463",
abstract="Software Product Lines (SPLs) are families of similar software products built from a common set of features. As the number of products of an SPL is potentially exponential in the number of its features, analysing SPLs is harder than for single software. In this invited paper, we synthesise six years of efforts in alleviating SPL verification and testing issues. To this end, we introduced Featured Transition Systems (FTS) as a compact behavioural model for SPLs. Based on this formalism, we designed verification algorithms and tools allowing to check temporal properties on FTS, thereby assessing the correct behaviour of all the SPL products. We also used FTS to define test coverage and generation techniques for model-driven SPLs. We also successfully employed the formalism in order to foster mutation analysis. We conclude with future directions on the development of FTS for SPL analysis.",
isbn="978-3-319-51963-0"
}


@InProceedings{10.1007/978-3-642-38916-0_11,
author="Oudinet, Johan
and Calvi, Alberto
and B{\"u}chler, Matthias",
editor="Veanes, Margus
and Vigan{\`o}, Luca",
title="Evaluation of ASLan Mutation Operators",
booktitle="Tests and Proofs",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="178--196",
abstract="The AVANTSSAR validation platform is an automated toolset for validating trust and security aspects of Service-Oriented Architectures (SOAs). Models and security properties are specified in lowlevel AVANTSSAR Specification Language (ASLan) and there are three dedicated model-checkers that can validate if such models satisfy the security properties. However, the implementation may deviate from the specification and may contain some vulnerabilities that an attacker could exploit to violate the defined security properties. We have designed a set of semantic mutation operators to inject such vulnerabilities in an ASLan specification. Here we present the implementation of those mutation operators as Extensible Stylesheet Language Transformation (XSLT) scripts. Then, we evaluate the interest of using semantic mutation operators instead of syntactic ones by comparing the number of mutants that lead to the generation of a test case (i.e., a potential attack) and the resulting test suite for a set of existing ASLan specifications.",
isbn="978-3-642-38916-0"
}


@InProceedings{10.1007/3-540-53162-9_45,
author="Bellegarde, Fran{\c{c}}oise",
editor="Kirchner, H{\'e}l{\`e}ne
and Wechler, Wolfgang",
title="A matching process modulo a theory of categorical products",
booktitle="Algebraic and Logic Programming",
year="1990",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="270--282",
abstract="We present a matching algorithm modulo axioms of categorical products. This infinitary matching returns what we call selector-solved forms in which sets of equations have been simplified as much as possible. Although the selector-solved form is weaker than the fully solved form, it is sufficient for application to program transformation.",
isbn="978-3-540-46738-0"
}


@InProceedings{10.1007/978-3-642-15057-9_12,
author="Parkinson, Matthew",
editor="Leavens, Gary T.
and O'Hearn, Peter
and Rajamani, Sriram K.",
title="The Next 700 Separation Logics ",
booktitle="Verified Software: Theories, Tools, Experiments",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="169--182",
abstract="In recent years, separation logic has brought great advances in the world of verification. However, there is a disturbing trend for each new library or concurrency primitive to require a new separation logic. I will argue that we shouldn't be inventing new separation logics, but should find the right logic to reason about interference, and have a powerful abstraction mechanism to enable the library's implementation details to be correctly abstracted. Adding new concurrency libraries should simply be a matter of verification, not of new logics or metatheory.",
isbn="978-3-642-15057-9"
}


@InProceedings{10.1007/978-3-319-09940-8_7,
author="Henard, Christopher
and Papadakis, Mike
and Le Traon, Yves",
editor="Le Goues, Claire
and Yoo, Shin",
title="Mutation-Based Generation of Software Product Line Test Configurations",
booktitle="Search-Based Software Engineering",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="92--106",
abstract="Software Product Lines (SPLs) are families of software products that can be configured and managed through a combination of features. Such products are usually represented with a Feature Model (FM). Testing the entire SPL may not be conceivable due to economical or time constraints and, more simply, because of the large number of potential products. Thus, defining methods for generating test configurations is required, and is now a very active research topic for the testing community. In this context, mutation has recently being advertised as a promising technique. Mutation evaluates the ability of the test suite to detect defective versions of the FM, called mutants. In particular, it has been shown that existing test configurations achieving the mutation criterion correlate with fault detection. Despite the potential benefit of mutation, there is no approach which aims at generating test configurations for SPL with respect to the mutation criterion. In this direction, we introduce a search-based approach which explores the SPL product space to generate product test configurations with the aim of detecting mutants.",
isbn="978-3-319-09940-8"
}


@Inbook{Jalote1997,
author="Jalote, Pankaj",
title="Testing",
bookTitle="An Integrated Approach to Software Engineering",
year="1997",
publisher="Springer New York",
address="New York, NY",
pages="403--479",
abstract="In a software development project, errors can be injected at any stage during development. For each phase, we have discussed different techniques for detecting and eliminating errors that originate in that phase. However, no technique is perfect, and it is expected that some of the errors of the earlier phases will finally manifest themselves in the code. This is particularly true because in the earlier phases most of the verification techniques are manual because no executable code exists. Ultimately, these remaining errors will be reflected in the code. Hence, the code developed during the coding activity is likely to have some requirements errors and design errors, in addition to errors introduced during the coding activity. Because code is frequently the only product that can be executed and whose actual behavior can be observed, testing is the phase where the errors remaining from all the previous phases must be detected. Hence, testing performs a very critical role for quality assurance and for ensuring the reliability of software.",
isbn="978-1-4684-9312-2",
doi="10.1007/978-1-4684-9312-2_9",
url="https://doi.org/10.1007/978-1-4684-9312-2_9"
}


@InProceedings{10.1007/978-3-540-69738-1_5,
author="Bouillaguet, Charles
and Kuncak, Viktor
and Wies, Thomas
and Zee, Karen
and Rinard, Martin",
editor="Cook, Byron
and Podelski, Andreas",
title="Using First-Order Theorem Provers in the Jahob Data Structure Verification System",
booktitle="Verification, Model Checking, and Abstract Interpretation",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="74--88",
abstract="This paper presents our integration of efficient resolution-based theorem provers into the Jahob data structure verification system. Our experimental results show that this approach enables Jahob to automatically verify the correctness of a range of complex dynamically instantiable data structures, such as hash tables and search trees, without the need for interactive theorem proving or techniques tailored to individual data structures.",
isbn="978-3-540-69738-1"
}


@InProceedings{10.1007/978-3-642-02408-5_11,
author="Sen, Sagar
and Baudry, Benoit
and Mottu, Jean-Marie",
editor="Paige, Richard F.",
title="Automatic Model Generation Strategies for Model Transformation Testing",
booktitle="Theory and Practice of Model Transformations",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="148--164",
abstract="Testing model transformations requires input models which are graphs of inter-connected objects that must conform to a meta-model and meta-constraints from heterogeneous sources such as well-formedness rules, transformation pre-conditions, and test strategies. Manually specifying such models is tedious since models must simultaneously conform to several meta-constraints. We propose automatic model generation via constraint satisfaction using our tool Cartier for model transformation testing. Due to the virtually infinite number of models in the input domain we compare strategies based on input domain partitioning to guide model generation. We qualify the effectiveness of these strategies by performing mutation analysis on the transformation using generated sets of models. The test sets obtained using partitioning strategies gives mutation scores of up to 87{\%} vs. 72{\%} in the case of unguided/random generation. These scores are based on analysis of 360 automatically generated test models for the representative transformation of UML class diagram models to RDBMS models.",
isbn="978-3-642-02408-5"
}


@InProceedings{10.1007/978-3-642-54108-7_3,
author="Kneuss, Etienne
and Kuncak, Viktor
and Suter, Philippe",
editor="Cohen, Ernie
and Rybalchenko, Andrey",
title="Effect Analysis for Programs with Callbacks",
booktitle="Verified Software: Theories, Tools, Experiments",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="48--67",
abstract="We introduce a precise interprocedural effect analysis for programs with mutable state, dynamic object allocation, and dynamic dispatch. Our analysis is precise even in the presence of dynamic dispatch where the context-insensitive estimate on the number of targets is very large. This feature makes our analysis appropriate for programs that manipulate first-class functions (callbacks). We present a framework in which programs are enriched with special effect statements, and define the semantics of both program and effect statements as relations on states. Our framework defines a program composition operator that is sound with respect to relation composition. Computing the summary of a procedure then consists of composing all its program statements to produce a single effect statement. We propose a strategy for applying the composition operator in a way that balances precision and efficiency.",
isbn="978-3-642-54108-7"
}


@InProceedings{10.1007/978-3-642-14107-2_9,
author="Svendsen, Kasper
and Birkedal, Lars
and Parkinson, Matthew",
editor="D'Hondt, Theo",
title="Verifying Generics and Delegates",
booktitle="ECOOP 2010 -- Object-Oriented Programming",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="175--199",
abstract="Recently, object-oriented languages, such as C{\$}^{\backslash}sharp{\$}, have been extended with language features prevalent in most functional languages: parametric polymorphism and higher-order functions. In the OO world these are called generics and delegates, respectively. These features allow for greater code reuse and reduce the possibilities for runtime errors. However, the combination of these features pushes the language beyond current object-oriented verification techniques.",
isbn="978-3-642-14107-2"
}


@InProceedings{10.1007/978-3-642-30476-7_2,
author="Sen, Sagar
and Mottu, Jean-Marie
and Tisi, Massimo
and Cabot, Jordi",
editor="Hu, Zhenjiang
and de Lara, Juan",
title="Using Models of Partial Knowledge to Test Model Transformations",
booktitle="Theory and Practice of Model Transformations",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="24--39",
abstract="Testers often use partial knowledge to build test models. This knowledge comes from sources such as requirements, known faults, existing inputs, and execution traces. In Model-Driven Engineering, test inputs are models executed by model transformations. Modelers build them using partial knowledge while meticulously satisfying several well-formedness rules imposed by the modelling language. This manual process is tedious and language constraints can force users to create complex models even for representing simple knowledge. In this paper, we want to simplify the development of test models by presenting an integrated methodology and semi-automated tool that allow users to build only small partial test models directly representing their testing intent. We argue that partial models are more readable and maintainable and can be automatically completed to full input models while considering language constraints. We validate this approach by evaluating the size and fault-detecting effectiveness of partial models compared to traditionally-built test models. We show that they can detect the same bugs/faults with a greatly reduced development effort.",
isbn="978-3-642-30476-7"
}


@InProceedings{10.1007/978-3-642-37057-1_6,
author="Hofer, Birgit
and Riboira, Andr{\'e}
and Wotawa, Franz
and Abreu, Rui
and Getzner, Elisabeth",
editor="Cortellessa, Vittorio
and Varr{\'o}, D{\'a}niel",
title="On the Empirical Evaluation of Fault Localization Techniques for Spreadsheets",
booktitle="Fundamental Approaches to Software Engineering",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="68--82",
abstract="Spreadsheets are by far the most prominent example of end-user programs of ample size and substantial structural complexity. In addition, spreadsheets are usually not tested very rigorously and thus comprise faults. Locating faults is a hard task due to the size and the structure, which is usually not directly visible to the user, i.e., the functions are hidden behind the cells and only the computed values are presented. Hence, there is a strong need for debugging support. In this paper, we adapt three program-debugging approaches that have been designed for more traditional procedural or object-oriented programming languages. These techniques are Spectrum-based Fault Localization, Spectrum-Enhanced Dynamic Slicing, and Constraint-based Debugging. Beside the theoretical foundations, we present a more sophisticated empirical evaluation including a comparison of these approaches. The empirical evaluation shows that Sfl (Spectrum-based Fault Localization) and Sendys (Spectrum ENhanced Dynamic Slicing) are the most promising techniques.",
isbn="978-3-642-37057-1"
}


@InProceedings{10.1007/978-3-319-45177-0_2,
author="Backenk{\"o}hler, Michael
and Bortolussi, Luca
and Wolf, Verena",
editor="Bartocci, Ezio
and Lio, Pietro
and Paoletti, Nicola",
title="Generalized Method of Moments for Stochastic Reaction Networks in Equilibrium",
booktitle="Computational Methods in Systems Biology",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="15--29",
abstract="Calibrating parameters is a crucial problem within quantitative modeling approaches to reaction networks. Existing methods for stochastic models rely either on statistical sampling or can only be applied to small systems. Here we present an inference procedure for stochastic models in equilibrium that is based on a moment matching scheme with optimal weighting and that can be used with high-throughput data like the one collected by flow cytometry. Our method does not require an approximation of the underlying equilibrium probability distribution and, if reaction rate constants have to be learned, the optimal values can be computed by solving a linear system of equations. We evaluate the effectiveness of the proposed approach on three case studies.",
isbn="978-3-319-45177-0"
}


@Article{Wang2013,
author="Wang, Nan
and Ai, Hai-Zhou
and Tang, Feng",
title="Who Blocks Who: Simultaneous Segmentation of Occluded Objects",
journal="Journal of Computer Science and Technology",
year="2013",
month="Sep",
day="01",
volume="28",
number="5",
pages="890--906",
abstract="In this paper, we present a simultaneous segmentation algorithm for multiple highly-occluded objects, which combines high-level knowledge and low-level information in a unified framework. The high-level knowledge provides sophisticated shape priors with the consideration of blocking relationship between nearby objects. Different from conventional layered model which attempts to solve the full ordering problem, we decompose the problem into a series of pairwise ones and this makes our algorithm scalable to a large number of objects. Objects are segmented in pixel level with higher-order soft constraints from superpixels, by a dual-level conditional random field. The model is optimized alternately by object layout and pixel-wise segmentation. We evaluate our system on different objects, i.e., clothing and pedestrian, and show impressive segmentation results and significant improvement over state-of-the-art segmentation algorithms.",
issn="1860-4749",
doi="10.1007/s11390-013-1385-6",
url="https://doi.org/10.1007/s11390-013-1385-6"
}


@InProceedings{10.1007/3-540-57887-0_93,
author="Hoa, Alain Hui Bon",
editor="Hagiya, Masami
and Mitchell, John C.",
title="Intuitionistic resolution for a logic programming language with scoping constructs",
booktitle="Theoretical Aspects of Computer Software",
year="1994",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="121--140",
abstract="A direct support for scopes appears to be essential for logic programming languages, in those applications, like meta-programming, needing to distinguish between various levels of reasoning. However, dealing with scoping constructs in a logic programming language notably causes the set of constants to evolve dynamically during the computation, which creates difficulties in defining alternative evaluation strategies to the Top-Down one. We present in this paper a logic programming language of the $\lambda$-Prolog family, focusing on this quantificational scoping feature, for which we define a general intuitionistic resolution. This method extends the resolution defined by Robinson for Horn Clauses, and provides a general framework for evaluation strategies, encompassing Top-Down and Bottom-Up resolutions, as well as a basis to enhanced techniques combining goal-directed search and subcomputation sharing.",
isbn="978-3-540-48383-0"
}


@InProceedings{10.1007/978-3-540-70592-5_17,
author="Banerjee, Anindya
and Naumann, David A.
and Rosenberg, Stan",
editor="Vitek, Jan",
title="Regional Logic for Local Reasoning about Global Invariants",
booktitle="ECOOP 2008 -- Object-Oriented Programming",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="387--411",
abstract="Shared mutable objects pose grave challenges in reasoning, especially for data abstraction and modularity. This paper presents a novel logic for error-avoiding partial correctness of programs featuring shared mutable objects. Using a first order assertion language, the logic provides heap-local reasoning about mutation and separation, via ghost fields and variables of type `region' (finite sets of object references). A new form of modifies clause specifies write, read, and allocation effects using region expressions; this supports effect masking and a frame rule that allows a command to read state on which the framed predicate depends. Soundness is proved using a standard program semantics. The logic facilitates heap-local reasoning about object invariants: disciplines such as ownership are expressible but not hard-wired in the logic.",
isbn="978-3-540-70592-5"
}


@InProceedings{10.1007/978-3-642-41533-3_6,
author="Pretschner, Alexander
and Holling, Dominik
and Eschbach, Robert
and Gemmar, Matthias",
editor="Moreira, Ana
and Sch{\"a}tz, Bernhard
and Gray, Jeff
and Vallecillo, Antonio
and Clarke, Peter",
title="A Generic Fault Model for Quality Assurance",
booktitle="Model-Driven Engineering Languages and Systems",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="87--103",
abstract="Because they are comparatively easy to implement, structural coverage criteria are commonly used for test derivation in model- and code-based testing. However, there is a lack of compelling evidence that they are useful for finding faults, specifically so when compared to random testing. This paper challenges the idea of using coverage criteria for test selection and instead proposes an approach based on fault models. We define a general fault model as a transformation from correct to incorrect programs and/or a partition of the input data space. Thereby, we leverage the idea of fault injection for test assessment to test derivation.",
isbn="978-3-642-41533-3"
}


@InProceedings{10.1007/978-3-319-40229-1_10,
author="Reynolds, Andrew
and Blanchette, Jasmin Christian
and Cruanes, Simon
and Tinelli, Cesare",
editor="Olivetti, Nicola
and Tiwari, Ashish",
title="Model Finding for Recursive Functions in SMT",
booktitle="Automated Reasoning",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="133--151",
abstract="SMT solvers have recently been extended with techniques for finding models of universally quantified formulas in some restricted fragments of first-order logic. This paper introduces a translation that reduces axioms specifying a large class of recursive functions, including terminating functions, to universally quantified formulas for which these techniques are applicable. An evaluation confirms that the approach improves the performance of existing solvers on benchmarks from three sources. The translation is implemented as a preprocessor in the CVC4 solver and in a new higher-order model finder called Nunchaku.",
isbn="978-3-319-40229-1"
}


@Inbook{Jalote2005,
title="Testing",
bookTitle="An Integrated Approach to Software Engineering",
year="2005",
publisher="Springer US",
address="Boston, MA",
pages="465--541",
isbn="978-0-387-28132-2",
doi="10.1007/0-387-28132-0_10",
url="https://doi.org/10.1007/0-387-28132-0_10"
}


@InProceedings{10.1007/978-3-662-49498-1_11,
author="Feltman, Nicolas
and Angiuli, Carlo
and Acar, Umut A.
and Fatahalian, Kayvon",
editor="Thiemann, Peter",
title="Automatically Splitting a Two-Stage Lambda Calculus",
booktitle="Programming Languages and Systems",
year="2016",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="255--281",
abstract="Staged programming languages assign a stage to each program expression and evaluate each expression in its assigned stage. A common use of staged languages is to describe programs where inputs arrive at different times or rates. In this paper we present an algorithm for statically splitting these mixed-staged programs into two unstaged, but dependent, programs where the outputs of the first program can be efficiently reused across multiple invocations of the second. While previous algorithms for performing this transformation (also called pass separation and data specialization) were limited to operate on simpler, imperative languages, we define a splitting algorithm for an explicitly-two-stage, typed lambda calculus with a {\$}{\$}{\backslash}bigcirc {\$}{\$}modality denoting computation at a later stage, and a {\$}{\$}{\backslash}nabla {\$}{\$}modality noting purely first-stage code. Most notably, the algorithm splits mixed-stage recursive and higher-order functions. We prove the dynamic correctness of our splitting algorithm with respect to a partial-evaluation semantics, and mechanize this proof in Twelf. We also implement the algorithm in a prototype compiler, and demonstrate that the ability to split programs in a language featuring recursion and higher-order features enables non-trivial algorithmic transformations that improve code efficiency and also facilitates modular expression of staged programs.",
isbn="978-3-662-49498-1"
}


@Inbook{Qin2008,
title="Flexible Software Architecture",
bookTitle="Software Architecture",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="274--312",
abstract="So far, we assume that every software system contains architecture information, representing the high level structures, behaviors and other issues related to them. When a system has been built, it is a common belief that its architecture will keep stable or only very small parts of it will get modified. However, current software does not stay so tame. Under various factors, they have to response with the changes in the architecture level, and in the perspective of marketing, which should not beget too much overhead.",
isbn="978-3-540-74343-9",
doi="10.1007/978-3-540-74343-9_8",
url="https://doi.org/10.1007/978-3-540-74343-9_8"
}


@Inbook{Zaus1999,
author="Zaus, Michael",
title="Causal Modeling with Fuzzy Cognitive Maps",
bookTitle="Crisp and Soft Computing with Hypercubical Calculus: New Approaches to Modeling in Cognitive Science and Technology with Parity Logic, Fuzzy Logic, and Evolutionary Computing",
year="1999",
publisher="Physica-Verlag HD",
address="Heidelberg",
pages="201--276",
abstract="In contemporary social and behavioral science, fuzzy logic is still rather unpopular, perhaps because of its major affiliation with electrical engineering, industrial systems control, and computer science. However, in view of the fact that fuzzy logic aims equally well at a formalization of the cognitive processes humans employ in their daily activities in private and working environments, we conclude that sociologists, political scientists, and psychologists are grossly mistaking the real impact of fuzzy logic upon cognition and action, because it provides a new framework for knowledge engineering.",
isbn="978-3-7908-1879-6",
doi="10.1007/978-3-7908-1879-6_8",
url="https://doi.org/10.1007/978-3-7908-1879-6_8"
}


@Article{Chockler2006,
author="Chockler, Hana
and Kupferman, Orna
and Vardi, Moshe",
title="Coverage metrics for formal verification",
journal="International Journal on Software Tools for Technology Transfer",
year="2006",
month="Aug",
day="01",
volume="8",
number="4",
pages="373--386",
abstract="In formal verification, we verify that a system is correct with respect to a specification. Even when the system is proven to be correct, there is still a question of how complete the specification is and whether it really covers all the behaviors of the system. The challenge of making the verification process as exhaustive as possible is even more crucial in simulation-based verification, where the infeasible task of checking all input sequences is replaced by checking a test suite consisting of a finite subset of them. It is very important to measure the exhaustiveness of the test suite, and indeed there has been extensive research in the simulation-based verification community on coverage metrics, which provide such a measure. It turns out that no single measure can be absolute, leading to the development of numerous coverage metrics whose usage is determined by industrial verification methodologies. On the other hand, prior research of coverage in formal verification has focused solely on state-based coverage. In this paper we adapt the work done on coverage in simulation-based verification to the formal-verification setting in order to obtain new coverage metrics. Thus, for each of the metrics used in simulation-based verification, we present a corresponding metric that is suitable for the setting of formal verification and describe an algorithmic way to check it.",
issn="1433-2787",
doi="10.1007/s10009-004-0175-4",
url="https://doi.org/10.1007/s10009-004-0175-4"
}


@Article{Mach2013,
author="Mach, Franti{\v{s}}ek
and K{\r{u}}s, Pavel
and Karban, Pavel
and Dole{\v{z}}el, Ivo",
title="Optimization of the system for induction heating of nonmagnetic cylindrical billets in rotating magnetic field produced by permanent magnets",
journal="Computing",
year="2013",
month="May",
day="01",
volume="95",
number="1",
pages="537--552",
abstract="The process of induction heating of cylindrical nonmagnetic billets is modeled and optimized. An unmovable billet is placed in rotating magnetic field generated by permanent magnets fixed in an external rotor driven by an asynchronous motor by means of a teeth gear. The coupled model of the problem consisting of two partial differential equations describing the distributions of magnetic and temperature fields in the system is solved by a fully adaptive higher-order finite element method. Computations are realized by own code Agros2D. The device is then optimized with respect to the total amount of heat generated in the billet; as the dimensions of the device are fixed, the only quantity that can be changed is the direction of magnetization of the individual permanent magnets. The optimization procedures represent a supplement to the code. Finally, the dynamic behavior of the optimized system is analyzed. The methodology is illustrated by a typical example whose results are discussed.",
issn="1436-5057",
doi="10.1007/s00607-013-0297-1",
url="https://doi.org/10.1007/s00607-013-0297-1"
}


@InProceedings{10.1007/978-3-642-40561-7_14,
author="Saleh, Iman
and Kulczycki, Gregory
and Blake, M. Brian
and Wei, Yi",
editor="Hierons, Robert M.
and Merayo, Mercedes G.
and Bravetti, Mario",
title="Static Detection of Implementation Errors Using Formal Code Specification",
booktitle="Software Engineering and Formal Methods",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="197--211",
abstract="The software engineering community suggests that formal specification of source code facilitates the verification that can help to identify hidden functional errors. In this work, we investigate the impact of various levels of formal specification on the ability to statically detect errors in code. Our goal is to quantify the return on investment with regards to the effectiveness of identifying errors versus the overhead of specifying software at various levels of detail. We looked at common algorithms and data structures implemented using C{\#} and specified using Spec{\#}. We selectively omitted various parts of the specification to come up with five different levels of specification, from unspecified to highly-specified. For each level of specification, we injected errors into the classes using a fault injection tool. Experimentation using a verifier showed that over 80{\%} of the errors were detected from the highest specification levels while the levels in between generated mixed results. To the best of our knowledge, our study is the first to quantitatively measure the effect of formal methods on code quality. We believe that our work can help convince skeptics that formal methods can be practically integrated into programming activities to produce code with higher quality even with partial specification.",
isbn="978-3-642-40561-7"
}


@InProceedings{10.1007/978-3-642-16478-1_9,
author="Strickland, T. Stephen
and Felleisen, Matthias",
editor="Moraz{\'a}n, Marco T.
and Scholz, Sven-Bodo",
title="Nested and Dynamic Contract Boundaries",
booktitle="Implementation and Application of Functional Languages",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="141--158",
abstract="Previous work on software contracts assumes fixed and statically known boundaries between the parties to a contract. Implementations of contract monitoring systems rely on this assumption to explain the nature of contract violations and to assign blame to violators. In this paper, we explain how to implement arbitrary, nested, and dynamic contract boundaries with two examples. First, we add nestable contract regions to a static, first-order module system. Second, we show that even a dynamic, higher-order, and hierarchical module system can be equipped with software contracts that support precise blame assignment.",
isbn="978-3-642-16478-1"
}


@Article{Kaptsov2010,
author="Kaptsov, O. V.",
title="Ideals of differential operators and transformations of linear partial differential equations",
journal="Programming and Computer Software",
year="2010",
month="Mar",
day="01",
volume="36",
number="2",
pages="97--102",
abstract="A ring of linear differential operators with smooth coefficients generated by two differentiations is considered. Concepts of operators closed with respect to commutation, a resultant of two operators, and a two-dimensional analogue of Wronskian are introduced. Sufficient conditions that two differential operators are generators of a left ideal annihilating a finite-dimensional space of functions are found. Differential operators annihilating given functions are constructed. The operators obtained transform solutions of one secondorder differential equation into solutions of another equation of the same order.",
issn="1608-3261",
doi="10.1134/S0361768810020076",
url="https://doi.org/10.1134/S0361768810020076"
}


@InProceedings{10.1007/978-3-642-35308-6_10,
author="Bulwahn, Lukas",
editor="Hawblitzel, Chris
and Miller, Dale",
title="The New Quickcheck for Isabelle",
booktitle="Certified Programs and Proofs",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="92--108",
abstract="The new Quickcheck is a counterexample generator for Isabelle/HOL that uncovers faulty specifications and invalid conjectures using various testing strategies. The previous Quickcheck only tested conjectures by random testing. The new Quickcheck extends the previous one and integrates two novel testing strategies: exhaustive testing with concrete values; and symbolic testing, evaluating conjectures with a narrowing strategy. Orthogonally to the strategies, we address two general issues: First, we extend the class of executable conjectures and specifications, and second, we present techniques to deal with conditional conjectures, i.e., conjectures with premises. We evaluate the testing strategies and techniques on a number of specifications, functional data structures and a hotel key card system.",
isbn="978-3-642-35308-6"
}


@InProceedings{10.1007/978-3-540-39724-3_11,
author="Chockler, Hana
and Kupferman, Orna
and Vardi, Moshe Y.",
editor="Geist, Daniel
and Tronci, Enrico",
title="Coverage Metrics for Formal Verification",
booktitle="Correct Hardware Design and Verification Methods",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="111--125",
abstract="In formal verification, we verify that a system is correct with respect to a specification. Even when the system is proven to be correct, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. The challenge of making the verification process as exhaustive as possible is even more crucial in simulation-based verification, where the infeasible task of checking all input sequences is replaced by checking a test suite consisting of a finite subset of them. It is very important to measure the exhaustiveness of the test suite, and indeed, there has been an extensive research in the simulation-based verification community on coverage metrics, which provide such a measure. It turns out that no single measure can be absolute, leading to the development of numerous coverage metrics whose usage is determined by industrial verification methodologies. On the other hand, prior research of coverage in formal verification has focused solely on state-based coverage. In this paper we adapt the work done on coverage in simulation-based verification to the formal-verification setting in order to obtain new coverage metrics. Thus, for each of the metrics used in simulation-based verification, we present a corresponding metric that is suitable for the setting of formal verification, and describe an algorithmic way to check it.",
isbn="978-3-540-39724-3"
}


@InProceedings{10.1007/978-3-642-28869-2_11,
author="Dimoulas, Christos
and Tobin-Hochstadt, Sam
and Felleisen, Matthias",
editor="Seidl, Helmut",
title="Complete Monitors for Behavioral Contracts",
booktitle="Programming Languages and Systems",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="214--233",
abstract="A behavioral contract in a higher-order language may invoke methods of unknown objects. Although this expressive power allows programmers to formulate sophisticated contracts, it also poses a problem for language designers. Indeed, two distinct semantics have emerged for such method calls, dubbed lax and picky. While lax fails to protect components in certain scenarios, picky may blame an uninvolved party for a contract violation.",
isbn="978-3-642-28869-2"
}


@InProceedings{10.1007/3-540-44755-5_16,
author="Gay, Simon J.",
editor="Boulton, Richard J.
and Jackson, Paul B.",
title="A Framework for the Formalisation of Pi Calculus Type Systems in Isabelle/HOL",
booktitle="Theorem Proving in Higher Order Logics",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="217--232",
abstract="We present a formalisation, in the theorem proving system Isabelle/HOL, of a linear type system for the pi calculus, including a proof of runtime safety of typed processes. The use of a uniform encoding of pi calculus syntax in a meta language, the development of a general theory of type environments, and the structured formalisation of the main proofs, facilitate the adaptation of the Isabelle theories and proof scripts to variations on the language and other type systems.",
isbn="978-3-540-44755-9"
}


@InProceedings{10.1007/978-3-319-08789-4_1,
author="Wieber, Martin
and Anjorin, Anthony
and Sch{\"u}rr, Andy",
editor="Di Ruscio, Davide
and Varr{\'o}, D{\'a}niel",
title="On the Usage of TGGs for Automated Model Transformation Testing",
booktitle="Theory and Practice of Model Transformations",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="1--16",
abstract="As model transformations are fundamental to model-driven engineering, assuring their quality is a central task which can be achieved by testing with sufficiently adequate and large test suites. As the latter requirement can render manual testing prohibitively costly in practice, a high level of automation is advisable. Triple Graph Grammars (TGGs) have been shown to provide a promising solution to this challenge as not only test case generators, but also generic test oracles can be derived from them. It is, however, unclear if such generated test suites are indeed adequate and, as different strategies can be used to steer the test generation process, a systematic means of comparing and evaluating such test suites and strategies is required.",
isbn="978-3-319-08789-4"
}


@Inbook{Aichernig2003,
author="Aichernig, Bernhard K.",
editor="Aichernig, Bernhard K.
and Maibaum, Tom",
title="Contract-Based Testing",
bookTitle="Formal Methods at the Crossroads. From Panacea to Foundational Support: 10th Anniversary Colloquium of UNU/IIST, the International Institute for Software Technology of The United Nations University, Lisbon, Portugal, March 18-20, 2002. Revised Papers",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="34--48",
abstract="A tester relies on some sort of contract between the users and the implementers of a system. The contract defines the obligations of each part that are partially checked by selecting and executing test-cases. In fact, these test-cases are contracts, too, although in a rather operational form. In this article we define the general relationship between these two forms of contract and present a method how various test-selection strategies can be defined formally. More precisely, we demonstrate how test-cases can be calculated from contracts using a refinement calculus.",
isbn="978-3-540-40007-3",
doi="10.1007/978-3-540-40007-3_3",
url="https://doi.org/10.1007/978-3-540-40007-3_3"
}


@InProceedings{10.1007/978-3-319-21155-8_9,
author="Jouault, Fr{\'e}d{\'e}ric
and Beaudoux, Olivier
and Brun, Matthias
and Clavreul, Mickael
and Savaton, Guillaume",
editor="Kolovos, Dimitris
and Wimmer, Manuel",
title="Towards Functional Model Transformations with OCL",
booktitle="Theory and Practice of Model Transformations",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="111--120",
abstract="Several model transformation approaches such as QVT and ATL use OCL as expression language for its model-querying capabilities. However, they need to add specific and incompatible syntactic constructs for pattern matching as well as model element creation and mutation.",
isbn="978-3-319-21155-8"
}


@InProceedings{10.1007/978-3-540-70592-5_4,
author="Gray, Kathryn E.",
editor="Vitek, Jan",
title="Safe Cross-Language Inheritance",
booktitle="ECOOP 2008 -- Object-Oriented Programming",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="52--75",
abstract="Inheritance is a standard means for reuse and for interfacing with external libraries. In a multi-language software product, extending a class written in a statically-typed language with a dynamically-typed class can require a significant number of manual indirections and other error-prone complications. Building on our previous interoperability work, we introduce a technique that allows safe, easy inheritance across languages. We demonstrate our technique for cross-language inheritance with a statically-typed object calculus and a dynamically-typed object calculus, where a statically-typed class can extend a dynamically-typed one and vice versa. We provide a proof sketch of soundness, as well as a guarantee that dynamic type errors do not arise due to statically-typed expressions.",
isbn="978-3-540-70592-5"
}


@InProceedings{10.1007/978-3-540-89439-1_33,
author="Chaudhuri, Kaustuv",
editor="Cervesato, Iliano
and Veith, Helmut
and Voronkov, Andrei",
title="Focusing Strategies in the Sequent Calculus of Synthetic Connectives",
booktitle="Logic for Programming, Artificial Intelligence, and Reasoning",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="467--481",
abstract="It is well-known that focusing striates a sequent derivation into phases of like polarity where each phase can be seen as inferring a synthetic connective. We present a sequent calculus of synthetic connectives based on neutral proof patterns, which are a syntactic normal form for such connectives. Different focusing strategies arise from different polarisations and arrangements of synthetic inference rules, which are shown to be complete by synthetic rule permutations. A simple generic cut-elimination procedure for synthetic connectives respects both the ordinary focusing and the maximally multi-focusing strategies, answering the open question of cut-admissibility for maximally multi-focused proofs.",
isbn="978-3-540-89439-1"
}


@InProceedings{10.1007/978-3-662-46675-9_5,
author="Jehan, Seema
and Pill, Ingo
and Wotawa, Franz",
editor="Egyed, Alexander
and Schaefer, Ina",
title="BPEL Integration Testing",
booktitle="Fundamental Approaches to Software Engineering",
year="2015",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="69--83",
abstract="Service-oriented architectures, and evolvements such as clouds, provide a promising infrastructure for future computing. They encapsulate an IP core's functionality for easy access via well-defined business and web interfaces, and in turn allow us to flexibly realize complex software drawing on available expertise. In this paper, we take a look at some challenges we have to face during the task of testing such systems for verification purposes. In particular, we delve into the task of test suite generation, and compare the performance of two corresponding algorithms. In addition, we report on experiments for a collection of BPEL processes taken from the literature, in order to identify performance trends with respect to fault coverage metrics. Our results suggest that a structural reasoning might outperform a completely random approach.",
isbn="978-3-662-46675-9"
}


@InProceedings{10.1007/978-3-642-27705-4_15,
author="Mehnert, Hannes
and Sieczkowski, Filip
and Birkedal, Lars
and Sestoft, Peter",
editor="Joshi, Rajeev
and M{\"u}ller, Peter
and Podelski, Andreas",
title="Formalized Verification of Snapshotable Trees: Separation and Sharing",
booktitle="Verified Software: Theories, Tools, Experiments",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="179--195",
abstract="We use separation logic to specify and verify a Java program that implements snapshotable search trees, fully formalizing the specification and verification in the Coq proof assistant. We achieve local and modular reasoning about a tree and its snapshots and their iterators, although the implementation involves shared mutable heap data structures with no separation or ownership relation between the various data.",
isbn="978-3-642-27705-4"
}


@InProceedings{10.1007/978-3-662-54434-1_9,
author="Caires, Lu{\'i}s
and P{\'e}rez, Jorge A.",
editor="Yang, Hongseok",
title="Linearity, Control Effects, and Behavioral Types",
booktitle="Programming Languages and Systems",
year="2017",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="229--259",
abstract="Mainstream programming idioms intensively rely on state mutation, sharing, and concurrency. Designing type systems for handling and disciplining such idioms is challenging, due to long known conflicts between internal non-determinism, linearity, and control effects such as exceptions. In this paper, we present the first type system that accommodates non-deterministic and abortable behaviors in the setting of session-based concurrent programs. Remarkably, our type system builds on a Curry-Howard correspondence with (classical) linear logic conservatively extended with two dual modalities capturing an additive (co)monad, and provides a first example of a Curry-Howard interpretation of a realistic programming language with built-in internal non-determinism. Thanks to its deep logical foundations, our system elegantly addresses several well-known tensions between control, linearity, and non-determinism: globally, it enforces progress and fidelity; locally, it allows the specification of non-deterministic and abortable computations. The expressivity of our system is illustrated by several examples, including a typed encoding of a higher-order functional language with threads, session channels, non-determinism, and exceptions.",
isbn="978-3-662-54434-1"
}


@InProceedings{10.1007/11924661_7,
author="Benton, Nick
and Kennedy, Andrew
and Hofmann, Martin
and Beringer, Lennart",
editor="Kobayashi, Naoki",
title="Reading, Writing and Relations",
booktitle="Programming Languages and Systems",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="114--130",
abstract="We give an elementary semantics to an effect system, tracking read and write effects by using relations over a standard extensional semantics for the original language. The semantics establishes the soundness of both the analysis and its use in effect-based program transformations.",
isbn="978-3-540-48938-2"
}


@InProceedings{10.1007/978-3-319-10936-7_5,
author="Brotherston, James
and Gorogiannis, Nikos",
editor="M{\"u}ller-Olm, Markus
and Seidl, Helmut",
title="Cyclic Abduction of Inductively Defined Safety and Termination Preconditions",
booktitle="Static Analysis",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="68--84",
abstract="We introduce cyclic abduction: a new method for automatically inferring safety and termination preconditions of heap-manipulating while programs, expressed as inductive definitions in separation logic. Cyclic abduction essentially works by searching for a cyclic proof of the desired property, abducing definitional clauses of the precondition as necessary in order to advance the proof search process.",
isbn="978-3-319-10936-7"
}


@Inbook{Fluet2010,
author="Fluet, Matthew
and Bergstrom, Lars
and Ford, Nic
and Rainey, Mike
and Reppy, John
and Shaw, Adam
and Xiao, Yingqi",
editor="Horv{\'a}th, Zolt{\'a}n
and Plasmeijer, Rinus
and Zs{\'o}k, Vikt{\'o}ria",
title="Programming in Manticore, a Heterogenous Parallel Functional Language",
bookTitle="Central European Functional Programming School: Third Summer School, CEFP 2009, Budapest, Hungary, May 21-23, 2009 and Kom{\'a}rno, Slovakia, May 25-30, 2009, Revised Selected Lectures",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="94--145",
abstract="The Manticore project is an effort to design and implement a new functional language for parallel programming. Unlike many earlier parallel languages, Manticore is a heterogeneous language that supports parallelism at multiple levels. Specifically, the Manticore language combines Concurrent ML-style explicit concurrency with fine-grain, implicitly threaded, parallel constructs. These lectures will introduce the Manticore language and explore a variety of programs written to take advantage of heterogeneous parallelism.",
isbn="978-3-642-17685-2",
doi="10.1007/978-3-642-17685-2_4",
url="https://doi.org/10.1007/978-3-642-17685-2_4"
}


@InProceedings{10.1007/978-3-662-54494-5_2,
author="Montaghami, Vajih
and Rayside, Derek",
editor="Huisman, Marieke
and Rubin, Julia",
title="Bordeaux: A Tool for Thinking Outside the Box",
booktitle="Fundamental Approaches to Software Engineering",
year="2017",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="22--39",
abstract="One of the great features of the Alloy Analyzer is that it can produce examples illustrating the meaning of the user's model. These inside-the-box examples, which are formally permissible but (potentially) undesirable, help the user understand underconstraint bugs in the model. To get similar help with overconstraint bugs in the model the user needs to see examples that are desirable but formally excluded: that is, they need to see outside-the-box (near-miss) examples. We have developed a prototype extension of the Alloy Analyzer, named Bordeaux, that can find these examples that are near the border of what is permitted, and hence might be desirable. More generally, Bordeaux finds a pair of examples, a, c, at a minimum distance to each other, and where a satisfies model A and c satisfies model C. The primary use case described is when model C is the negation of model A, but there are also other uses for this relative minimization. Previous works, such as Aluminum, have focused on finding inside-the-box examples that are absolutely minimal.",
isbn="978-3-662-54494-5"
}


@InProceedings{10.1007/978-3-642-14107-2_3,
author="Dhoolia, Pankaj
and Mani, Senthil
and Sinha, Vibha Singhal
and Sinha, Saurabh",
editor="D'Hondt, Theo",
title="Debugging Model-Transformation Failures Using Dynamic Tainting",
booktitle="ECOOP 2010 -- Object-Oriented Programming",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="26--51",
abstract="Model-to-text (M2T) transforms are a class of software applications that translate a structured input into text output. The input models to such transforms are complex, and faults in the models that cause an M2T transform to generate an incorrect or incomplete output can be hard to debug. We present an approach based on dynamic tainting to assist transform users in debugging input models. The approach instruments the transform code to associate taint marks with the input-model elements, and propagate the marks to the output text. The taint marks identify the input-model elements that either contribute to an output string, or cause potentially incorrect paths to be executed through the transform, which results in an incorrect or a missing string in the output. We implemented our approach for XSL-based transforms and conducted empirical studies. Our results illustrate that the approach can significantly reduce the fault search space and, in many cases, precisely identify the input-model faults. The main benefit of our approach is that it automates, with a high degree of accuracy, a debugging task that can be tedious to perform manually.",
isbn="978-3-642-14107-2"
}


@Inbook{Reynolds2008,
author="Reynolds, John C.",
editor="Meyer, Bertrand
and Woodcock, Jim",
title="An Overview of Separation Logic",
bookTitle="Verified Software: Theories, Tools, Experiments: First IFIP TC 2/WG 2.3 Conference, VSTTE 2005, Zurich, Switzerland, October 10-13, 2005, Revised Selected Papers and Discussions",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="460--469",
abstract="After some general remarks about program verification, we introduce separation logic, a novel extension of Hoare logic that can strengthen the applicability and scalability of program verification for imperative programs that use shared mutable data structures or shared-memory concurrency.",
isbn="978-3-540-69149-5",
doi="10.1007/978-3-540-69149-5_49",
url="https://doi.org/10.1007/978-3-540-69149-5_49"
}


@InProceedings{10.1007/978-3-319-08970-6_16,
author="Dufourd, Jean-Fran{\c{c}}ois",
editor="Klein, Gerwin
and Gamboa, Ruben",
title="Hypermap Specification and Certified Linked Implementation Using Orbits",
booktitle="Interactive Theorem Proving",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="242--257",
abstract="We propose a revised constructive specification and a certified hierarchized linked implementation of combinatorial hypermaps using a general notion of orbit. Combinatorial hypermaps help to prove theorems in algebraic topology and to develop algorithms in computational geometry. Orbits unify the presentation at conceptual and concrete levels and reduce the proof effort. All the development is formalized and verified in the Coq proof assistant. The implementation is easily proved observationally equivalent to the specification and translated in C language. Our method is transferable to a great class of algebraic specifications implemented into complex data structures with hierarchized linear, circular or symmetric linked lists, and pointer arrays.",
isbn="978-3-319-08970-6"
}


@InProceedings{10.1007/978-3-642-04425-0_8,
author="Chenouard, Rapha{\"e}l
and Jouault, Fr{\'e}d{\'e}ric",
editor="Sch{\"u}rr, Andy
and Selic, Bran",
title="Automatically Discovering Hidden Transformation Chaining Constraints",
booktitle="Model Driven Engineering Languages and Systems",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="92--106",
abstract="Model transformations operate on models conforming to precisely defined metamodels. Consequently, it often seems relatively easy to chain them: the output of a transformation may be given as input to a second one if metamodels match. However, this simple rule has some obvious limitations. For instance, a transformation may only use a subset of a metamodel. Therefore, chaining transformations appropriately requires more information.",
isbn="978-3-642-04425-0"
}


@InProceedings{10.1007/978-3-642-14306-9_56,
author="Abo-Hammour, Zaer. S.
and Alsmadi, Othman M. K.
and Al-Smadi, Adnan M.",
editor="Zavoral, Filip
and Yaghob, Jakub
and Pichappan, Pit
and El-Qawasmeh, Eyas",
title="A Novel Technique for ARMA Modelling with Order and Parameter Estimation Using Genetic Algorithms",
booktitle="Networked Digital Technologies",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="564--576",
abstract="A new method for determining simultaneously the order and parameters of Auto Regressive Moving Average (ARMA) models is presented in this paper. ARMA models, which can be present in different fields such as communication systems, control systems, internet software and hardware models are determined using genetic algorithms (GAs). Given ARMA (p, q) model input/output data with the absence of any information about the order, the correct model (p, q) is determined (order and parameters). The proposed method works on the principle of minimizing the overall deviation between the actual plant output, with or without noise, and the estimated plant output. The algorithm does not use complex mathematical procedures in its detection. Simulation results covered in this paper show in detail the efficiency and the generality of the proposed approach. In addition to that, the new method is compared with other well known methods for ARMA model order and parameter estimation.",
isbn="978-3-642-14306-9"
}


@InProceedings{10.1007/978-3-540-30217-9_67,
author="Schneider, Georg
and Wersing, Heiko
and Sendhoff, Bernhard
and K{\"o}rner, Edgar",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="Coupling of Evolution and Learning to Optimize a Hierarchical Object Recognition Model",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="662--671",
abstract="A key problem in designing artificial neural networks for visual object recognition tasks is the proper choice of the network architecture. Evolutionary optimization methods can help to solve this problem. In this work we compare different evolutionary optimization approaches for a biologically inspired neural vision system: Direct coding versus a biologically more plausible indirect coding using unsupervised local learning. A comparison to state-of-the-art recognition approaches shows the competitiveness of our approach.",
isbn="978-3-540-30217-9"
}


@Inbook{Zaus1999,
author="Zaus, Michael",
title="Fundamentals of Autogenetic Algorithms",
bookTitle="Crisp and Soft Computing with Hypercubical Calculus: New Approaches to Modeling in Cognitive Science and Technology with Parity Logic, Fuzzy Logic, and Evolutionary Computing",
year="1999",
publisher="Physica-Verlag HD",
address="Heidelberg",
pages="309--399",
abstract="In this final chapter we shall outline the computational foundations of autogenetic algorithms. The term ``autogenetic algorithms'' (AGAs) refers to a new class of adaptive search procedures that is closely related to ``genetic algorithms'' (GAs) by structure, but differing from GAs on the choice of parity integration ⊕ as its main ``genetic'' operator.",
isbn="978-3-7908-1879-6",
doi="10.1007/978-3-7908-1879-6_10",
url="https://doi.org/10.1007/978-3-7908-1879-6_10"
}


@InProceedings{10.1007/978-3-540-71618-1_18,
author="Silva, Rafael R.
and Lopes, Heitor S.
and Erig Lima, Carlos R.",
editor="Beliczynski, Bartlomiej
and Dzielinski, Andrzej
and Iwanowski, Marcin
and Ribeiro, Bernardete",
title="A New Mutation Operator for the Elitism-Based Compact Genetic Algorithm",
booktitle="Adaptive and Natural Computing Algorithms",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="159--166",
abstract="A Compact Genetic Algorithm (CGA) is a genetic algorithm specially devised to meet the tight restrictions of hardware-based implementations. We propose a new mutation operator for an elitism-based CGA. The performance of this algorithm, named emCGA, was tested using a set of algebraic functions for optimization. The optimal mutation rate found for high-dimensionality functions is around 0.5{\%}, and the low the dimension of the problem, the less sensitive is emCGA to the mutation rate. The emCGA was compared with other two similar algorithms and demonstrated better tradeoff between quality of solutions and convergence speed. It also achieved such results with smaller population sizes than the other algorithms.",
isbn="978-3-540-71618-1"
}


@InProceedings{10.1007/978-3-642-10672-9_14,
author="Tan, Gang
and Shao, Zhong
and Feng, Xinyu
and Cai, Hongxu",
editor="Hu, Zhenjiang",
title="Weak updates and separation logic",
booktitle="Programming Languages and Systems",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="178--193",
abstract="Separation Logic (SL) provides a simple but powerful technique for reasoning about imperative programs that use shared data structures. Unfortunately, SL supports only ``strong updates'', in which mutation to a heap location is safe only if a unique reference is owned. This limits the applicability of SL when reasoning about the interaction between many high-level languages (e.g., ML, Java, C{\#}) and low-level ones since these high-level languages do not support strong updates. Instead, they adopt the discipline of ``weak updates'', in which there is a global ``heap type'' to enforce the invariant of type-preserving heap updates. We present SLw, a logic that extends SL with reference types and elegantly reasons about the interaction between strong and weak updates. We also describe a semantic framework for reference types; this framework is used to prove the soundness of SLw.",
isbn="978-3-642-10672-9"
}


@InProceedings{10.1007/978-3-540-70594-9_16,
author="Nishimura, Susumu",
editor="Audebaud, Philippe
and Paulin-Mohring, Christine",
title="Safe Modification of Pointer Programs in Refinement Calculus",
booktitle="Mathematics of Program Construction",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="284--304",
abstract="This paper discusses stepwise refinement of pointer programs in the framework of refinement calculus. We augment the underlying logic with formulas of separation logic and then introduce a pair of new predicate transformers, called separating assertion and separating assumption. The new predicate transformers are derived from separating conjunction and separating implication, which are fundamental logical connectives in separation logic. They represent primitive forms of heap allocation/deallocation operators and the basic pointer statements can be specified by means of them. We derive several refinement laws that are useful for stepwise refinement and demonstrate the use of the laws in the context of correctness preserving transformations that are intended for improved memory usage.",
isbn="978-3-540-70594-9"
}


@InProceedings{10.1007/978-3-642-38883-5_18,
author="Wieber, Martin
and Sch{\"u}rr, Andy",
editor="Duddy, Keith
and Kappel, Gerti",
title="Systematic Testing of Graph Transformations: A Practical Approach Based on Graph Patterns",
booktitle="Theory and Practice of Model Transformations",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="205--220",
abstract="Correctness is an essential property of model transformations. Although testing is a well-accepted method for assuring software quality in general, the properties of declarative transformation languages often prevent a direct application of testing strategies from imperative programming languages. A key challenge of transformation testing concerns limiting the testing effort by a good stop criterion. In this work, we tackle this issue for programmed graph transformations, and present a practical methodology to derive sufficient test suites based on a new coverage notion inspired by mutation analysis. We systematically generate requirement (graph) patterns from the transformation under test, applying different requirement construction strategies, and analyze the approach in terms of practicability, test suite quality and the ability to guide and support test case construction.",
isbn="978-3-642-38883-5"
}


@InProceedings{10.1007/978-3-642-24559-6_20,
author="Maclean, Ewen
and Ireland, Andrew",
editor="Qin, Shengchao
and Qiu, Zongyan",
title="Mutation in Linked Data Structures",
booktitle="Formal Methods and Software Engineering",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="275--290",
abstract="Separation logic was developed as an extension to Hoare logic with the aim of simplifying pointer program proofs. A key feature of the logic is that it focuses the reasoning effort on only those parts of the heap that are relevant to a program - so called local reasoning. Underpinning this local reasoning are the separating conjunction and separating implication operators. Here we present an automated reasoning technique called mutation that provides guidance for separation logic proofs. Specifically, given two heap structures specified within separation logic, mutation attempts to construct an equivalence proof using a difference reduction strategy. Pivotal to this strategy is a generalised decomposition operator which is essential when matching heap structures. We show how mutation provides an effective strategy for proving the functional correctness of iterative and recursive programs within the context of weakest precondition analysis. Currently, mutation is implemented as a proof plan within our CORE program verification system. CORE combines results from shape analysis with our work on invariant generation and proof planning. We present our results for mutation within the context of the CORE system.",
isbn="978-3-642-24559-6"
}


@InProceedings{10.1007/11844297_6,
author="J{\"a}gersk{\"u}pper, Jens
and Storch, Tobias",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="How Comma Selection Helps with the Escape from Local Optima",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="52--61",
abstract="We investigate (1,$\lambda$) ESs using isotropic mutations for optimization in ℝnby means of a theoretical runtime analysis. In particular, a constant offspring-population size $\lambda$ will be of interest.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/BFb0026577,
author="Jagannathan, Suresh",
editor="Ito, Takayasu
and Yonezawa, Akinori",
title="Locality abstractions for parallel and distributed computing",
booktitle="Theory and Practice of Parallel Programming",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="320--345",
abstract="Temporal and spatial locality are significant concerns in the design and implementation of any realistic parallel or distributed computing system. Temporal locality is concerned with relations among objects that share similar lifetimes and birth dates; spatial locality is concerned with relations among objects that share information. Exploiting temporal locality can lead to improved memory behavior; exploiting spatial locality can lead to improved communication behavior. Linguistic, compiler, and runtime support for locality issues is especially important for unstructured symbolic computations in which lifetimes and sharing properties of objects are not readily apparent.",
isbn="978-3-540-49218-4"
}


@InProceedings{10.1007/978-3-540-74591-4_16,
author="Norrish, Michael
and Vestergaard, Ren{\'e}",
editor="Schneider, Klaus
and Brandt, Jens",
title="Proof Pearl: De Bruijn Terms Really Do Work",
booktitle="Theorem Proving in Higher Order Logics",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="207--222",
abstract="Placing our result in a web of related mechanised results, we give a direct proof that the de Bruijn $\lambda$-calculus ({\`a} la Huet, Nipkow and Shankar) is isomorphic to an $\alpha$-quotiented $\lambda$-calculus. In order to establish the link, we introduce an ``index-carrying'' abstraction mechanism over de Bruijn terms, and consider it alongside a simplified substitution mechanism. Relating the new notions to those of the $\alpha$-quotiented and the proper de Bruijn formalisms draws on techniques from the theory of nominal sets.",
isbn="978-3-540-74591-4"
}


@InProceedings{10.1007/978-3-642-39038-8_28,
author="Auerbach, Josh
and Bacon, Dave F.
and Cheng, Perry
and Fink, Steve
and Rabbah, Rodric",
editor="Castagna, Giuseppe",
title="The Shape of Things to Run",
booktitle="ECOOP 2013 -- Object-Oriented Programming",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="679--706",
abstract="Reconfigurable hardware can deliver impressive performance for some applications, when a highly static hardware design closely matches application logic. Obliged to express efficient static hardware structures, hardware designers cannot currently employ abstractions using dynamic features of modern programming languages.",
isbn="978-3-642-39038-8"
}


@Inbook{Taha2008,
author="Taha, Walid",
editor="L{\"a}mmel, Ralf
and Visser, Joost
and Saraiva, Jo{\~a}o",
title="A Gentle Introduction to Multi-stage Programming, Part II",
bookTitle="Generative and Transformational Techniques in Software Engineering II: International Summer School, GTTSE 2007, Braga, Portugal, July 2-7, 2007. Revised Papers",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="260--290",
abstract="As domain-specific languages (DSLs) permeate into mainstream software engineering, there is a need for economic methods for implementing languages. Following up on a paper with a similar title, this paper focuses on dynamically typed languages, covering issues ranging from parsing to defining and staging an interpreter for an interesting subset of Dr. Scheme. Preliminary experimental results indicate that the speedups reported in previous work for smaller languages and with smaller benchmarks are maintained.",
isbn="978-3-540-88643-3",
doi="10.1007/978-3-540-88643-3_6",
url="https://doi.org/10.1007/978-3-540-88643-3_6"
}


@InProceedings{10.1007/3-540-55808-X_32,
author="Laneve, Cosimo
and Montanari, Ugo",
editor="Havel, Ivan M.
and Koubek, V{\'a}clav",
title="Mobility in the CC-paradigm",
booktitle="Mathematical Foundations of Computer Science 1992",
year="1992",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="336--345",
isbn="978-3-540-47291-9"
}


@InProceedings{10.1007/978-3-642-11931-6_3,
author="Kitzelmann, Emanuel",
editor="Schmid, Ute
and Kitzelmann, Emanuel
and Plasmeijer, Rinus",
title="Inductive Programming: A Survey of Program Synthesis Techniques",
booktitle="Approaches and Applications of Inductive Programming",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="50--73",
abstract="Inductive programming (IP)---the use of inductive reasoning methods for programming, algorithm design, and software development---is a currently emerging research field. A major subfield is inductive program synthesis, the (semi-)automatic construction of programs from exemplary behavior. Inductive program synthesis is not a unified research field until today but scattered over several different established research fields such as machine learning, inductive logic programming, genetic programming, and functional programming. This impedes an exchange of theory and techniques and, as a consequence, a progress of inductive programming. In this paper we survey theoretical results and methods of inductive program synthesis that have been developed in different research fields until today.",
isbn="978-3-642-11931-6"
}


@Article{Ab. Rahim2015,
author="Ab. Rahim, Lukman
and Whittle, Jon",
title="A survey of approaches for verifying model transformations",
journal="Software {\&} Systems Modeling",
year="2015",
month="May",
day="01",
volume="14",
number="2",
pages="1003--1028",
abstract="As with other software development artifacts, model transformations are not bug-free and so must be systematically verified. Their nature, however, means that transformations require specialist verification techniques. This paper brings together current research on model transformation verification by classifying existing approaches along two dimensions. Firstly, we present a coarse-grained classification based on the technical details of the approach (e.g., testing, theorem proving, model checking). Secondly, we present a finer-grained classification which categorizes approaches according to criteria such as level of formality, transformation language, properties verified. The purpose of the survey is to bring together research in model transformation verification to act as a resource for the community. Furthermore, based on the survey, we identify a number of trends in current and past research on model transformation verification.",
issn="1619-1374",
doi="10.1007/s10270-013-0358-0",
url="https://doi.org/10.1007/s10270-013-0358-0"
}


@InProceedings{10.1007/11494676_7,
author="Nowostawski, Mariusz
and Purvis, Martin
and Cranefield, Stephen",
editor="Brueckner, Sven A.
and Di Marzo Serugendo, Giovanna
and Karageorgos, Anthony
and Nagpal, Radhika",
title="An Architecture for Self-Organising Evolvable Virtual Machines",
booktitle="Engineering Self-Organising Systems",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="100--122",
abstract="Contemporary software systems are exposed to demanding, dynamic, and unpredictable environments where the traditional adaptability mechanisms may not be sufficient. To imitate and fully benefit from life-like adaptability in software systems that might come closer to the complexity levels of biological organisms, we seek a formal mathematical model of certain fundamental concepts such as: life, organism, evolvability and adaptation. In this work we concentrate on the concept of software evolvability. Our work proposes an evolutionary computation model, based on the theory of hypercycles and autopoiesis. The intrinsic properties of hypercycles allow them to evolve into higher levels of complexity, analogous to multi-level, or hierarchical evolutionary processes. We aim to obtain structures of self-maintaining ensembles, that are hierarchically organised, and our primary focus is on such open-ended hierarchically organised evolution.",
isbn="978-3-540-31901-6"
}


@Inbook{Michalewicz1996,
author="Michalewicz, Zbigniew",
title="Fine Local Tuning",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="107--120",
abstract="Genetic algorithms display inherent difficulties in performing local search for numerical applications. Holland suggested [188] that the genetic algorithm should be used as a preprocessor to perform the initial search, before turning the search process over to a system that can employ domain knowledge to guide the local search. As observed in [170]:``Like natural genetic systems, GAs progress by virtue of changing the distribution of high performance substructures in the overall population; individual structures are not the focus of attention. Once the high performance regions of the search space are identified by a GA, it may be useful to invoke a local search routine to optimize the members of the final population.''",
isbn="978-3-662-03315-9",
doi="10.1007/978-3-662-03315-9_7",
url="https://doi.org/10.1007/978-3-662-03315-9_7"
}


@InProceedings{10.1007/11844297_98,
author="Moore, Jason H.
and White, Bill C.",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Exploiting Expert Knowledge in Genetic Programming for Genome-Wide Genetic Analysis",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="969--977",
abstract="Human genetics is undergoing an information explosion. The availability of chip-based technology facilitates the measurement of thousands of DNA sequence variation from across the human genome. The challenge is to sift through these high-dimensional datasets to identify combinations of interacting DNA sequence variations that are predictive of common diseases. The goal of this paper was to develop and evaluate a genetic programming (GP) approach for attribute selection and modeling that uses expert knowledge such as Tuned ReliefF (TuRF) scores during selection to ensure trees with good building blocks are recombined and reproduced. We show here that using expert knowledge to select trees performs as well as a multiobjective fitness function but requires only a tenth of the population size. This study demonstrates that GP may be a useful computational discovery tool in this domain.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-642-20282-7_22,
author="Neme, Antonio
and Nido, Antonio",
editor="Dobnikar, Andrej
and Lotri{\v{c}}, Uro{\v{s}}
and {\v{S}}ter, Branko",
title="Visualizing Multidimensional Data through Multilayer Perceptron Maps",
booktitle="Adaptive and Natural Computing Algorithms",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="210--219",
abstract="Visualization of high-dimensional data is a major task in data mining. The main idea of visualization is to map data from the high-dimensional space onto a certain position in a low-dimensional space. From all mappings, only those that lead to maps that are good approximations of the data distribution observed in the high-dimensional space are of interest. Here, we present a mapping scheme based on multilayer perceptrons that forms a two-dimensional representation of high-dimensional data. The core idea is that the system maps all vectors to a certain position in the two-dimensional space. We then measure how much does this map resemble the distribution in the original high-dimensional space, which leads to an error measure. Based on this error, we apply reinforcement learning to multilayer perceptrons to find good maps. We present here the description of the model as well as some results in well-known benchmarks. We conclude that the multilayer perceptron is a good tool to visualize high-dimensional data.",
isbn="978-3-642-20282-7"
}


@InProceedings{10.1007/978-3-319-07785-7_7,
author="Prasetya, I. S. Wishnu B.",
editor="Vos, Tanja E.J.
and Lakhotia, Kiran
and Bauersfeld, Sebastian",
title="T3, a Combinator-Based Random Testing Tool for Java: Benchmarking",
booktitle="Future Internet Testing",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="101--110",
abstract="T3 is the next generation of the light weight automated testing tool T2 for Java. In the heart T3 is still a random testing tool; but it now comes with some new features: pair-wise testing, concurrent generators, and a combinator-based approach ala QuickCheck. This paper presents the result of benchmarking of T3 on its default configuration against a set of real world classes.",
isbn="978-3-319-07785-7"
}


@InProceedings{10.1007/978-3-319-57858-3_10,
author="Schneider, Martin A.
and Wendland, Marc-Florian
and Bornemann, Leon",
editor="Gro{\ss}mann, J{\"u}rgen
and Felderer, Michael
and Seehusen, Fredrik",
title="Gaining Certainty About Uncertainty",
booktitle="Risk Assessment and Risk-Driven Quality Assurance",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="129--142",
abstract="A cyber-physical system (CPS) comprises several connected, embedded systems and is additionally equipped with sensors and actuators. Thus, CPSs can communicate with their cyber environment and measure and interact with their physical environment. Due to the complexity of their operational environment, assumptions the manufacturer have made may not hold in operation. During an unforeseen environmental situation, a CPS may expose behavior that negatively impactsits reliability. This may arise due to insufficiently considered environmental conditions during the design of a CPS, or -- even worse -- it is impossible to anticipate such conditions. In the U-Test project, we are developing a configurable search-based testing framework that exploits information from functional testing and from declarative descriptions of uncertainties. Itaims at revealing unintended behavior in the presence of uncertainties. This framework enables testing for different scenarios of uncertainty and thus, allows to achieve a certain coverage of those, and to find unknown uncertainty scenarios.",
isbn="978-3-319-57858-3"
}


@Inbook{Michalewicz1994,
author="Michalewicz, Zbigniew",
title="Fine Local Tuning",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1994",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="105--118",
abstract="Genetic algorithms display inherent difficulties in performing local search for numerical applications. Holland suggested [142] that the genetic algorithm should be used as a preprocessor to perform the initial search, before turning the search process over to a system that can employ domain knowledge to guide the local search. As observed in [129]:``Like natural genetic systems, GAs progress by virtue of changing the distribution of high performance substructures in the overall population; individual structures are not the focus of attention. Once the high performance regions of the search space are identified by a GA, it may be useful to invoke a local search routine to optimize the members of the final population.''",
isbn="978-3-662-07418-3",
doi="10.1007/978-3-662-07418-3_7",
url="https://doi.org/10.1007/978-3-662-07418-3_7"
}


@InProceedings{10.1007/978-3-642-04921-7_17,
author="Juuso, Esko K.",
editor="Kolehmainen, Mikko
and Toivanen, Pekka
and Beliczynski, Bartlomiej",
title="Tuning of Large-Scale Linguistic Equation (LE) Models with Genetic Algorithms",
booktitle="Adaptive and Natural Computing Algorithms",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="161--170",
abstract="Evolutionary computing is widely used to tune intelligent systems which incorporate expert knowledge with data. The linguistic equation (LE) approach is an efficient technique for developing truly adaptive, yet understandable, systems for highly complex applications. Process insight is maintained, while data-driven tuning relates the measurements to the operating areas. Genetic algorithms are well suited for LE models based on nonlinear scaling and linear interactions. New parameter definitions have been developed for the scaling functions to handle efficiently the parameter constraints of the monotonously increasing second order polynomials. While identification approaches are used to define the model structures of the dynamic models. Cascade models, effective delays and working point models are also represented with LE models, i.e. the whole system is configured with a set of parameters. Results show that the efficiency of the systems improves considerably after the implementation of simultaneous tuning of all parameters.",
isbn="978-3-642-04921-7"
}


@InProceedings{10.1007/978-3-319-22102-1_9,
author="Chargu{\'e}raud, Arthur
and Pottier, Fran{\c{c}}ois",
editor="Urban, Christian
and Zhang, Xingyuan",
title="Machine-Checked Verification of the Correctness and Amortized Complexity of an Efficient Union-Find Implementation",
booktitle="Interactive Theorem Proving",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="137--153",
abstract="Union-Find is a famous example of a simple data structure whose amortized asymptotic time complexity analysis is non-trivial. We present a Coq formalization of this analysis. Moreover, we implement Union-Find as an OCaml library and formally endow it with a modular specification that offers a full functional correctness guarantee as well as an amortized complexity bound. Reasoning in Coq about imperative OCaml code relies on the CFML tool, which is based on characteristic formulae and Separation Logic, and which we extend with time credits. Although it was known in principle that amortized analysis can be explained in terms of time credits and that time credits can be viewed as resources in Separation Logic, we believe our work is the first practical demonstration of this approach.",
isbn="978-3-319-22102-1"
}


@InProceedings{10.1007/978-3-642-20551-4_15,
author="Calv{\`e}s, Christophe
and Fern{\'a}ndez, Maribel",
editor="Alpuente, Mar{\'i}a",
title="The First-Order Nominal Link",
booktitle="Logic-Based Program Synthesis and Transformation",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="234--248",
abstract="We define a morphism from nominal syntax, which supports binding, to standard (first-order) syntax. We use this morphism to extend Paterson and Wegman's linear first-order unification algorithm in order to deal with terms modulo alpha-equivalence. The nominal unification algorithm obtained is quadratic in time.",
isbn="978-3-642-20551-4"
}


@InProceedings{10.1007/978-3-319-07151-0_6,
author="Kiselyov, Oleg",
editor="Codish, Michael
and Sumii, Eijiro",
title="The Design and Implementation of BER MetaOCaml",
booktitle="Functional and Logic Programming",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="86--102",
abstract="MetaOCaml is a superset of OCaml extending it with the data type for program code and operations for constructing and executing such typed code values. It has been used for compiling domain-specific languages and automating tedious and error-prone specializations of high-performance computational kernels. By statically ensuring that the generated code compiles and letting us quickly run it, MetaOCaml makes writing generators less daunting and more productive.",
isbn="978-3-319-07151-0"
}


@InProceedings{10.1007/BFb0019443,
author="Cook, William R.",
editor="de Bakker, J. W.
and de Roever, W. P.
and Rozenberg, G.",
title="Object-oriented programming versus abstract data types",
booktitle="Foundations of Object-Oriented Languages",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="151--178",
abstract="This tutorial collects and elaborates arguments for distinguishing between object-oriented programming and abstract data types. The basic distinction is that object-oriented programming achieves data abstraction by the use of procedural abstraction, while abstract data types depend upon type abstraction. Object-oriented programming and abstract data types can also be viewed as complimentary implementation techniques: objects are centered around the constructors of a data abstraction, while abstract data types are organized around the operations. These differences have consequences relating to extensibility, efficiency, typing, and verification; in many cases the strengths of one paradigm are the weaknesses of the other. Most object-oriented programming languages support aspects of both techniques, not a unification of them, so an understanding of their relative merits is useful in designing programs.",
isbn="978-3-540-46450-1"
}


@InProceedings{10.1007/3-540-55253-7_23,
author="Odersky, Martin",
editor="Krieg-Br{\"u}ckner, Bernd",
title="Observers for linear types",
booktitle="ESOP '92",
year="1992",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="390--407",
abstract="Linear types provide the framework for a safe embedding of mutable state in functional languages by enforcing the principle that variables of linear type must be used exactly once. A potential disadvantage of this approach is that it places read accesses to such variables under the same restriction as write accesses, and thus prevents reads to proceed in parallel. We present here an extension of linear types which augments the usual distinction between linear and non-linear by a third state, observers of linear variables. Since, unlike linear variables, observers can be duplicated, multiple concurrent reads are made possible. On the other hand, observers must be short-lived enough to never overlap with mutations. The resulting type system is in many aspects similar to the one of ML: It is polymorphic, has principal types, and admits a type reconstruction algorithm.",
isbn="978-3-540-46803-5"
}


@InProceedings{10.1007/BFb0029949,
author="Ferrari, GianLuigi
and Montanari, Ugo",
editor="Pr{\'i}vara, Igor
and Ru{\v{z}}i{\v{c}}ka, Peter",
title="A tile-based coordination view of asynchronous $\pi$-calculus",
booktitle="Mathematical Foundations of Computer Science 1997",
year="1997",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="52--70",
abstract="Tiles are rewrite rules with side effects, reminiscent of both Plotkin SOS and Meseguer rewriting logic rules. They are well suited for modeling coordination languages, since they can be composed both statically and dynamically via possibly complex synchronization and work-flow mechanisms. In this paper, we give a the-based bisimilarity semantics for the asynchronous $\pi$-calculus of Honda and Tokoro and prove it equivalent to the ordinary semantics. Two kinds of tiles are provided: activity tiles and coordination tiles. Activity tiles specify the basic interactions sequential processes are able to perform, without considering the operational environment where they live. Instead, coordination tiles control the global evolution of programs.",
isbn="978-3-540-69547-9"
}


@InProceedings{10.1007/978-3-642-54833-8_16,
author="Nanevski, Aleksandar
and Ley-Wild, Ruy
and Sergey, Ilya
and Delbianco, Germ{\'a}n Andr{\'e}s",
editor="Shao, Zhong",
title="Communicating State Transition Systems for Fine-Grained Concurrent Resources",
booktitle="Programming Languages and Systems",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="290--310",
abstract="We present a novel model of concurrent computations with shared memory and provide a simple, yet powerful, logical framework for uniform Hoarestyle reasoning about partial correctness of coarse- and fine-grained concurrent programs. The key idea is to specify arbitrary resource protocols as communicating state transition systems (STS) that describe valid states of a resource and the transitions the resource is allowed to make, including transfer of heap ownership.",
isbn="978-3-642-54833-8"
}


@InProceedings{10.1007/3-540-47993-7_5,
author="Bacon, David F.
and Fink, Stephen J.
and Grove, David",
editor="Magnusson, Boris",
title="Space- and Time-Efficient Implementation of the Java Object Model",
booktitle="ECOOP 2002 --- Object-Oriented Programming",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="111--132",
abstract="While many object-oriented languages impose space overhead of only one word per object to support features like virtual method dispatch, Java's richer functionality has led to implementations that require two or three header words per object. This space overhead increases memory usage and attendant garbage collection costs, reduces cache locality, and constrains programmers who might naturally solve a problem by using large numbers of small objects.",
isbn="978-3-540-47993-2"
}


@InProceedings{10.1007/978-3-540-30217-9_24,
author="de Jong, Edwin D.
and Thierens, Dirk
and Watson, Richard A.",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="Hierarchical Genetic Algorithms",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="232--241",
abstract="Current Genetic Algorithms can efficiently address order-k separable problems, in which the order of the linkage is restricted to a low value k. Outside this class, there exist hierarchical problems that cannot be addressed by current genetic algorithms, yet can be addressed efficiently in principle by exploiting hierarchy. We delineate the class of hierarchical problems, and describe a framework for Hierarchical Genetic Algorithms. Based on this outline for algorithms, we investigate under what conditions hierarchical problems may be solved efficiently. Sufficient conditions are provided under which hierarchical problems can be addressed in polynomial time. The analysis points to the importance of efficient sampling techniques that assess the quality of module settings.",
isbn="978-3-540-30217-9"
}


@InProceedings{10.1007/BFb0026565,
author="Queinnec, Christian",
editor="Ito, Takayasu
and Yonezawa, Akinori",
title="Sharing mutable objects and controlling groups of tasks in a concurrent and distributed language",
booktitle="Theory and Practice of Parallel Programming",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="70--93",
abstract="This paper presents: (i) an operational semantics, based on a functional framework, for a concurrent and distributed extension of the Scheme programming language, (ii) a coherency protocol taking care of shared mutable objects, (iii) a new coherency protocol to imperatively control hierarchical groups of cooperating tasks. These two protocols do not require broadcast, nor FIFO communications, nor a centralized machine; they allow to manage an unbound number of shared mutable values and groups of tasks. This paper also advocates for the use of a functional continuation-based presentation for these protocols.",
isbn="978-3-540-49218-4"
}


@Article{Cuadrado2018,
author="Cuadrado, Jes{\'u}s S{\'a}nchez
and Guerra, Esther
and de Lara, Juan",
title="Quick fixing ATL transformations with speculative analysis",
journal="Software {\&} Systems Modeling",
year="2018",
month="Jul",
day="01",
volume="17",
number="3",
pages="779--813",
abstract="Model transformations are central components of most model-based software projects. While ensuring their correctness is vital to guarantee the quality of the solution, current transformation tools provide limited support to statically detect and fix errors. In this way, the identification of errors and their correction are nowadays mostly manual activities which incur in high costs. The aim of this work is to improve this situation. Recently, we developed a static analyser that combines program analysis and constraint solving to identify errors in ATL model transformations. In this paper, we present a novel method and system that uses our analyser to propose suitable quick fixes for ATL transformation errors, notably some non-trivial, transformation-specific ones. Our approach supports speculative analysis to help developers select the most appropriate fix by creating a dynamic ranking of fixes, reporting on the consequences of applying a quick fix, and providing a pre-visualization of each quick fix application. The approach integrates seamlessly with the ATL editor. Moreover, we provide an evaluation based on existing faulty transformations built by a third party, and on automatically generated transformation mutants, which are then corrected with the quick fixes of our catalogue.",
issn="1619-1374",
doi="10.1007/s10270-016-0541-1",
url="https://doi.org/10.1007/s10270-016-0541-1"
}


@InProceedings{10.1007/978-3-642-45221-5_27,
author="Heras, J{\'o}nathan
and Komendantskaya, Ekaterina
and Johansson, Moa
and Maclean, Ewen",
editor="McMillan, Ken
and Middeldorp, Aart
and Voronkov, Andrei",
title="Proof-Pattern Recognition and Lemma Discovery in ACL2",
booktitle="Logic for Programming, Artificial Intelligence, and Reasoning",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="389--406",
abstract="We present a novel technique for combining statistical machine learning for proof-pattern recognition with symbolic methods for lemma discovery. The resulting tool, ACL2(ml), gathers proof statistics and uses statistical pattern-recognition to pre-processes data from libraries, and then suggests auxiliary lemmas in new proofs by analogy with already seen examples. This paper presents the implementation of ACL2(ml) alongside theoretical descriptions of the proof-pattern recognition and lemma discovery methods involved in it.",
isbn="978-3-642-45221-5"
}


@InProceedings{10.1007/978-3-540-27813-9_22,
author="Immerman, Niel
and Rabinovich, Alexander
and Reps, Thomas W.
and Sagiv, Mooly
and Yorsh, Great",
editor="Alur, Rajeev
and Peled, Doron A.",
title="Verification via Structure Simulation",
booktitle="Computer Aided Verification",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="281--294",
abstract="This paper shows how to harness decision procedures to automatically verify safety properties of imperative programs that perform dynamic storage allocation and destructive updating of structure fields. Decidable logics that can express reachability properties are used to state properties of linked data structures, while guaranteeing that the verification method always terminates. The main technical contribution is a method of structure simulation in which a set of original structures that we wish to model, e.g., doubly linked lists, nested linked lists, binary trees, etc., are mapped to a set of tractable structures that can be reasoned about using decidable logics. Decidable logics that can express reachability are rather limited in the data structures that they can directly model. For instance, our examples use the logic MSO-E, which can only model function graphs; however, the simulation technique provides an indirect way to model additional data structures.",
isbn="978-3-540-27813-9"
}


@InProceedings{10.1007/978-3-642-23716-4_7,
author="Chicano, Francisco
and Ferrer, Javier
and Alba, Enrique",
editor="Cohen, Myra B.
and {\'O} Cinn{\'e}ide, Mel",
title="Elementary Landscape Decomposition of the Test Suite Minimization Problem",
booktitle="Search Based Software Engineering",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="48--63",
abstract="Landscape theory provides a formal framework in which combinatorial optimization problems can be theoretically characterized as a sum of a special kind of landscape called elementary landscape. The decomposition of the objective function of a problem into its elementary components provides additional knowledge on the problem that can be exploited to create new search methods for the problem. We analyze the Test Suite Minimization problem in Regression Testing from the point of view of landscape theory. We find the elementary landscape decomposition of the problem and propose a practical application of such decomposition for the search.",
isbn="978-3-642-23716-4"
}


@InProceedings{10.1007/3-540-60360-3_41,
author="Jagannathan, Suresh
and Wright, Andrew",
editor="Mycroft, Alan",
title="Effective flow analysis for avoiding run-time checks",
booktitle="Static Analysis",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="207--224",
abstract="This paper describes a general purpose program analysis that computes global control-flow and data-flow information for higher-order, call-by-value programs. This information can be used to drive global program optimizations such as inlining and run-time check elimination, as well as optimizations like constant folding and loop invariant code motion that are typically based on special-purpose local analyses.",
isbn="978-3-540-45050-4"
}


@InProceedings{10.1007/978-3-540-74591-4_8,
author="Gonthier, Georges
and Mahboubi, Assia
and Rideau, Laurence
and Tassi, Enrico
and Th{\'e}ry, Laurent",
editor="Schneider, Klaus
and Brandt, Jens",
title="A Modular Formalisation of Finite Group Theory",
booktitle="Theorem Proving in Higher Order Logics",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="86--101",
abstract="In this paper, we present a formalisation of elementary group theory done in Coq. This work is the first milestone of a long-term effort to formalise the Feit-Thompson theorem. As our further developments will heavily rely on this initial base, we took special care to articulate it in the most compositional way.",
isbn="978-3-540-74591-4"
}


@InProceedings{10.1007/11814771_41,
author="Urban, Christian
and Berghofer, Stefan",
editor="Furbach, Ulrich
and Shankar, Natarajan",
title="A Recursion Combinator for Nominal Datatypes Implemented in Isabelle/HOL",
booktitle="Automated Reasoning",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="498--512",
abstract="The nominal datatype package implements an infrastructure in Isabelle/HOL for defining languages involving binders and for reasoning conveniently about alpha-equivalence classes. Pitts stated some general conditions under which functions over alpha-equivalence classes can be defined by a form of structural recursion and gave a clever proof for the existence of a primitive-recursion combinator. We give a version of this proof that works directly over nominal datatypes and does not rely upon auxiliary constructions. We further introduce proving tools and a heuristic that made the automation of our proof tractable. This automation is an essential prerequisite for the nominal datatype package to become useful.",
isbn="978-3-540-37188-5"
}


@InProceedings{10.1007/978-3-319-11737-9_10,
author="Dufourd, Jean-Fran{\c{c}}ois",
editor="Merz, Stephan
and Pang, Jun",
title="Pointer Program Derivation Using Coq: Graphs and Schorr-Waite Algorithm",
booktitle="Formal Methods and Software Engineering",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="139--154",
abstract="We present a specification, a derivation and total correctness proofs of operations for bi-functional graphs implemented with pointers, including the Schorr-Waite algorithm. This one marks such a graph with an economical depth-first strategy. Our approach is purely algebraic and functional, from a simple graph specification to the simulation of a tail-recursive imperative program, then to a true C pointer program by elementary classical transformations. We stay in the unique higher-order formalism of the Calculus of Inductive Constructions for specifications, programs and proofs. All the development is supported by Coq.",
isbn="978-3-319-11737-9"
}


@InProceedings{10.1007/978-3-642-34407-7_6,
author="Persson, Anders
and Axelsson, Emil
and Svenningsson, Josef",
editor="Gill, Andy
and Hage, Jurriaan",
title="Generic Monadic Constructs for Embedded Languages",
booktitle="Implementation and Application of Functional Languages",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="85--99",
abstract="We present a library of generic monadic constructs for embedded languages. It is an extension of Syntactic, a Haskell library for defining and processing generic abstract syntax. Until now, Syntactic has been mostly suited to implement languages based on pure, side effect free, expressions. The presented extension allows the pure expressions to also contain controlled side effects, enabling the representation of expressions that rely on destructive updates for efficiency. We demonstrate the usefulness of the extension by giving examples from the embedded language Feldspar which is implemented using Syntactic.",
isbn="978-3-642-34407-7"
}


@InProceedings{10.1007/978-1-4471-3182-3_5,
author="Sheeran, Mary",
editor="Birtwistle, Graham",
title="Sorts of butterflies",
booktitle="IV Higher Order Workshop, Banff 1990",
year="1991",
publisher="Springer London",
address="London",
pages="66--76",
abstract="This paper shows how Ruby is used to describe and analyse permutation and comparator networks. It describes two merging networks, the bitonic merger and the balanced merger, and shows how they are related. Both of these networks can be used to build recursive sorters. The balanced merger is also the building block of a periodic sorting network that is suitable for implementation on silicon. The correctness of this sorter is demonstrated. As always the key to success in understanding a circuit or algorithm is in finding suitable structuring functions and studying their mathematical properties. This paper uses the notation and to a large extent the structuring functions introduced in reference [4] (in this volume) and that paper should be read first.",
isbn="978-1-4471-3182-3"
}


@Inbook{Topçu2016,
author="Top{\c{c}}u, Okan
and Durak, Umut
and O{\u{g}}uzt{\"u}z{\"u}n, Halit
and Yilmaz, Levent",
title="Synergies of MDE, Simulation, and Agent Technology",
bookTitle="Distributed Simulation: A Model Driven Engineering Approach",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="251--270",
abstract="Software agents, modeling and simulation (M{\&}S), and model-driven engineering (MDE) are fields with their distinct body of knowledge and good practices. However, developments in one area can provide new avenues for advancing the methodologies and technical strategies in other fields. This chapter examines the synergies among these three fields by highlighting selected challenges in each area and by delineating how methods developed in each field can mutually be beneficial. We categorize the ways in which the agent paradigm can contribute to critical activities in MDE, and similarly we delineate how domain-specific languages and model transformation strategies can be instrumental in the design, implementation, and management of agent systems.",
isbn="978-3-319-03050-0",
doi="10.1007/978-3-319-03050-0_11",
url="https://doi.org/10.1007/978-3-319-03050-0_11"
}


@InProceedings{10.1007/978-3-319-26841-5_3,
author="Mariot, Luca
and Leporati, Alberto",
editor="Dediu, Adrian-Horia
and Magdalena, Luis
and Mart{\'i}n-Vide, Carlos",
title="A Genetic Algorithm for Evolving Plateaued Cryptographic Boolean Functions",
booktitle="Theory and Practice of Natural Computing",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="33--45",
abstract="We propose a genetic algorithm (GA) to search for plateaued boolean functions, which represent suitable candidates for the design of stream ciphers due to their good cryptographic properties. Using the spectral inversion technique introduced by Clark, Jacob, Maitra and Stanica, our GA encodes the chromosome of a candidate solution as a permutation of a three-valued Walsh spectrum. Additionally, we design specialized crossover and mutation operators so that the swapped positions in the offspring chromosomes correspond to different values in the resulting Walsh spectra. Some tests performed on the set of pseudoboolean functions of {\$}{\$}n=6{\$}{\$}and {\$}{\$}n=7{\$}{\$}variables show that in the former case our GA outperforms Clark et al.'s simulated annealing algorithm with respect to the ratio of generated plateaued boolean functions per number of optimization runs.",
isbn="978-3-319-26841-5"
}


@InProceedings{10.1007/978-3-319-26841-5_6,
author="Picek, Stjepan
and Guilley, Sylvain
and Carlet, Claude
and Jakobovic, Domagoj
and Miller, Julian F.",
editor="Dediu, Adrian-Horia
and Magdalena, Luis
and Mart{\'i}n-Vide, Carlos",
title="Evolutionary Approach for Finding Correlation Immune Boolean Functions of Order t with Minimal Hamming Weight",
booktitle="Theory and Practice of Natural Computing",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="71--82",
abstract="The role of Boolean functions is prominent in several areas like cryptography, sequences and coding theory. Therefore, various methods to construct Boolean functions with desired properties are of direct interest. When concentrating on Boolean functions and their role in cryptography, we observe that new motivations and hence new properties have emerged during the years. It is important to note that there are still many design criteria left unexplored and this is where Evolutionary Computation can play a distinct role. One combination of design criteria that has appeared recently is finding Boolean functions that have various orders of correlation immunity and minimal Hamming weight. Surprisingly, most of the more traditionally used methods for Boolean function generation are inadequate in this domain. In this paper, we concentrate on a detailed exploration of several evolutionary algorithms and their applicability for this problem. Our results show that such algorithms are a viable choice when evolving Boolean functions with minimal Hamming weight and certain order of correlation immunity. This approach is also successful in obtaining Boolean functions with several values that were known previously to be theoretically optimal, but no one succeeded in finding actual Boolean functions with such values.",
isbn="978-3-319-26841-5"
}


@InProceedings{10.1007/978-3-642-19861-8_13,
author="Henretty, Tom
and Stock, Kevin
and Pouchet, Louis-No{\"e}l
and Franchetti, Franz
and Ramanujam, J.
and Sadayappan, P.",
editor="Knoop, Jens",
title="Data Layout Transformation for Stencil Computations on Short-Vector SIMD Architectures",
booktitle="Compiler Construction",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="225--245",
abstract="Stencil computations are at the core of applications in many domains such as computational electromagnetics, image processing, and partial differential equation solvers used in a variety of scientific and engineering applications. Short-vector SIMD instruction sets such as SSE and VMX provide a promising and widely available avenue for enhancing performance on modern processors. However a fundamental memory stream alignment issue limits achieved performance with stencil computations on modern short SIMD architectures. In this paper, we propose a novel data layout transformation that avoids the stream alignment conflict, along with a static analysis technique for determining where this transformation is applicable. Significant performance increases are demonstrated for a variety of stencil codes on three modern SIMD-capable processors.",
isbn="978-3-642-19861-8"
}


@InProceedings{10.1007/3-540-48035-8_50,
author="Runqiang, Bian
and Chen, Phoebe
and Burrage, Kevin
and Hanan, Jim
and Room, Peter
and Belward, John",
editor="Hendtlass, Tim
and Ali, Moonis",
title="Derivation of L-system Models from Measurements of Biological Branching Structures Using Genetic Algorithms",
booktitle="Developments in Applied Artificial Intelligence",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="514--524",
abstract="L-systems are widely used in the modelling of branching structures and the growth process of biological objects such as plants, nerves and airways in lungs. The derivation of such L-system models involves a lot of hard mental work and time-consuming manual procedures. A method based on genetic algorithms for automating the derivation of L-systems is presented here. The method involves representation of branching structure, translation of L-systems to axial tree architectures, comparison of branching structure and the application of genetic algorithms. Branching structures are represented as axial trees and positional information is considered as an important attribute along with length and angle in the database configuration of branches. An algorithm is proposed for automatic L-system translation that compares randomly generated branching structures with the target structure. Edit distance, which is proposed as a measure of dissimilarity between rooted trees, is extended for the comparison of structures represented in axial trees and positional information is involved in the local cost function. Conventional genetic algorithms and repair mechanics are employed in the search for L-system models having the best fit to observational data.",
isbn="978-3-540-48035-8"
}


@Inbook{Hinze2010,
author="Hinze, Ralf",
editor="Horv{\'a}th, Zolt{\'a}n
and Plasmeijer, Rinus
and Zs{\'o}k, Vikt{\'o}ria",
title="Reasoning about Codata",
bookTitle="Central European Functional Programming School: Third Summer School, CEFP 2009, Budapest, Hungary, May 21-23, 2009 and Kom{\'a}rno, Slovakia, May 25-30, 2009, Revised Selected Lectures",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="42--93",
abstract="Programmers happily use induction to prove properties of recursive programs. To show properties of corecursive programs they employ coinduction, but perhaps less enthusiastically. Coinduction is often considered a rather low-level proof method, in particular, as it departs quite radically from equational reasoning. Corecursive programs are conveniently defined using recursion equations. Suitably restricted, these equations possess unique solutions. Uniqueness gives rise to a simple and attractive proof technique, which essentially brings equational reasoning to the coworld. We illustrate the approach using two major examples: streams and infinite binary trees. Both coinductive types exhibit a rich structure: they are applicative functors or idioms, and they can be seen as memo-tables or tabulations. We show that definitions and calculations benefit immensely from this additional structure.",
isbn="978-3-642-17685-2",
doi="10.1007/978-3-642-17685-2_3",
url="https://doi.org/10.1007/978-3-642-17685-2_3"
}


@Article{Nikanjam2012,
author="Nikanjam, Amin
and Rahmani, Adel",
title="Exploiting Bivariate Dependencies to Speedup Structure Learning in Bayesian Optimization Algorithm",
journal="Journal of Computer Science and Technology",
year="2012",
month="Sep",
day="01",
volume="27",
number="5",
pages="1077--1090",
abstract="Bayesian optimization algorithm (BOA) is one of the successful and widely used estimation of distribution algorithms (EDAs) which have been employed to solve different optimization problems. In EDAs, a model is learned from the selected population that encodes interactions among problem variables. New individuals are generated by sampling the model and incorporated into the population. Different probabilistic models have been used in EDAs to learn interactions. Bayesian network (BN) is a well-known graphical model which is used in BOA. Learning a proper model in EDAs and particularly in BOA is distinguished as a computationally expensive task. Different methods have been proposed in the literature to improve the complexity of model building in EDAs. This paper employs bivariate dependencies to learn accurate BNs in BOA efficiently. The proposed approach extracts the bivariate dependencies using an appropriate pairwise interaction-detection metric. Due to the static structure of the underlying problems, these dependencies are used in each generation of BOA to learn an accurate network. By using this approach, the computational cost of model building is reduced dramatically. Various optimization problems are selected to be solved by the algorithm. The experimental results show that the proposed approach successfully finds the optimum in problems with different types of interactions efficiently. Significant speedups are observed in the model building procedure as well.",
issn="1860-4749",
doi="10.1007/s11390-012-1285-1",
url="https://doi.org/10.1007/s11390-012-1285-1"
}


@Article{Iacca2012,
author="Iacca, Giovanni
and Caraffini, Fabio
and Neri, Ferrante",
title="Compact Differential Evolution Light: High Performance Despite Limited Memory Requirement and Modest Computational Overhead",
journal="Journal of Computer Science and Technology",
year="2012",
month="Sep",
day="01",
volume="27",
number="5",
pages="1056--1076",
abstract="Compact algorithms are Estimation of Distribution Algorithms which mimic the behavior of population-based algorithms by means of a probabilistic representation of the population of candidate solutions. These algorithms have a similar behaviour with respect to population-based algorithms but require a much smaller memory. This feature is crucially important in some engineering applications, especially in robotics. A high performance compact algorithm is the compact Differential Evolution (cDE) algorithm. This paper proposes a novel implementation of cDE, namely compact Differential Evolution light (cDElight), to address not only the memory saving necessities but also real-time requirements. cDElight employs two novel algorithmic modifications for employing a smaller computational overhead without a performance loss, with respect to cDE. Numerical results, carried out on a broad set of test problems, show that cDElight, despite its minimal hardware requirements, does not deteriorate the performance of cDE and thus is competitive with other memory saving and population-based algorithms. An application in the field of mobile robotics highlights the usability and advantages of the proposed approach.",
issn="1860-4749",
doi="10.1007/s11390-012-1284-2",
url="https://doi.org/10.1007/s11390-012-1284-2"
}


@InProceedings{10.1007/978-3-642-36751-9_15,
author="Hinze, Thomas
and Schell, Benjamin
and Schumann, Mathias
and Bodenstein, Christian",
editor="Csuhaj-Varj{\'u}, Erzs{\'e}bet
and Gheorghe, Marian
and Rozenberg, Grzegorz
and Salomaa, Arto
and Vaszil, Gy{\"o}rgy",
title="Maintenance of Chronobiological Information by P System Mediated Assembly of Control Units for Oscillatory Waveforms and Frequency",
booktitle="Membrane Computing",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="208--227",
abstract="Oscillatory signals turn out to be reliable carriers for efficient processing and propagation of information in both spheres, life sciences and engineering. Each living organism typically comprises a variety of inherent biological rhythms whose periodicities cover a widespread range of scales like split seconds, minutes, or hours, and sometimes even months or years. Due to different molecular principles of generation, those rhythms seem to persist independently from each other. Their combination and assembly in conjunction with recurrent environmental changes can lead to astonishing capabilities and evolutionary advantages. Motivated by the question on how populations of cicadas, an insect species living in the soil, sustain a synchronous life cycle of 17 years away from any known external stimulus of this duration, we aim at exploring potential underlying mechanisms by P system mediated assembly of a set of chemical control units. To this end, we identify a collection of core oscillators responsible for sinusoidal, spiking, and plated waveforms along with pass filters, switches, and modulators. Considering these units as genotypic elementary components, we utilise P system control for selection and (re-)assembly of units towards complex phenotypic systems. Two simulation case studies demonstrate the potential of this approach following the idea of artificial evolution. Our first study inspired by the cicadas converts a chemical frequency divider model 1:17 into counterparts of 1:3, 1:5, and 1:6 just by exchange of single units. In the second study adopted from the mammalian circadian clock system residing within the suprachiasmatic nucleus, we illustrate the stabilisation of the overall clock signal by addition of auxiliary core oscillators.",
isbn="978-3-642-36751-9"
}


@InProceedings{10.1007/978-3-642-39799-8_53,
author="Itzhaky, Shachar
and Banerjee, Anindya
and Immerman, Neil
and Nanevski, Aleksandar
and Sagiv, Mooly",
editor="Sharygina, Natasha
and Veith, Helmut",
title="Effectively-Propositional Reasoning about Reachability in Linked Data Structures",
booktitle="Computer Aided Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="756--772",
abstract="This paper proposes a novel method of harnessing existing SAT solvers to verify reachability properties of programs that manipulate linked-list data structures. Such properties are essential for proving program termination, correctness of data structure invariants, and other safety properties. Our solution is complete, i.e., a SAT solver produces a counterexample whenever a program does not satisfy its specification. This result is surprising since even first-order theorem provers usually cannot deal with reachability in a complete way, because doing so requires reasoning about transitive closure.",
isbn="978-3-642-39799-8"
}


@InProceedings{10.1007/BFb0029946,
author="Bodlaender, Hans L.",
editor="Pr{\'i}vara, Igor
and Ru{\v{z}}i{\v{c}}ka, Peter",
title="Treewidth: Algorithmic techniques and results",
booktitle="Mathematical Foundations of Computer Science 1997",
year="1997",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="19--36",
abstract="This paper gives an overview of several results and techniques for graphs algorithms that compute the treewidth of a graph or that solve otherwise intractable problems when restricted graphs with bounded treewidth more efficiently. Also, several results on graph minors are reviewed.",
isbn="978-3-540-69547-9"
}


@InProceedings{10.1007/978-3-319-48989-6_12,
author="David, Cristina
and Kesseli, Pascal
and Kroening, Daniel
and Lewis, Matt",
editor="Fitzgerald, John
and Heitmeyer, Constance
and Gnesi, Stefania
and Philippou, Anna",
title="Danger Invariants",
booktitle="FM 2016: Formal Methods",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="182--198",
abstract="Static analysers search for overapproximating proofs of safety commonly known as safety invariants. Conversely, static bug finders (e.g. Bounded Model Checking) give evidence for the failure of an assertion in the form of a counterexample trace. As opposed to safety invariants, the size of a counterexample is dependent on the depth of the bug, i.e., the length of the execution trace prior to the error state, which also determines the computational effort required to find them. We propose a way of expressing danger proofs that is independent of the depth of bugs. Essentially, such danger proofs constitute a compact representation of a counterexample trace, which we call a danger invariant. Danger invariants summarise sets of traces that are guaranteed to be able to reach an error state. Our conjecture is that such danger proofs will enable the design of bug finding analyses for which the computational effort is independent of the depth of bugs, and thus find deep bugs more efficiently. As an exemplar of an analysis that uses danger invariants, we design a bug finding technique based on a synthesis engine. We implemented this technique and compute danger invariants for intricate programs taken from SV-COMP 2016.",
isbn="978-3-319-48989-6"
}


@InProceedings{10.1007/978-3-642-38088-4_32,
author="Lyde, Steven
and Might, Matthew",
editor="Brat, Guillaume
and Rungta, Neha
and Venet, Arnaud",
title="Extracting Hybrid Automata from Control Code",
booktitle="NASA Formal Methods",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="447--452",
abstract="Formal methods---and abstract interpretation in particular---can assist in the development of correct control code. However, current approaches to deploying formal methods do not always match the way practicing engineers develop real control code. Engineers tend to think in code first---not formal models. Standard practice is for engineers to develop their control code and then build a model like a hybrid automaton from which to verify properties. Since the construction of this model is manual, it leaves open the possibility of error. Existing formal approaches, on the other hand, tend to focus on synthesizing control code from a verified formal model. We propose a method for synthesizing a hybrid automaton from the control code directly. Specifically, we use abstract interpretation to create an abstract state transition system, and from this we systematically extract a hybrid automaton. Not only does this eliminate the introduction of error into the model based on the code, it fits with common practice in engineering cyberphysical systems. We test the technique on a couple examples---control code for a thermostat and a nuclear reactor. We then pass the generated automata to the HyTech model-checker to verify safety and liveness properties.",
isbn="978-3-642-38088-4"
}


@InProceedings{10.1007/978-3-319-21365-1_12,
author="Katayama, Susumu",
editor="Bieger, Jordi
and Goertzel, Ben
and Potapov, Alexey",
title="Towards Human-Level Inductive Functional Programming",
booktitle="Artificial General Intelligence",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="111--120",
abstract="Inductive programming is the framework for automated programming, obtaining generalized recursive programs from ambiguous specifications such as input-output examples. Development of an inductive programming system at the level of human programmers is desired, but it involves the trade off between scale and versatility which are difficult to go together.",
isbn="978-3-319-21365-1"
}


@InProceedings{10.1007/978-3-319-06410-9_4,
author="Bj{\o}rner, Dines
and Havelund, Klaus",
editor="Jones, Cliff
and Pihlajasaari, Pekka
and Sun, Jun",
title="40 Years of Formal Methods",
booktitle="FM 2014: Formal Methods",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="42--61",
abstract="In this ``40 years of formal methods'' essay we shall first delineate, Sect. 1, what we mean by method, formal method, computer science, computing science, software engineering, and model-oriented and algebraic methods. Based on this, we shall characterize a spectrum from specification-oriented methods to analysis-oriented methods. Then, Sect. 2, we shall provide a ``survey'': which are the `prerequisite works' that have enabled formal methods, Sect. 2.1, and which are, to us, the, by now, classical `formal methods', Sect. 2.2. We then ask ourselves the question: have formal methods for software development, in the sense of this paper been successful? Our answer is, regretfully, no! We motivate this answer, in Sect. 3.2, by discussing eight obstacles or hindrances to the proper integration of formal methods in university research and education as well as in industry practice. This ``looking back'' is complemented, in Sect. 3.4, by a ``looking forward'' at some promising developments --- besides the alleviation of the (eighth or more) hindrances!",
isbn="978-3-319-06410-9"
}


@InProceedings{10.1007/978-3-319-22183-0_9,
author="Kocsis, Zoltan A.
and Brownlee, Alexander E. I.
and Swan, Jerry
and Senington, Richard",
editor="Barros, M{\'a}rcio
and Labiche, Yvan",
title="Haiku - a Scala Combinator Toolkit for Semi-automated Composition of Metaheuristics",
booktitle="Search-Based Software Engineering",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="125--140",
abstract="There is an emerging trend towards the automated design of metaheuristics at the software component level. In principle, metaheuristics have a relatively clean decomposition, where well-known frameworks such as ILS and EA are parametrised by variant components for acceptance, perturbation etc. Automated generation of these frameworks is not so simple in practice, since the coupling between components may be implementation specific. Compositionality is the ability to freely express a space of designs `bottom up' in terms of elementary components: previous work in this area has used combinators, a modular and functional approach to componentisation arising from foundational Computer Science. In this article, we describe Haiku, a combinator tool-kit written in the Scala language, which builds upon previous work to further automate the process by automatically composing the external dependencies of components. We provide examples of use and give a case study in which a programatically-generated heuristic is applied to the Travelling Salesman Problem within an Evolutionary Strategies framework.",
isbn="978-3-319-22183-0"
}


@InProceedings{10.1007/978-3-642-38856-9_13,
author="Dudka, Kamil
and Peringer, Petr
and Vojnar, Tom{\'a}{\v{s}}",
editor="Logozzo, Francesco
and F{\"a}hndrich, Manuel",
title="Byte-Precise Verification of Low-Level List Manipulation",
booktitle="Static Analysis",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="215--237",
abstract="We propose a new approach to shape analysis of programs with linked lists that use low-level memory operations. Such operations include pointer arithmetic, safe usage of invalid pointers, block operations with memory, reinterpretation of the memory contents, address alignment, etc. Our approach is based on a new representation of sets of heaps, which is to some degree inspired by works on separation logic with higher-order list predicates, but it is graph-based and uses a more fine-grained (byte-precise) memory model in order to support the various low-level memory operations. The approach was implemented in the Predator tool and successfully validated on multiple non-trivial case studies that are beyond the capabilities of other current fully automated shape analysis tools.",
isbn="978-3-642-38856-9"
}


@InProceedings{10.1007/978-3-540-71067-7_10,
author="Berghofer, Stefan
and Urban, Christian",
editor="Mohamed, Otmane Ait
and Mu{\~{n}}oz, C{\'e}sar
and Tahar, Sofi{\`e}ne",
title="Nominal Inversion Principles",
booktitle="Theorem Proving in Higher Order Logics",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="71--85",
abstract="When reasoning about inductively defined predicates, such as typing judgements or reduction relations, proofs are often done by inversion, that is by a case analysis on the last rule of a derivation. In HOL and other formal frameworks this case analysis involves solving equational constraints on the arguments of the inductively defined predicates. This is well-understood when the arguments consist of variables or injective term-constructors. However, when alpha-equivalence classes are involved, that is when term-constructors are not injective, these equational constraints give rise to annoying variable renamings. In this paper, we show that more convenient inversion principles can be derived where one does not have to deal with variable renamings. An interesting observation is that our result relies on the fact that inductive predicates must satisfy the variable convention compatibility condition, which was introduced to justify the admissibility of Barendregt's variable convention in rule inductions.",
isbn="978-3-540-71067-7"
}


@InProceedings{10.1007/978-3-642-30561-0_14,
author="Mehnert, Hannes
and Aldrich, Jonathan",
editor="Furia, Carlo A.
and Nanz, Sebastian",
title="Verification of Snapshotable Trees Using Access Permissions and Typestate",
booktitle="Objects, Models, Components, Patterns",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="187--201",
abstract="We use access permissions and typestate to specify and verify a Java library that implements snapshotable search trees, as well as some client code. We formalize our approach in the Plural tool, a sound modular typestate checking tool. We describe the challenges to verifying snapshotable trees in Plural, give an abstract interface specification against which we verify the client code, provide a concrete specification for an implementation and describe proof patterns we found. We also relate this verification approach to other techniques used to verify this data structure.",
isbn="978-3-642-30561-0"
}


@Article{Rahmoun2019,
author="Rahmoun, Smail
and Mehiaoui-Hamitou, Asma
and Borde, Etienne
and Pautet, Laurent
and Soubiran, Elie",
title="Multi-objective exploration of architectural designs by composition of model transformations",
journal="Software {\&} Systems Modeling",
year="2019",
month="Feb",
day="01",
volume="18",
number="1",
pages="107--127",
abstract="Designing software architectures and optimizing them based on extra-functional properties (EFPs) require to identify appropriate design decisions and to apply them on valid architectural elements. Software designers have to check whether the resulting architecture fulfills the requirements and how it positively improves (possibly conflicting) EFPs. In practice, they apply well-known solutions such as design patterns manually. This is time-consuming, error-prone, and possibly sub-optimal. Well-established approaches automate the search of the design space for an optimal solution. They are based model-driven engineering techniques that formalized design decisions as model transformations and architectural elements as components. Using multi-objective optimizations techniques, they explore the design space by randomly selecting a set of components and applying to them variation operators that include a fixed set of predefined design decisions. In this work, we claim that the design space exploration requires to reason on both architectural components as well as model transformations. More specifically, we focus on possible instantiations of model transformations materialized as the application of model transformation alternatives on a set of architectural components. This approach was prototyped in RAMSES, a model transformation and code generation framework. Experimental results show the capability of our approach (i) to combine evolutionary algorithms and model transformation techniques to explore efficiently a set of architectural alternatives with conflicting EFPs, (ii) to instantiate, and select transformation instances that generate architectures satisfying stringent structural constraints, and (iii) to explore design spaces by chaining more than one transformation. In particular, we evaluated our approach on EFPs, architectures, and design alternatives inspired from the railway industry by chaining model transformations dedicated to implement safety design patterns and software components allocation on a multi-processor hardware platform.",
issn="1619-1374",
doi="10.1007/s10270-017-0580-2",
url="https://doi.org/10.1007/s10270-017-0580-2"
}


@Inbook{Giachino2014,
author="Giachino, Elena
and Laneve, Cosimo",
editor="Bernardo, Marco
and Damiani, Ferruccio
and H{\"a}hnle, Reiner
and Johnsen, Einar Broch
and Schaefer, Ina",
title="Deadlock Detection in Linear Recursive Programs",
bookTitle="Formal Methods for Executable Software Models: 14th International School on Formal Methods for the Design of Computer, Communication, and Software Systems, SFM 2014, Bertinoro, Italy, June 16-20, 2014, Advanced Lectures",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="26--64",
abstract="Deadlock detection in recursive programs that admit dynamic resource creation is extremely complex and solutions either give imprecise answers or do not scale.",
isbn="978-3-319-07317-0",
doi="10.1007/978-3-319-07317-0_2",
url="https://doi.org/10.1007/978-3-319-07317-0_2"
}


@InProceedings{10.1007/978-3-540-72883-2_21,
author="Su, Sen
and Zhang, Chengwen
and Chen, Junliang",
editor="Indulska, Jadwiga
and Raymond, Kerry",
title="An Improved Genetic Algorithm for Web Services Selection",
booktitle="Distributed Applications and Interoperable Systems",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="284--295",
abstract="An improved genetic algorithm is presented to select optimal web services composite plans from a lot of composite plans on the basis of global Quality-of-Service (QoS) constraints. The relation matrix coding scheme of genome is its basis. In this genetic algorithm, an especial fitness function and a mutation policy are proposed on the basis of the relation matrix coding scheme of genome. They enhance convergence of genetic algorithm and can get more excellent composite service plan because they accord with web services selection very well. The simulation results on QoS-aware web services selection have shown that the improved genetic algorithm can gain effectively the composite service plan that satisfies the global QoS requirements, and that the convergence of genetic algorithm was improved very well.",
isbn="978-3-540-72883-2"
}


@Inbook{Klettke2011,
author="Klettke, Meike
and Thalheim, Bernhard ",
editor="Embley, David W.
and Thalheim, Bernhard",
title="Evolution and Migration of Information Systems",
bookTitle="Handbook of Conceptual Modeling: Theory, Practice, and Research Challenges",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="381--419",
abstract="Modernisation of information systems is a fundamental but sometimes neglected aspect of conceptual modelling. The management of evolution, migration and refinement and the ability for information systems to deal with modernisation is an essential component in developing and maintaining truly useful systems that minimise service disruption and down time and maximise availability of data and applications. Many approaches to handling evolution and migration have been proposed in various areas of data management. Most of them are rather informal descriptions of the project management of either evolution management or migration management. Typical problems that have been considered are modelling and management of evolution and migration; handling of changes and versioning; managing information system upgrades and schema changes; semantics of modernisation in time and space; handling changes in metadata, schema evolution, migration and versioning; change detection, monitoring and mining.",
isbn="978-3-642-15865-0",
doi="10.1007/978-3-642-15865-0_12",
url="https://doi.org/10.1007/978-3-642-15865-0_12"
}


@InProceedings{10.1007/978-3-540-45099-3_1,
author="Jackson, Daniel",
editor="Palsberg, Jens",
title="Enforcing Design Constraints with Object Logic",
booktitle="Static Analysis",
year="2000",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--21",
abstract="Design constraints express essential behavioural properties of a software system. Two key elements of a scheme for enforcing design constraints are presented: a logic for describing the constraints, and an analysis that can be used both to explore the constraints in isolation (and thus gain confidence in their correctness), and to check that they are obeyed by an implementation. Examples of applications of the logic and its analysis at various levels of abstraction are given, from high-level designs to finding bugs in code. The challenge of bridging several levels, and checking code against abstract design constraints, is illustrated with a scenario from an air-traffic control system.",
isbn="978-3-540-45099-3"
}


@Inbook{Schmid2003,
author="Schmid, Ute",
title="6. Automatic Programming",
bookTitle="Inductive Synthesis of Functional Programs: Universal Planning, Folding of Finite Programs, and Schema Abstraction by Analogical Reasoning",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="99--166",
abstract="Automatic programming is investigated in artificial intelligence and software engineering. The overall research goal in automatic programming is to automatize as large a part of the development of computer programs as possible. A more modest goal is to automatize or support special aspects of program development - such as program verification or generation of high-level programs from specifications. The focus of this chapter is on program generation from specifications - referred to as automatic program construction or program synthesis.",
isbn="978-3-540-44846-4",
doi="10.1007/978-3-540-44846-4_6",
url="https://doi.org/10.1007/978-3-540-44846-4_6"
}


@InProceedings{10.1007/11844297_97,
author="Kubal{\'i}k, Ji{\v{r}}{\'i}
and Po{\v{s}}{\'i}k, Petr
and Herold, Jan",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="A Selecto-recombinative Genetic Algorithm with Continuous Chromosome Reconfiguration",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="959--968",
abstract="A good performance of traditional genetic algorithm is determined by its ability to identify building blocks and grow them to larger ones. To attain this objective a properly arranged chromosome is needed to ensure that building blocks will survive the application of recombination operators. The proposed algorithm periodically rearranges the order of genes in the chromosome while the actual information about the inter-gene dependencies is calculated on-line through the run. Standard 2-point crossover, operating on the adapted chromosomal structure, is used to generate new solutions. Experimental results show that this algorithm is able to solve separable problems with strong intra building block dependencies among genes as well as the hierarchical problems.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-319-19797-5_7,
author="Dongol, Brijesh
and Gomes, Victor B. F.
and Struth, Georg",
editor="Hinze, Ralf
and Voigtl{\"a}nder, Janis",
title="A Program Construction and Verification Tool for Separation Logic",
booktitle="Mathematics of Program Construction",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="137--158",
abstract="An algebraic approach to the design of program construction and verification tools is applied to separation logic. The control-flow level is modelled by power series with convolution as separating conjunction. A generic construction lifts resource monoids to assertion and predicate transformer quantales. The data domain is captured by concrete store-heap models. These are linked to the separation algebra by soundness proofs. Verification conditions and transformation or refinement laws are derived by equational reasoning within the predicate transformer quantale. This separation of concerns makes an implementation in the Isabelle/HOL proof assistant simple and highly automatic. The resulting tool is itself correct by construction; it is explained on three simple examples.",
isbn="978-3-319-19797-5"
}


@InProceedings{10.1007/978-3-319-42064-6_2,
author="Klint, Paul
and van der Storm, Tijs",
editor="Van Gorp, Pieter
and Engels, Gregor",
title="Model Transformation with Immutable Data",
booktitle="Theory and Practice of Model Transformations",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="19--35",
abstract="Mainstream model transformation tools operate on graph structured models which are described by class-based meta-models. In the traditional grammarware space, transformation tools consume and produce tree structured terms, which are described by some kind of algebraic datatype or grammar. In this paper we explore a functional style of model transformation using Rascal, a meta-programming language, that seamlessly integrates functional programming, flexible static typing, and syntax-based analysis and transformation. We represent meta-models as algebraic data types (ADTs), and models as immutable values conforming to those data types. Our main contributions are (a) REFS a simple encoding and API, to deal with cross references among model elements that are represented as ADTs; (b) a mapping from models to ADTs augmented with REFS; (c) evaluation of our encoding by implementing various well-known model transformations on state machines, meta-models, and activity diagrams. Our approach can be seen as a first step towards making existing techniques and tools from the modelware domain available for reuse within Rascal, and opening up Rascal's transformation capabilities for use in model driven engineering scenarios.",
isbn="978-3-319-42064-6"
}


@InProceedings{10.1007/11844297_8,
author="Beyer, Hans-Georg
and Meyer-Nieberg, Silja",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Self-adaptation on the Ridge Function Class: First Results for the Sharp Ridge",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="72--81",
abstract="This paper presents first results of an analysis of the $\sigma$-self-adaptation mechanism on the sharp ridge for non-recombinative (1,$\lambda$) evolution strategies (ES). To analyze the ES's evolution, we consider the so-called evolution equations which describe the one-generation change. Neglecting stochastic perturbations and considering only the mean value dynamics, we will investigate possible causes why self-adaptation can fail on the sharp ridge.",
isbn="978-3-540-38991-0"
}


@Inbook{Michalewicz1994,
author="Michalewicz, Zbigniew",
title="GAs: Why Do They Work?",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1994",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="43--53",
abstract="The theoretical foundations of genetic algorithms rely on a binary string representation of solutions, and on the notion of a schema (see e.g., [142]) --- a template allowing exploration of similarities among chromosomes. A schema is built by introducing a don't care symbol (*) into the alphabet of genes. A schema represents all strings (a hyperplane, or subset of the search space), which match it on all positions other than `*'.",
isbn="978-3-662-07418-3",
doi="10.1007/978-3-662-07418-3_4",
url="https://doi.org/10.1007/978-3-662-07418-3_4"
}


@Inbook{Michalewicz1996,
author="Michalewicz, Zbigniew",
title="GAs: Why Do They Work?",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="45--55",
abstract="The theoretical foundations of genetic algorithms rely on a binary string representation of solutions, and on the notion of a schema (see e.g., [188]) --- a template allowing exploration of similarities among chromosomes. A schema is built by introducing a don't care symbol (⋆) into the alphabet of genes. A schema represents all strings (a hyperplane, or subset of the search space), which match it on all positions other than `⋆'.",
isbn="978-3-662-03315-9",
doi="10.1007/978-3-662-03315-9_4",
url="https://doi.org/10.1007/978-3-662-03315-9_4"
}


@InProceedings{10.1007/978-3-642-58049-9_11,
author="Cosnard, M.
and Loi, M.
and Tourancheau, B.",
editor="Kowalik, Janusz S.
and Grandinetti, Lucio",
title="Data Migrations on the Hypercube",
booktitle="Software for Parallel Computation",
year="1993",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="149--162",
abstract="In this paper, our aim is twofold. First, we present a general framework for data allocation specification, including those most commonly used in scientific parallel programming. Second, we review how the data migrations can be implemented and we present recent works for hypercube topologies.",
isbn="978-3-642-58049-9"
}


@InProceedings{10.1007/3-540-36580-X_21,
author="de Jong, Hidde
and Gouz{\'e}, Jean-Luc
and Hernandez, C{\'e}line
and Page, Michel
and Sari, Tewfik
and Geiselmann, Johannes",
editor="Maler, Oded
and Pnueli, Amir",
title="Hybrid Modeling and Simulation of Genetic Regulatory Networks: A Qualitative Approach",
booktitle="Hybrid Systems: Computation and Control",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="267--282",
abstract="The study of genetic regulatory networks has received a major impetus from the recent development of experimental techniques allowing the measurement of patterns of gene expression in a massively parallel way. This experimental progress calls for the development of appropriate computer tools for the modeling and simulation of gene regulation processes. We present a method for the hybrid modeling and simulation of genetic regulatory networks, based on a class of piecewiselinear (PL) differential equations that has been well-studied in mathematical biology. Distinguishing characteristics of the method are that it makes qualitative predictions of the behavior of regulatory systems and that it deals with discontinuities in the right-hand side of the differential equations. The simulation method has been implemented in Java in the computer tool Genetic Network Analyzer (GNA). The method and the tool have been used to analyze several networks of biological interest, including the network underlying the initiation of sporulation in Bacillus subtilis.",
isbn="978-3-540-36580-8"
}


@InProceedings{10.1007/978-3-319-41135-4_3,
author="Cheney, James
and Momigliano, Alberto
and Pessina, Matteo",
editor="Aichernig, Bernhard K.
and Furia, Carlo A.",
title="Advances in Property-Based Testing for {\$}{\$}{\backslash}alpha {\$}{\$}Prolog",
booktitle="Tests and Proofs",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="37--56",
abstract="{\$}{\$}{\backslash}alpha {\$}{\$}Check is a light-weight property-based testing tool built on top of {\$}{\$}{\backslash}alpha {\$}{\$}Prolog, a logic programming language based on nominal logic. {\$}{\$}{\backslash}alpha {\$}{\$}Prolog is particularly suited to the validation of the meta-theory of formal systems, for example correctness of compiler translations involving name-binding, alpha-equivalence and capture-avoiding substitution. In this paper we describe an alternative to the negation elimination algorithm underlying {\$}{\$}{\backslash}alpha {\$}{\$}Check that substantially improves its effectiveness. To substantiate this claim we compare the checker performances w.r.t. two of its main competitors in the logical framework niche, namely the QuickCheck/Nitpick combination offered by Isabelle/HOL and the random testing facility in PLT-Redex.",
isbn="978-3-319-41135-4"
}


@InProceedings{10.1007/978-3-642-17164-2_20,
author="Kero, Martin
and Pietrzak, Pawe{\l}
and Nordlander, Johan",
editor="Ueda, Kazunori",
title="Live Heap Space Bounds for Real-Time Systems",
booktitle="Programming Languages and Systems",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="287--303",
abstract="Live heap space analyses have so far been concerned with the standard sequential programming model. However, that model is not very well suited for embedded real-time systems, where fragments of code execute concurrently and in orders determined by periodic and sporadic events. Schedulability analysis has shown that the programming model of real-time systems is not fundamentally in conflict with static predictability, but in contrast to accumulative properties like time, live heap space usage exhibits a very state-dependent behavior that renders direct application of schedulability analysis techniques unsuitable.",
isbn="978-3-642-17164-2"
}


@InProceedings{10.1007/978-3-642-13953-6_9,
author="Heidegger, Phillip
and Thiemann, Peter",
editor="Vitek, Jan",
title="Contract-Driven Testing of JavaScript Code",
booktitle="Objects, Models, Components, Patterns",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="154--172",
abstract="JSConTest is a tool that enhances JavaScript with simple, type-like contracts and provides a framework for monitoring and guided random testing of programs against these contracts at the same time. Function contracts in JSConTest serve a dual role as specifications of the input/output behavior and as test case generators. Generation of test data for a contract is generally random, but it can be guided by annotations on the contract to achieve higher coverage. Annotations may indicate dependencies among parameters and the result or they may select lightweight program analyses, the results of which influence the choice of test data. A case study substantiates that JSConTest finds type-related errors with high probability.",
isbn="978-3-642-13953-6"
}


@InProceedings{10.1007/3-540-45789-5_19,
author="Ruf, Erik",
editor="Hermenegildo, Manuel V.
and Puebla, Germ{\'a}n",
title="Improving the Precision of Equality-Based Dataflow Analyses",
booktitle="Static Analysis",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="247--262",
abstract="We present two new, orthogonal techniques for improving the precision of equality-based dataflow analyses. Subtype expansion models objects at a per-type granularity, enabling a form of subtype-restricted equality constraint, while mutation tracking uses a simple effect analysis to avoid a class of false aliases induced by the bidirectional nature of equality constraints. The utility and costs of these techniques are demonstrated in a context-sensitive interprocedural optimization whose static precision improves by 6-600{\%} when our techniques are applied.",
isbn="978-3-540-45789-3"
}


@InProceedings{10.1007/978-3-642-27245-5_26,
author="Mandal, Jyotsna Kumar
and Mukhopadhyay, Somnath",
editor="Chaki, Nabendu
and Cortesi, Agostino",
title="GA Based Denoising of Impulses (GADI)",
booktitle="Computer Information Systems -- Analysis and Technologies",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="212--220",
abstract="In this paper we have proposed a novel method of removing random valued impulse noises from the digital images. A variable window such as 5 {\texttimes} 5 and 3 {\texttimes} 3 are utilized for such purpose. The proposed method is a switching median filter. The detection of noises in every 5 {\texttimes} 5 window of the noisy image is done using all neighbor directional weighted pixels. After detection of noisy pixel in the 5 {\texttimes} 5 window the proposed filtering scheme restored it to a pixel which is most suitable in the 3 {\texttimes} 3 and 5 {\texttimes} 5 window regions. This scheme is based on weighted median filtering on the 3 {\texttimes} 3 window regional pixels. Three user parameters of the proposed noise removal operator are searched in a 3D space using a randomized search and optimization technique i.e., Genetic Algorithm. Implementation of the scheme shows better noise removal performance and also preserves the image fine details well.",
isbn="978-3-642-27245-5"
}


@Inbook{Michalewicz1996,
author="Michalewicz, Zbigniew",
title="The Traveling Salesman Problem",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="209--237",
abstract="In the next chapter, we present several examples of evolution programs tailored to specific applications (graph drawing, partitioning, scheduling). The traveling salesman problem (TSP) is just one of such applications; however, we treat it as a special problem --- the mother of all problems --- and discuss it in a separate chapter. What are the reasons?",
isbn="978-3-662-03315-9",
doi="10.1007/978-3-662-03315-9_11",
url="https://doi.org/10.1007/978-3-662-03315-9_11"
}


@InProceedings{10.1007/11494744_5,
author="van der Aalst, W. M. P.
and de Medeiros, A. K. Alves
and Weijters, A. J. M. M.",
editor="Ciardo, Gianfranco
and Darondeau, Philippe",
title="Genetic Process Mining",
booktitle="Applications and Theory of Petri Nets 2005",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="48--69",
abstract="The topic of process mining has attracted the attention of both researchers and tool vendors in the Business Process Management (BPM) space. The goal of process mining is to discover process models from event logs, i.e., events logged by some information system are used to extract information about activities and their causal relations. Several algorithms have been proposed for process mining. Many of these algorithms cannot deal with concurrency. Other typical problems are the presence of duplicate activities, hidden activities, non-free-choice constructs, etc. In addition, real-life logs contain noise (e.g., exceptions or incorrectly logged events) and are typically incomplete (i.e., the event logs contain only a fragment of all possible behaviors). To tackle these problems we propose a completely new approach based on genetic algorithms. As can be expected, a genetic approach is able to deal with noise and incompleteness. However, it is not easy to represent processes properly in a genetic setting. In this paper, we show a genetic process mining approach using the so-called causal matrix as a representation for individuals. We elaborate on the relation between Petri nets and this representation and show that genetic algorithms can be used to discover Petri net models from event logs.",
isbn="978-3-540-31559-9"
}


@InProceedings{10.1007/11844297_80,
author="Pelikan, Martin
and Sastry, Kumara
and Butz, Martin V.
and Goldberg, David E.",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Performance of Evolutionary Algorithms on Random Decomposable Problems",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="788--797",
abstract="This paper describes a class of random additively decomposable problems (rADPs) with and without interactions between the subproblems. The paper then tests the hierarchical Bayesian optimization algorithm (hBOA) and other evolutionary algorithms on a large number of random instances of the proposed class of problems. The results show that hBOA can scalably solve rADPs and that it significantly outperforms all other methods included in the comparison. Furthermore, the results provide a number of interesting insights into both the difficulty of a broad class of decomposable problems as well as the sensitivity of various evolutionary algorithms to different sources of problem difficulty. rADPs can be used to test other optimization algorithms.",
isbn="978-3-540-38991-0"
}


@Article{Liang2010,
author="Liang, Jie
and Qian, Hong",
title="Computational Cellular Dynamics Based on the Chemical Master Equation: A Challenge for Understanding Complexity",
journal="Journal of Computer Science and Technology",
year="2010",
month="Jan",
day="01",
volume="25",
number="1",
pages="154--168",
abstract="Modern molecular biology has always been a great source of inspiration for computational science. Half a century ago, the challenge from understanding macromolecular dynamics has led the way for computations to be part of the tool set to study molecular biology. Twenty-five years ago, the demand from genome science has inspired an entire generation of computer scientists with an interest in discrete mathematics to join the field that is now called bioinformatics. In this paper, we shall lay out a new mathematical theory for dynamics of biochemical reaction systems in a small volume (i.e., mesoscopic) in terms of a stochastic, discrete-state continuous-time formulation, called the chemical master equation (CME). Similar to the wavefunction in quantum mechanics, the dynamically changing probability landscape associated with the state space provides a fundamental characterization of the biochemical reaction system. The stochastic trajectories of the dynamics are best known through the simulations using the Gillespie algorithm. In contrast to the Metropolis algorithm, this Monte Carlo sampling technique does not follow a process with detailed balance. We shall show several examples how CMEs are used to model cellular biochemical systems. We shall also illustrate the computational challenges involved: multiscale phenomena, the interplay between stochasticity and nonlinearity, and how macroscopic determinism arises from mesoscopic dynamics. We point out recent advances in computing solutions to the CME, including exact solution of the steady state landscape and stochastic differential equations that offer alternatives to the Gilespie algorithm. We argue that the CME is an ideal system from which one can learn to understand ``complex behavior'' and complexity theory, and from which important biological insight can be gained.",
issn="1860-4749",
doi="10.1007/s11390-010-9312-6",
url="https://doi.org/10.1007/s11390-010-9312-6"
}


@InProceedings{10.1007/978-3-642-40894-6_12,
author="De Florio, Vincenzo",
editor="Gorbenko, Anatoliy
and Romanovsky, Alexander
and Kharchenko, Vyacheslav",
title="Preliminary Contributions Towards Auto-resilience",
booktitle="Software Engineering for Resilient Systems",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="141--155",
abstract="The variability in the conditions of deployment environments introduces new challenges for the resilience of our computer systems. As a response to said challenges, novel approaches must be devised so that identity robustness be guaranteed autonomously and with minimal overhead. This paper provides the elements of one such approach. First, building on top of previous results, we formulate a metric framework to compare specific aspects of the resilience of systems and environments. Such framework is then put to use by sketching the elements of a handshake mechanism between systems declaring their resilience figures and environments stating their minimal resilience requirements. Despite its simple formulation it is shown how said mechanism enables scenarios in which resilience can be autonomously enhanced, e.g., through forms of social collaboration. This paves the way to future ``auto-resilient'' systems, namely systems able to reason and revise their own architectures and organisations so as to optimally guarantee identity persistence.",
isbn="978-3-642-40894-6"
}


@InProceedings{10.1007/978-3-540-87700-4_89,
author="Icl{\u{a}}nzan, David
and Dumitrescu, Dumitru",
editor="Rudolph, G{\"u}nter
and Jansen, Thomas
and Beume, Nicola
and Lucas, Simon
and Poloni, Carlo",
title="Large-Scale Optimization of Non-separable Building-Block Problems",
booktitle="Parallel Problem Solving from Nature -- PPSN X",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="899--908",
abstract="This paper presents principled results demonstrating how the identification and exploitation of variable dependencies by means of Artificial Neural Network powered online model building, combined with a model based local-search, opens the way towards large-scale optimization of hard, non-separable building-block problems.",
isbn="978-3-540-87700-4"
}


@InProceedings{10.1007/978-3-540-30217-9_1,
author="Beyer, Hans-Georg
and Meyer-Nieberg, Silja",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="On the Quality Gain of (1,$\lambda$)-ES Under Fitness Noise",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--10",
abstract="In optimization tasks that deal with real-world applications noise is very common leading to degradation of the performance of Evolution Strategies. We will consider the quality gain of an (1,$\lambda$)-ES under noisy fitness evaluations for arbitrary fitness functions. The equation developed will be applied to several test functions to check its predictive quality.",
isbn="978-3-540-30217-9"
}


@InProceedings{10.1007/978-3-540-74061-2_24,
author="Chang, Bor-Yuh Evan
and Rival, Xavier
and Necula, George C.",
editor="Nielson, Hanne Riis
and Fil{\'e}, Gilberto",
title="Shape Analysis with Structural Invariant Checkers",
booktitle="Static Analysis",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="384--401",
abstract="Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (eg, used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants.",
isbn="978-3-540-74061-2"
}


@InProceedings{10.1007/978-3-642-20282-7_36,
author="Buj{\'a}n, Jorge Novo
and Santos, Jos{\'e}
and Penedo, Manuel G.",
editor="Dobnikar, Andrej
and Lotri{\v{c}}, Uro{\v{s}}
and {\v{S}}ter, Branko",
title="Optimization of Topological Active Nets with Differential Evolution",
booktitle="Adaptive and Natural Computing Algorithms",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="350--360",
abstract="The Topological Active Net model for image segmentation is a deformable model that integrates features of region--based and boundary--based segmentation techniques. The segmentation process turns into a minimization task of the energy functions which control the model deformation. We used Differential Evolution as an alternative evolutionary method that minimizes the decisions of the designer with respect to other evolutionary methods such as genetic algorithms. Moreover, we hybridized Differential Evolution with a greedy search to integrate the advantages of global and local searches at the same time that the segmentation speed is improved.",
isbn="978-3-642-20282-7"
}


@Inbook{Michalewicz1994,
author="Michalewicz, Zbigniew",
title="The Traveling Salesman Problem",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1994",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="211--237",
abstract="In the next chapter, we present several examples of evolution programs tailored to specific applications (graph drawing, partitioning, scheduling). The traveling salesman problem (TSP) is just one of such applications; however, we treat it as a special problem --- the mother of all problems --- and discuss it in a separate chapter. What are the reasons?",
isbn="978-3-662-07418-3",
doi="10.1007/978-3-662-07418-3_11",
url="https://doi.org/10.1007/978-3-662-07418-3_11"
}


@InProceedings{10.1007/11844297_79,
author="Galv{\'a}n-L{\'o}pez, Edgar
and Poli, Riccardo",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Some Steps Towards Understanding How Neutrality Affects Evolutionary Search",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="778--787",
abstract="The effects of neutrality on evolutionary search have been considered in a number of interesting studies, the results of which, however, have been contradictory. We believe that this confusion is due to several reasons. In this paper, we shed some light on neutrality by addressing these problems. That is, we use the simplest possible definition of neutrality, we consider one of the simplest possible algorithms, we apply it to two problems (a unimodal landscape and a deceptive landscape), which we analyse using fitness distance correlation, performance statistics and, critically, tracking the full evolutionary path of individuals within their family tree.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-642-29280-4_30,
author="Jasper, J.
and Victoire, T. Aruldoss Albert",
editor="Thilagam, P. Santhi
and Pais, Alwyn Roshan
and Chandrasekaran, K.
and Balakrishnan, N.",
title="Variable Neighborhood Search Guided Differential Evolution for Non Convex Economic Load Dispatch",
booktitle="Advanced Computing, Networking and Security",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="253--262",
abstract="This article addresses a novel and effective algorithm for solving the economic load dispatch (ELD) problem of generating units. Generator constraints, such as valve point loading, ramp rate limits and prohibited operating zones are taken into account in the problem formulation of ELD. The cost function of the generating units exhibits nonconvex characteristics, as valve-point effects are modeled and included as rectified sinusoid components in its conventional formulation. The paper investigates the application of variable neighborhood search (VNS) to tune Differential Evolution (DE) algorithm for solving ELD problem considering non-smooth characteristics (NSELD). The basic idea of VNS is to perform a systematic change of neighborhood within a local search. The hybrid method incorporates the DE as the main optimizer and VNS as the local optimizer to fine-tune the solution region discovered by DE during its progress of run. Thus, the VNS guides PSO for better performance in the complex solution space. To demonstrate its efficiency and feasibility, the VNS guided DE is applied to solve NSELD problem of power systems with 6 and 13 units. The simulation results obtained from the VNS guided DE was compared to those from previous literature in terms of solution quality and computational efficiency. It is shown that, the proposed technique for non-smooth ELD problem generates quality solutions reliably.",
isbn="978-3-642-29280-4"
}


@InProceedings{10.1007/11561163_10,
author="Ancona, D.
and Moggi, E.",
editor="de Boer, Frank S.
and Bonsangue, Marcello M.
and Graf, Susanne
and de Roever, Willem-Paul",
title="Program Generation and Components",
booktitle="Formal Methods for Components and Objects",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="222--250",
abstract="The first part of the paper gives a brief overview of meta-programming, in particular program generation, and its use in software development. The second part introduces a basic calculus, related to FreshML, that supports program generation (as described through examples and a translation of MetaML into it) and programming in-the-large (this is demonstrated by a translation of CMS into it).",
isbn="978-3-540-31939-9"
}


@InProceedings{10.1007/978-3-642-54833-8_25,
author="Garnock-Jones, Tony
and Tobin-Hochstadt, Sam
and Felleisen, Matthias",
editor="Shao, Zhong",
title="The Network as a Language Construct",
booktitle="Programming Languages and Systems",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="473--492",
abstract="The actor model inspires several important programming languages. In this model, communicating concurrent actors collaborate to produce a result. A pure actor language tends to turn systems into an organization-free collection of processes, however, even though most applications call for layered and tiered architectures. To address this lack of an organizational principle, programmers invent design patterns.",
isbn="978-3-642-54833-8"
}


@Inbook{Clavel2007,
author="Clavel, Manuel
and Dur{\'a}n, Francisco
and Eker, Steven
and Lincoln, Patrick
and Mart{\'i}-Oliet, Narciso
and Meseguer, Jos{\'e}
and Talcott, Carolyn",
title="A Sampler of Application Areas",
bookTitle="All About Maude - A High-Performance Logical Framework: How to Specify, Program and Verify Systems in Rewriting Logic",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="645--665",
abstract="This chapter gives an overview of some application areas of rewriting logic and Maude, with pointers to papers and web sites where more information can be found. Some of the material is adapted, with some modifications and extensions, from [199, 3, 217]. Since Maude is a general-purpose declarative programming language, there is in principle no limit to the applications that could be developed using it. Therefore, the areas discussed, although quite diverse, are only a sample of types of applications for which Maude seems particularly well suited. But there are many others. For example, the availability of built-in internet sockets in Maude 2.2 (see Section 11.4.1) opens up interesting possibilities for a new style of declarative internet programming which have already begun to be exploited (see Chapter 16).",
isbn="978-3-540-71999-1",
doi="10.1007/978-3-540-71999-1_20",
url="https://doi.org/10.1007/978-3-540-71999-1_20"
}


@InProceedings{10.1007/978-3-642-16527-6_25,
author="Hedjazi, Seyyed Mahdi
and Marjani, Samane Sadat",
editor="Wang, Fu Lee
and Deng, Hepu
and Gao, Yang
and Lei, Jingsheng",
title="Pruned Genetic Algorithm",
booktitle="Artificial Intelligence and Computational Intelligence",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="193--200",
abstract="Genetic algorithm is known as one of the ways of resolving complicated problems and optimization issues. This algorithm works based on a search space and in this space it'd seeking for the optimum answer. In this algorithm, there exist agents and gorges which expand the search space with no logical reason. We can find the measures which take us away from the optimal answer by observing the trend of changes, and it can apply the changes in a way that increases the speed of reaching the answers. It's obvious these changes must be as much as they don't add time complexity or memory load to the system.",
isbn="978-3-642-16527-6"
}


@InProceedings{10.1007/978-3-540-71316-6_35,
author="Condit, Jeremy
and Harren, Matthew
and Anderson, Zachary
and Gay, David
and Necula, George C.",
editor="De Nicola, Rocco",
title="Dependent Types for Low-Level Programming",
booktitle="Programming Languages and Systems",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="520--535",
abstract="In this paper, we describe the key principles of a dependent type system for low-level imperative languages. The major contributions of this work are (1) a sound type system that combines dependent types and mutation for variables and for heap-allocated structures in a more flexible way than before and (2) a technique for automatically inferring dependent types for local variables. We have applied these general principles to design Deputy, a dependent type system for C that allows the user to describe bounded pointers and tagged unions. Deputy has been used to annotate and check a number of real-world C programs.",
isbn="978-3-540-71316-6"
}


@InProceedings{10.1007/11504894_79,
author="Kim, Dongwon
and Park, Gwi-Tae",
editor="Ali, Moonis
and Esposito, Floriana",
title="GMDH-Type Neural Network Modeling in Evolutionary Optimization",
booktitle="Innovations in Applied Artificial Intelligence",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="563--570",
abstract="We discuss a new design of group method of data handling (GMDH)-type neural network using evolutionary algorithm. The performances of the GMDH-type network depend strongly on the number of input variables and order of the polynomials to each node. They must be fixed by designer in advance before the architecture is constructed. So the trial and error method must go with heavy computation burden and low efficiency. To alleviate these problems we employed evolutionary algorithms. The order of the polynomial, the number of input variables, and the optimum input variables are encoded as a chromosome and fitness of each chromosome is computed. The appropriate information of each node are evolved accordingly and tuned gradually throughout the GA iterations. By the simulation results, we can show that the proposed networks have good performance.",
isbn="978-3-540-31893-4"
}


@InProceedings{10.1007/978-3-319-11629-7_18,
author="Seman, Noraini
and Bakar, Zainab Abu
and Bakar, Nordin Abu",
editor="Das, Vinu V.
and Elkafrawy, Passent",
title="Dynamic Neuro-genetic Weights Connection Strategy for Isolated Spoken Malay Speech Recognition System",
booktitle="Signal Processing and Information Technology",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="121--130",
abstract="This paper presents the fusion of artificial intelligence (AI) learning algorithms that combined genetic algorithms (GA) and neural network (NN) methods. These both methods were used to find the optimum weights for the hidden and output layers of feed-forward artificial neural network (ANN) model. Both algorithms are the separate modules and we proposed dynamic connection strategy for combining both algorithms to improve the recognition performance for isolated spoken Malay speech recognition. There are two different GA techniques used in this research, one is standard GA and slightly different technique from standard GA also has been proposed. Thus, from the results, it was observed that the performance of proposed GA algorithm while combined with NN shows better than standard GA and NN models alone. Integrating the GA with feed-forward network can improve mean square error (MSE) performance and with good connection strategy by this two stage training scheme, the recognition rate can be increased up to 99{\%}.",
isbn="978-3-319-11629-7"
}


@Inbook{Mikhaiel2013,
author="Mikhaiel, Rimon
and Tsantalis, Nikolaos
and Negara, Natalia
and Stroulia, Eleni
and Xing, Zhenchang",
editor="L{\"a}mmel, Ralf
and Saraiva, Jo{\~a}o
and Visser, Joost",
title="Differencing UML Models: A Domain-Specific vs. a Domain-Agnostic Method",
bookTitle="Generative and Transformational Techniques in Software Engineering IV: International Summer School, GTTSE 2011, Braga, Portugal, July 3-9, 2011. Revised Papers",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="159--196",
abstract="Comparing software artifacts to identify their similarities and differences is a task ubiquitous in software engineering. Logical-design comparison is particularly interesting, since it can serve multiple purposes. When comparing the as-intended vs. the as-implemented designs, one can evaluate implementation-to-design conformance. When comparing newer code versions against earlier ones, one may better understand the development process of the system, recognize the refactorings it has gone through and the qualities motivating them, and infer high-order patterns in its history. Given its importance, design differencing has been the subject of much research and a variety of algorithms have been developed to compare different types of software artifacts, in support of a variety of different software-engineering activities. Our team has developed two different algorithms for differencing logical-design models of object-oriented software. Both algorithms adopt a similar conceptual model of UML logical designs (as containment trees); however, one of them is heuristic whereas the other relies on a generic tree-differencing algorithm. In this paper, we describe the two approaches and we compare them on multiple versions of an open-source software system.",
isbn="978-3-642-35992-7",
doi="10.1007/978-3-642-35992-7_4",
url="https://doi.org/10.1007/978-3-642-35992-7_4"
}


@InProceedings{10.1007/978-3-540-71618-1_23,
author="Santos, Jos{\'e}
and Ib{\'a}{\~{n}}ez, {\'O}scar
and Barreira, Noelia
and Penedo, Manuel G.",
editor="Beliczynski, Bartlomiej
and Dzielinski, Andrzej
and Iwanowski, Marcin
and Ribeiro, Bernardete",
title="Genetic-Greedy Hybrid Approach for Topological Active Nets Optimization",
booktitle="Adaptive and Natural Computing Algorithms",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="202--210",
abstract="In this paper we propose a genetic and greedy algorithm combination for the optimization of the Topological Active Nets (TAN) model. This is a deformable model used for image segmentation that integrates features of region-based and edge-based segmentation techniques, being able to fit the edges of the objects and model their inner topology. The hybrid approach we propose can optimize the active nets through the minimization of the model energy functions and, moreover, it can provide some segmentation results unreachable by the GA method alone such as changes in the net topology.",
isbn="978-3-540-71618-1"
}


@InProceedings{10.1007/978-3-642-13977-2_4,
author="Ahn, Ki Yung
and Denney, Ewen",
editor="Fraser, Gordon
and Gargantini, Angelo",
title="Testing First-Order Logic Axioms in Program Verification",
booktitle="Tests and Proofs",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="22--37",
abstract="Program verification systems based on automated theorem provers rely on user-provided axioms in order to verify domain-specific properties of code. However, formulating axioms correctly (that is, formalizing properties of an intended mathematical interpretation) is non-trivial in practice, and avoiding or even detecting unsoundness can sometimes be difficult to achieve. Moreover, speculating soundness of axioms based on the output of the provers themselves is not easy since they do not typically give counterexamples. We adopt the idea of model-based testing to aid axiom authors in discovering errors in axiomatizations. To test the validity of axioms, users define a computational model of the axiomatized logic by giving interpretations to the function symbols and constants in a simple declarative programming language. We have developed an axiom testing framework that helps automate model definition and test generation using off-the-shelf tools for meta-programming, property-based random testing, and constraint solving. We have experimented with our tool to test the axioms used in AutoCert, a program verification system that has been applied to verify aerospace flight code using a first-order axiomatization of navigational concepts, and were able to find counterexamples for a number of axioms.",
isbn="978-3-642-13977-2"
}


@InProceedings{10.1007/978-3-319-06410-9_34,
author="Nistor, Ligia
and Aldrich, Jonathan
and Balzer, Stephanie
and Mehnert, Hannes",
editor="Jones, Cliff
and Pihlajasaari, Pekka
and Sun, Jun",
title="Object Propositions",
booktitle="FM 2014: Formal Methods",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="497--513",
abstract="The presence of aliasing makes modular verification of object-oriented code difficult. If multiple clients depend on the properties of an object, one client may break a property that others depend on.",
isbn="978-3-319-06410-9"
}


@InProceedings{10.1007/3-540-61487-7_22,
author="Taura, Kenjiro
and Yonezawa, Akinori",
editor="Briot, Jean-Pierre
and Geib, Jean-Marc
and Yonezawa, Akinori",
title="Schematic: A concurrent object-oriented extension to Scheme",
booktitle="Object-Based Parallel and Distributed Computation",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="59--82",
abstract="A concurrent object-oriented extension to the programming language Scheme, called Schematic, is described. Schematic supports familiar constructs often used in typical parallel programs (future and higher-level macros such as plet and pbegin), which are actually defined atop a very small number of fundamental primitives. In this way, Schematic achieves both the convenience for typical concurrent programming and simplicity and flexibility of the language kernel. Schematic also supports concurrent objects which exhibit more natural and intuitive behavior than the ``bare'' (unprotected) shared memory, and permit intra-object concurrency. Schematic will be useful for intensive parallel applications on parallel machines or networks of workstations, concurrent graphical user interface programming, distributed programming over network, and even concurrent shell programming.",
isbn="978-3-540-68672-9"
}


@InProceedings{10.1007/978-3-319-09156-3_42,
author="Car{\c{c}}{\~a}o, Tiago
and Martins, Pedro",
editor="Murgante, Beniamino
and Misra, Sanjay
and Rocha, Ana Maria A. C.
and Torre, Carmelo
and Rocha, Jorge Gustavo
and Falc{\~a}o, Maria Irene
and Taniar, David
and Apduhan, Bernady O.
and Gervasi, Osvaldo",
title="A Visual DSL for the Certification of Open Source Software",
booktitle="Computational Science and Its Applications -- ICCSA 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="602--617",
abstract="Quality assessment of open source software is becoming an important and active research area. One of the reasons for this recent interest is the consequence of Internet popularity. Nowadays, programming also involves looking for the large set of open source libraries and tools that may be reused when developing our software applications. In order to reuse such open source software artifacts, programmers not only need the guarantee that the reused artifact is certified, but also that independently developed artifacts can be easily combined into a coherent piece of software.",
isbn="978-3-319-09156-3"
}


@InProceedings{10.1007/978-3-540-89330-1_21,
author="Sridhar, Swaroop
and Shapiro, Jonathan S.
and Smith, Scott F.",
editor="Ramalingam, G.",
title="Sound and Complete Type Inference for a Systems Programming Language",
booktitle="Programming Languages and Systems",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="290--306",
abstract="This paper introduces a new type system designed for safe systems programming. The type system features a new mutability model that combines unboxed types with a consistent typing of mutability. The type system is provably sound, supports polymorphism, and eliminates the need for alias analysis to determine the immutability of a location. A sound and complete type inference algorithm for this system is presented.",
isbn="978-3-540-89330-1"
}


@InProceedings{10.1007/3-540-47910-4_8,
author="Liskov, Barbara
and Wing, Jeannette M.",
editor="Nierstrasz, Oscar M.",
title="A New Definition of the Subtype Relation",
booktitle="ECOOP' 93 --- Object-Oriented Programming",
year="1993",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="118--141",
abstract="The use of hierarchy is an important component of object-oriented design. Hierarchy allows the use of type families, in which higher level supertypes capture the behavior that all of their subtypes have in common. For this methodology to be effective, it is necessary to have a clear understanding of how subtypes and supertypes are related. This paper presents a new definition of the subtype relation that ensures that any property proved about supertype objects also holds for subtype objects. It also discusses the ramifications of the definition on the design of type families.",
isbn="978-3-540-47910-9"
}


@InProceedings{10.1007/978-3-319-54072-6_2,
author="Hinze, Thomas",
editor="Leporati, Alberto
and Rozenberg, Grzegorz
and Salomaa, Arto
and Zandron, Claudio",
title="Coping with Dynamical Structures for Interdisciplinary Applications of Membrane Computing",
booktitle="Membrane Computing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="16--27",
abstract="Biological information processing and maintenance of life mainly utilise dynamical structures at different levels from a nanoscopic up to a macroscopic scale. Providing a high degree of reliability, reproducibility, unambiguousness, and addressability, underlying compositional processes appear as ideal candidates to perform computational tasks in a discretised manner. In this essay, we consider four levels in which dynamical structures enable an efficient handling with information: (1) the molecular level, (2) the level of reaction network modules, (3) the level of membranes, and (4) the level of higher-order organisms and populations. All of them have in common the capability of controlled memory-based state transitions and hence dedicated systems's configurations encoding behavioural patterns. Due to its discrete algebraic nature, membrane systems represent advantageous frameworks in order to formalise corresponding activities. This in turn paves the way towards efficient tools inspired by nature with manifold smart applications in engineering, computer science, and systems biology. We illustrate membrane system's abilities, benefits, and progress for coping with dynamical structures from an integrative perspective.",
isbn="978-3-319-54072-6"
}


@InProceedings{10.1007/978-3-540-87700-4_1,
author="Arnold, Dirk V.
and Brauer, Daniel",
editor="Rudolph, G{\"u}nter
and Jansen, Thomas
and Beume, Nicola
and Lucas, Simon
and Poloni, Carlo",
title="On the Behaviour of the (1+1)-ES for a Simple Constrained Problem",
booktitle="Parallel Problem Solving from Nature -- PPSN X",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--10",
abstract="This paper studies the behaviour of the (1{\thinspace}+{\thinspace}1)-ES when applied to a linear problem with a single linear constraint. It goes beyond previous work by considering constraint planes that do not contain the gradient direction. The behaviour of the distance of the search point from the constraint plane forms a Markov chain. The limit distribution of that chain is approximated using an exponential model, and progress rates and success probabilities are derived. Consequences for the working of step length adaptation mechanisms based on success probabilities are discussed.",
isbn="978-3-540-87700-4"
}


@Inbook{Michalewicz1996,
author="Michalewicz, Zbigniew",
title="Introduction",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--10",
abstract="During the last thirty years there has been a growing interest in problem solving systems based on principles of evolution and hereditary: such systems maintain a population of potential solutions, they have some selection process based on fitness of individuals, and some ``genetic'' operators. One type of such systems is a class of Evolution Strategies i.e., algorithms which imitate the principles of natural evolution for parameter optimization problems [319, 348] (Rechenberg, Schwefel). Fogel's Evolutionary Programming [126] is a technique for searching through a space of small finite-state machines Glover's Scatter Search techniques [142] maintain a population of reference points and generate offspring by weighted linear combinations. Another type of evolution based systems are Holland's Genetic Algorithms (GAs) [188]. In 1990, Koza [231] proposed an evolution based systems, Genetic Programming, to search for the most fit computer program to solve a particular problem.",
isbn="978-3-662-03315-9",
doi="10.1007/978-3-662-03315-9_1",
url="https://doi.org/10.1007/978-3-662-03315-9_1"
}


@InProceedings{10.1007/978-3-540-88192-6_25,
author="Sureka, Ashish
and Indukuri, Kishore Varma",
editor="Tang, Changjie
and Ling, Charles X.
and Zhou, Xiaofang
and Cercone, Nick J.
and Li, Xue",
title="Using Genetic Algorithms for Parameter Optimization in Building Predictive Data Mining Models",
booktitle="Advanced Data Mining and Applications",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="260--271",
abstract="We present an application of genetic algorithms to search the space of model building parameters for optimizing the score function or accuracy of a predictive data mining model. The goal of predictive modeling is to build a classification or regression model that can accurately predict the value of a target column by observing the values of the input attributes. The process of finding an optimal algorithm and its control parameters for building a predictive model is a non-trivial process because of two reasons. The first reason is that the number of classification algorithms and its control parameters are very large. The second reason is that it can be quite time consuming to build a model for datasets containing a large number of records and attributes. These two reasons makes it impractical to enumerate through every algorithm and its possible control parameters for finding an optimal model. Genetic Algorithms are adaptive heuristic search algorithm and have been successfully applied to solve optimization problems in diverse domains. In this work, we formulate the problem of finding optimal predictive model building parameter as an optimization problem and examine the usefulness of genetic algorithms. We perform experiments on several datasets and report empirical results to show the applicability of genetic algorithms to the problem of finding optimal predictive model building parameters.",
isbn="978-3-540-88192-6"
}


@Inbook{Michalewicz1994,
author="Michalewicz, Zbigniew",
title="Introduction",
bookTitle="Genetic Algorithms + Data Structures = Evolution Programs",
year="1994",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--10",
abstract="During the last thirty years there has been a growing interest in problem solving systems based on principles of evolution and hereditary: such systems maintain a population of potential solutions, they have some selection process based on fitness of individuals, and some ``genetic'' operators. One type of such systems is a class of Evolution Strategies i.e., algorithms which imitate the principles of natural evolution for parameter optimization problems [239], [263] (Rechenberg, Schwefel). Fogel's Evolutionary Programming [93] is a technique for searching through a space of small finite-state machines. Glover's Scatter Search techniques [105] maintain a population of reference points and generate offspring by weighted linear combinations. Another type of evolution based systems are Holland's Genetic Algorithms (GAs) [142]. In 1990, Koza [172] proposed an evolution based systems, Genetic Programming, to search for the most fit computer program to solve a particular problem.",
isbn="978-3-662-07418-3",
doi="10.1007/978-3-662-07418-3_1",
url="https://doi.org/10.1007/978-3-662-07418-3_1"
}


@Inbook{Dietl2013,
author="Dietl, Werner
and M{\"u}ller, Peter",
editor="Clarke, Dave
and Noble, James
and Wrigstad, Tobias",
title="Object Ownership in Program Verification",
bookTitle="Aliasing in Object-Oriented Programming. Types, Analysis and Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="289--318",
abstract="Dealing with aliasing is one of the key challenges for the verification of imperative programs. For instance, aliases make it difficult to determine which abstractions are potentially affected by a heap update and to determine which locks need to be acquired to avoid data races. Object ownership was one of the first approaches that allowed programmers to control aliasing and to restrict the operations that can be applied to a reference. It thus enabled sound, modular, and automatic verification of heap-manipulating programs. In this paper, we present two ownership systems that have been designed specifically to support program verification---Universe Types and Spec{\#}'s Dynamic Ownership---and explain their applications in program verification, illustrated through a series of Spec{\#} examples.",
isbn="978-3-642-36946-9",
doi="10.1007/978-3-642-36946-9_11",
url="https://doi.org/10.1007/978-3-642-36946-9_11"
}


@InProceedings{10.1007/978-3-540-78499-9_27,
author="Kikuchi, Kentaro
and Lengrand, St{\'e}phane",
editor="Amadio, Roberto",
title="Strong Normalisation of Cut-Elimination That Simulates $\beta$-Reduction",
booktitle="Foundations of Software Science and Computational Structures",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="380--394",
abstract="This paper is concerned with strong normalisation of cut-elimination for a standard intuitionistic sequent calculus. The cut- elimination procedure is based on a rewrite system for proof-terms with cut-permutation rules allowing the simulation of $\beta$-reduction. Strong normalisation of the typed terms is inferred from that of the simply-typed $\lambda$-calculus, using the notions of safe and minimal reductions as well as a simulation in Nederpelt-Klop's $\lambda$I-calculus. It is also shown that the type-free terms enjoy the preservation of strong normalisation (PSN) property with respect to $\beta$-reduction in an isomorphic image of the type-free $\lambda$-calculus.",
isbn="978-3-540-78499-9"
}


@Inbook{Bocchino2013,
author="Bocchino, Robert L.",
editor="Clarke, Dave
and Noble, James
and Wrigstad, Tobias",
title="Alias Control for Deterministic Parallelism",
bookTitle="Aliasing in Object-Oriented Programming. Types, Analysis and Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="156--195",
abstract="A parallel program is deterministic if it produces the same output on every execution with a given input, regardless of the parallel schedule chosen. Determinism makes parallel programs much easier to write, understand, debug, and maintain. Further, many parallel programs are intended to be deterministic. Therefore a deterministic programming model (i.e., one in which all programs that pass compile-time checking are guaranteed to run deterministically) is attractive. However, aliasing poses difficulties for such a model, because hidden read-write conflicts through shared memory can cause unwanted nondeterminism and even data races. This article surveys the state of the art in program annotations for controlling aliasing in a way that can support a deterministic parallel programming model. It discusses the following techniques: the Deterministic Parallel Java effect system; other effect systems, including systems based on object ownership; permission-based type systems; and annotations based on program logic.",
isbn="978-3-642-36946-9",
doi="10.1007/978-3-642-36946-9_7",
url="https://doi.org/10.1007/978-3-642-36946-9_7"
}


@InProceedings{10.1007/978-3-319-03756-1_26,
author="Hassanein, Osama
and Sreenatha, G.
and Ray, Tapabrata",
editor="Panigrahi, Bijaya Ketan
and Suganthan, Ponnuthurai Nagaratnam
and Das, Swagatam
and Dash, Shubhransu Sekhar",
title="Hybrid Neuro-Fuzzy Network Identification for Autonomous Underwater Vehicles",
booktitle="Swarm, Evolutionary, and Memetic Computing",
year="2013",
publisher="Springer International Publishing",
address="Cham",
pages="287--297",
abstract="Autonomous Underwater Vehicles (AUVs) are ideal platforms for aquatic search and rescue operations and exploration. The AUV poses serious challenges due to its complex, inherently nonlinear and time-varying dynamics. In addition, its hydrodynamic coefficients are difficult to model accurately because of their variations under different navigational conditions and manoeuvring in uncertain environments. This paper introduces an identifier scheme for identification of non-linear systems with disturbances based on Hybrid Neuro-Fuzzy Network (HNFN) technique. The method comprises of an automatic structure-generating phase using entropy based technique. The accuracy of the model is suitably controlled using the entropy measure. To improve the accuracy and also for generalization of the model to handle different data sets, Differential Evolution technique (DE) is employed. Finally, Hardware In-Loop (HIL) simulation and real-time experiments using the proposed algorithm to identify the 6-DOF UNSW Canberra AUV's dynamics are implemented. The modelling performance and generalisation capability are seen to be superior with our method.",
isbn="978-3-319-03756-1"
}


@InProceedings{10.1007/3-540-61142-8_675,
author="Rebaudengo, Maurizio
and Reorda, Matteo Sonza",
editor="Liddell, Heather
and Colbrook, Adrian
and Hertzberger, Bob
and Sloot, Peter",
title="A cellular genetic algorithm for the Floorplan area optimization problem on a SIMD architecture",
booktitle="High-Performance Computing and Networking",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="987--988",
isbn="978-3-540-49955-8"
}


@InProceedings{10.1007/11901433_22,
author="Marti, Nicolas
and Affeldt, Reynald
and Yonezawa, Akinori",
editor="Liu, Zhiming
and He, Jifeng",
title="Formal Verification of the Heap Manager of an Operating System Using Separation Logic",
booktitle="Formal Methods and Software Engineering",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="400--419",
abstract="In order to ensure memory properties of an operating system, it is important to verify the implementation of its heap manager. In the case of an existing operating system, this is a difficult task because the heap manager is usually written in a low-level language that makes use of pointers, and it is usually not written with verification in mind. In this paper, our main contribution is the formal verification of the heap manager of an existing embedded operating system, namely Topsy. For this purpose, we develop in the Coq proof assistant a library for separation logic, an extension of Hoare logic to deal with pointers. Using this library, we were able to verify the C source code of the Topsy heap manager, and to find and correct bugs.",
isbn="978-3-540-47462-3"
}


@InProceedings{10.1007/11844297_24,
author="Lima, Claudio F.
and Pelikan, Martin
and Sastry, Kumara
and Butz, Martin
and Goldberg, David E.
and Lobo, Fernando G.",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Substructural Neighborhoods for Local Search in the Bayesian Optimization Algorithm",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="232--241",
abstract="This paper studies the utility of using substructural neighborhoods for local search in the Bayesian optimization algorithm (BOA). The probabilistic model of BOA, which automatically identifies important problem substructures, is used to define the structure of the neighborhoods used in local search. Additionally, a surrogate fitness model is considered to evaluate the improvement of the local search steps. The results show that performing substructural local search in BOA significatively reduces the number of generations necessary to converge to optimal solutions and thus provides substantial speedups.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-642-17625-8_21,
author="Rashid, Ahmar
and Khambampati, Anil Kumar
and Kim, Bong Seok
and Liu, Dong
and Kim, Sin
and Kim, Kyung Youn",
editor="Kim, Tai-hoon
and Yau, Stephen S.
and Gervasi, Osvaldo
and Kang, Byeong-Ho
and Stoica, Adrian
and {\'{S}}l{\k{e}}zak, Dominik",
title="A Differential Evolution Based Approach to Estimate the Shape and Size of Complex Shaped Anomalies Using EIT Measurements",
booktitle="Grid and Distributed Computing, Control and Automation",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="206--215",
abstract="EIT image reconstruction is an ill-posed problem, the spatial resolution of the estimated conductivity distribution is usually poor and the external voltage measurements are subject to variable noise. Therefore, EIT conductivity estimation cannot be used in the raw form to correctly estimate the shape and size of complex shaped regional anomalies. An efficient algorithm employing a shape based estimation scheme is needed. The performance of traditional inverse algorithms, such as the Newton Raphson method, used for this purpose is below par and depends upon the initial guess and the gradient of the cost functional. This paper presents the application of differential evolution (DE) algorithm to estimate complex shaped region boundaries, expressed as coefficients of truncated Fourier series, using EIT. DE is a simple yet powerful population-based, heuristic algorithm with the desired features to solve global optimization problems under realistic conditions. The performance of the algorithm has been tested through numerical simulations, comparing its results with that of the traditional modified Newton Raphson (mNR) method.",
isbn="978-3-642-17625-8"
}


@Article{Weise2012,
author="Weise, Thomas
and Chiong, Raymond
and Tang, Ke",
title="Evolutionary Optimization: Pitfalls and Booby Traps",
journal="Journal of Computer Science and Technology",
year="2012",
month="Sep",
day="01",
volume="27",
number="5",
pages="907--936",
abstract="Evolutionary computation (EC), a collective name for a range of metaheuristic black-box optimization algorithms, is one of the fastest-growing areas in computer science. Many manuals and ``how-to''s on the use of different EC methods as well as a variety of free or commercial software libraries are widely available nowadays. However, when one of these methods is applied to a real-world task, there can be many pitfalls and booby traps lurking --- certain aspects of the optimization problem that may lead to unsatisfactory results even if the algorithm appears to be correctly implemented and executed. These include the convergence issues, ruggedness, deceptiveness, and neutrality in the fitness landscape, epistasis, non-separability, noise leading to the need for robustness, as well as dimensionality and scalability issues, among others. In this article, we systematically discuss these related hindrances and present some possible remedies. The goal is to equip practitioners and researchers alike with a clear picture and understanding of what kind of problems can render EC applications unsuccessful and how to avoid them from the start.",
issn="1860-4749",
doi="10.1007/s11390-012-1274-4",
url="https://doi.org/10.1007/s11390-012-1274-4"
}


@Inbook{Juhos2008,
author="Juhos, Istv{\'a}n
and van Hemert, Jano",
editor="Cotta, Carlos
and van Hemert, Jano",
title="Contraction-Based Heuristics to Improve the Efficiency of Algorithms Solving the Graph Colouring Problem",
bookTitle="Recent Advances in Evolutionary Computation for Combinatorial Optimization",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="167--184",
abstract="Graph vertex colouring can be defined in such a way where colour assignments are substituted by vertex contractions. We present various hypergraph representations for the graph colouring problem all based on the approach where vertices are merged into groups. In this paper, we explain this approach and identify three reasons that make it useful. First, generally, this approach provides a potential decrease in computational complexity. Second, it provides a uniform and compact way in which algorithms, be it of a complete or a heuristic nature, can be defined and progress toward a colouring. Last, it opens the way to novel applications that extract information useful to guide algorithms during their search. These approaches can be useful in the design of an algorithm.",
isbn="978-3-540-70807-0",
doi="10.1007/978-3-540-70807-0_11",
url="https://doi.org/10.1007/978-3-540-70807-0_11"
}


@InProceedings{10.1007/978-3-642-15769-1_13,
author="Cherini, Renato
and Rearte, Lucas
and Blanco, Javier",
editor="Cousot, Radhia
and Martel, Matthieu",
title="A Shape Analysis for Non-linear Data Structures",
booktitle="Static Analysis",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="201--217",
abstract="We present a terminating shape analysis based on Separation Logic for programs that manipulate non-linear data structures such as trees and graphs. The analysis automatically calculates concise invariants for loops, with a level of precision depending on the manipulations applied on each program variable. We report experimental results obtained from running a prototype that implements our analysis on a variety of examples.",
isbn="978-3-642-15769-1"
}


@InProceedings{10.1007/978-3-642-15323-5_28,
author="Farnsworth, Michael
and Benkhelifa, Elhadj
and Tiwari, Ashutosh
and Zhu, Meiling",
editor="Tempesti, Gianluca
and Tyrrell, Andy M.
and Miller, Julian F.",
title="A Novel Approach to Multi-level Evolutionary Design Optimization of a MEMS Device",
booktitle="Evolvable Systems: From Biology to Hardware",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="322--334",
abstract="This paper introduces a novel approach to the evolutionary design optimisation of an MEMS bandpass filter, incorporating areas of multi-disciplinary, multi-level and multi-objective design optimisation in the process. In order to demonstrate this approach a comparison is made to previous attempts to design similar bandpass filters, providing comparable results at a significant reduction in functional evaluations. In this endeavour, a circuit equivalent of the MEMS bandpass filter is evolved extrinsically using the SPICE Simulator.",
isbn="978-3-642-15323-5"
}


@InProceedings{10.1007/978-3-662-45234-9_31,
author="Lepper, Markus
and Tranc{\`o}n y Widemann, Baltasar",
editor="Margaria, Tiziana
and Steffen, Bernhard",
title="Rewriting Object Models With Cycles and Nested Collections",
booktitle="Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="445--460",
abstract="Metaprogramming with classical compiler technology is similar to model-based code generation. We discuss a particular tool, umod, that generates complex data model implementations in Java, and a particular aspect of its support for declarative programming: The rewriting of data models in object-oriented style, based on the visitor pattern, with support for arbitrary reference graphs and nested collection-valued fields. We demonstrate that concerns of both compiler theory and model-based development apply, and that the distinction is overshadowed by a general commitment to semantic rigour.",
isbn="978-3-662-45234-9"
}


@InProceedings{10.1007/978-3-642-25379-9_6,
author="Miller, Dale",
editor="Jouannaud, Jean-Pierre
and Shao, Zhong",
title="A Proposal for Broad Spectrum Proof Certificates",
booktitle="Certified Programs and Proofs",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="54--69",
abstract="Recent developments in the theory of focused proof systems provide flexible means for structuring proofs within the sequent calculus. This structuring is organized around the construction of ``macro'' level inference rules based on the ``micro'' inference rules which introduce single logical connectives. After presenting focused proof systems for first-order classical logics (one with and one without fixed points and equality) we illustrate several examples of proof certificates formats that are derived naturally from the structure of such focused proof systems. In principle, a proof certificate contains two parts: the first part describes how macro rules are defined in terms of micro rules and the second part describes a particular proof object using the macro rules. The first part, which is based on the vocabulary of focused proof systems, describes a collection of macro rules that can be used to directly present the structure of proof evidence captured by a particular class of computational logic systems. While such proof certificates can capture a wide variety of proof structures, a proof checker can remain simple since it must only understand the micro-rules and the discipline of focusing. Since proofs and proof certificates are often likely to be large, there must be some flexibility in allowing proof certificates to elide subproofs: as a result, proof checkers will necessarily be required to perform (bounded) proof search in order to reconstruct missing subproofs. Thus, proof checkers will need to do unification and restricted backtracking search.",
isbn="978-3-642-25379-9"
}


@Inbook{Bonchi2008,
author="Bonchi, Filippo
and Buscemi, Maria Grazia
and Ciancia, Vincenzo
and Gadducci, Fabio",
editor="Degano, Pierpaolo
and De Nicola, Rocco
and Meseguer, Jos{\'e}",
title="A Category of Explicit Fusions",
bookTitle="Concurrency, Graphs and Models: Essays Dedicated to Ugo Montanari on the Occasion of His 65th Birthday",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="544--562",
abstract="Name passing calculi are nowadays an established field on its own. Besides their practical relevance, they offered an intriguing challenge, since the standard operational, denotational and logical methods often proved inadequate to reason about these formalisms. A domain which has been successfully employed for languages with asymmetric communication, like the $\pi$-calculus, are presheaf categories based on (injective) relabelings, such as {\$}{\{}Set{\}}^{\backslash}mathbb{\{}I{\}}{\$}. Calculi with symmetric binding, in the spirit of the fusion calculus, give rise to new research problems. In this work we examine the calculus of explicit fusions, and propose to model its syntax and semantics using the presheaf category {\$}{\{}Set{\}}^{\backslash}mathbb{\{}E{\}}{\$}, where {\$}{\backslash}mathbb{\{}E{\}}{\$}is the category of equivalence relations and equivalence preserving morphisms.",
isbn="978-3-540-68679-8",
doi="10.1007/978-3-540-68679-8_34",
url="https://doi.org/10.1007/978-3-540-68679-8_34"
}


@InProceedings{10.1007/978-3-662-49665-7_6,
author="Semer{\'a}th, Oszk{\'a}r
and V{\"o}r{\"o}s, Andr{\'a}s
and Varr{\'o}, D{\'a}niel",
editor="Stevens, Perdita
and W{\k{a}}sowski, Andrzej",
title="Iterative and Incremental Model Generation by Logic Solvers",
booktitle="Fundamental Approaches to Software Engineering",
year="2016",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="87--103",
abstract="The generation of sample instance models of Domain-Specific Language (DSL) specifications has become an active research line due to its increasing industrial relevance for engineering complex modeling tools by using large metamodels and complex well-formedness constraints. However, the synthesis of large, well-formed and realistic models is still a major challenge. In this paper, we propose an iterative process for generating valid instance models by calling existing logic solvers as black-box components using various approximations of metamodels and constraints to improve overall scalability. (1) First, we apply enhanced metamodel pruning and partial instance models to reduce the complexity of model generation subtasks and the retrieved partial solutions initiated in each step. (2) Then we propose an (over-)approximation technique for well-formedness constraints in order to interpret and evaluate them on partial (pruned) metamodels. (3) Finally, we define a workflow that incrementally generates a sequence of instance models by refining and extending partial models in multiple steps, where each step is an independent call to the underlying solver (the Alloy Analyzer in our experiments).",
isbn="978-3-662-49665-7"
}


@InProceedings{10.1007/978-3-642-41582-1_2,
author="Dieterle, Mischa
and Horstmeyer, Thomas
and Berthold, Jost
and Loogen, Rita",
editor="Hinze, Ralf",
title="Iterating Skeletons",
booktitle="Implementation and Application of Functional Languages",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="18--36",
abstract="Algorithmic skeletons are higher-order functions which provide tools for parallel programming at a higher abstraction level, hiding the technical details of parallel execution inside the skeleton implementation. However, this encapsulation becomes an obstacle when the actual algorithm is one that involves iterative application of the same skeleton to successively improve or approximate the result. Striving for a general and portable solution, we propose a skeleton iteration framework in which arbitrary skeletons can be embedded with only minor modifications. The framework is flexible and allows for various parallel iteration control and parallel iteration body variants. We have implemented it in the parallel Haskell dialect Eden using dedicated stream communication types for the iteration. Two non-trivial case studies show the practicality of our approach. The performance of our compositional iteration framework is competitive with customised iteration skeletons.",
isbn="978-3-642-41582-1"
}


@InProceedings{10.1007/978-3-662-54434-1_10,
author="Chargu{\'e}raud, Arthur
and Pottier, Fran{\c{c}}ois",
editor="Yang, Hongseok",
title="Temporary Read-Only Permissions for Separation Logic",
booktitle="Programming Languages and Systems",
year="2017",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="260--286",
abstract="We present an extension of Separation Logic with a general mechanism for temporarily converting any assertion (or ``permission'') to a read-only form. No accounting is required: our read-only permissions can be freely duplicated and discarded. We argue that, in circumstances where mutable data structures are temporarily accessed only for reading, our read-only permissions enable more concise specifications and proofs. The metatheory of our proposal is verified in Coq.",
isbn="978-3-662-54434-1"
}


@InProceedings{10.1007/978-3-642-32759-9_18,
author="Giorgino, Mathieu
and Strecker, Martin",
editor="Giannakopoulou, Dimitra
and M{\'e}ry, Dominique",
title="Correctness of Pointer Manipulating Algorithms Illustrated by a Verified BDD Construction",
booktitle="FM 2012: Formal Methods",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="202--216",
abstract="This paper is an extended case study using a high-level approach to the verification of graph transformation algorithms: To represent sharing, graphs are considered as trees with additional pointers, and algorithms manipulating them are essentially primitive recursive traversals written in a monadic style. With this, we achieve almost trivial termination arguments and can use inductive reasoning principles for showing the correctness of the algorithms. We illustrate the approach with the verification of a BDD package which is modular in that it can be instantiated with different implementations of association tables for node lookup. We have also implemented a garbage collector for freeing association tables from unused entries. Even without low-level optimizations, the resulting implementation is reasonably efficient.",
isbn="978-3-642-32759-9"
}


@Inbook{Clarke2013,
author="Clarke, Dave
and {\"O}stlund, Johan
and Sergey, Ilya
and Wrigstad, Tobias",
editor="Clarke, Dave
and Noble, James
and Wrigstad, Tobias",
title="Ownership Types: A Survey",
bookTitle="Aliasing in Object-Oriented Programming. Types, Analysis and Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="15--58",
abstract="Ownership types were devised nearly 15 years ago to provide a stronger notion of protection to object-oriented programming languages. Rather than simply protecting the fields of an object from external access, ownership types protect also the objects stored in the fields, thereby enabling an object to claim (exclusive) ownership of and access to other objects. Furthermore, this notion is statically enforced by now-standard type-checking techniques.",
isbn="978-3-642-36946-9",
doi="10.1007/978-3-642-36946-9_3",
url="https://doi.org/10.1007/978-3-642-36946-9_3"
}


@InProceedings{10.1007/978-3-540-79124-9_5,
author="Claessen, Koen
and Svensson, Hans",
editor="Beckert, Bernhard
and H{\"a}hnle, Reiner",
title="Finding Counter Examples in Induction Proofs ",
booktitle="Tests and Proofs",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="48--65",
abstract="This paper addresses a problem arising in automated proof of invariants of transition systems, for example transition systems modelling distributed programs. Most of the time, the actual properties we want to prove are too weak to hold inductively, and auxiliary invariants need to be introduced. The problem is how to find these extra invariants. We propose a method where we find minimal counter examples to candidate invariants by means of automated random testing techniques. These counter examples can be inspected by a human user, and used to adapt the set of invariants at hand. We are able to find two different kinds of counter examples, either indicating (1) that the used invariants are too strong (a concrete trace of the system violates at least one of the invariants), or (2) that the used invariants are too weak (a concrete transition of the system does not maintain all invariants). We have developed and evaluated our method in the context of formally verifying an industrial-strength implementation of a fault-tolerant distributed leader election protocol.",
isbn="978-3-540-79124-9"
}


@InProceedings{10.1007/978-3-319-46433-6_2,
author="Horv{\'a}th, Ill{\'e}s
and S{\'a}f{\'a}r, Orsolya
and Telek, Mikl{\'o}s
and Z{\'a}mb{\'o}, Bence",
editor="Fiems, Dieter
and Paolieri, Marco
and Platis, Agapios N.",
title="Concentrated Matrix Exponential Distributions",
booktitle="Computer Performance Engineering",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="18--31",
abstract="We revisit earlier attempts for finding matrix exponential (ME) distributions of a given order with low coefficient of variation ({\$}{\$}{\backslash}hbox {\{}cv{\}}{\$}{\$}). While there is a long standing conjecture that for the first non-trivial order, which is order 3, the {\$}{\$}{\backslash}hbox {\{}cv{\}}{\$}{\$}cannot be less than 0.200902 but the proof of this conjecture is still missing.",
isbn="978-3-319-46433-6"
}


@InProceedings{10.1007/978-3-642-24690-6_10,
author="Crespo, Juan Manuel
and Kunz, C{\'e}sar",
editor="Barthe, Gilles
and Pardo, Alberto
and Schneider, Gerardo",
title="A Machine-Checked Framework for Relational Separation Logic",
booktitle="Software Engineering and Formal Methods",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="122--137",
abstract="Relational methods are gaining growing acceptance for specifying and verifying properties defined in terms of the execution of two programs---notions such as simulation, observational equivalence, non-interference, and continuity can be elegantly cast in this setting. In previous work, we have proposed program product construction as a technique to reduce relational verification to standard verification. This method hinges on the ability to interpret relational assertions as traditional predicates, which becomes problematic when considering assertions from relational separation logic. We report in this article an alternative method that overcomes this difficulty, defined as a relational weakest precondition calculus based on separation logic and formalized in the Coq proof assistant. The formalization includes an application to the formal verification of the Schorr-Waite graph marking algorithm. We discuss additional variants of relational separation logic inspired by the standard notions of partial and total correctness, and extensions of the logic to handle non-structurally equivalent programs.",
isbn="978-3-642-24690-6"
}


@InProceedings{10.1007/978-3-642-04441-0_21,
author="Singh, Vivek Kumar
and Gautam, Divya
and Singh, Rishi Raj
and Gupta, Ashok K.",
editor="Nguyen, Ngoc Thanh
and Kowalczyk, Ryszard
and Chen, Shyi-Ming",
title="Agent-Based Computational Modeling of Emergent Collective Intelligence",
booktitle="Computational Collective Intelligence. Semantic Web, Social Networks and Multiagent Systems",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="240--251",
abstract="Collective Intelligence is a form of intelligence which emerges out of collaboration and coordination of many individual agents. A group of actors performing simple behaviours and interacting with fellow group members {\&} the environment often produce global behaviours which seems intelligent. Understanding the emergence of intelligent collective behaviours in social systems, such as norms {\&} conventions, higher level organizations, collective wisdom and evolution of culture from simple and predictable local interactions; has been an important research question since decades. Agent-based modeling of complex social behaviours by simulating social units as agents and modeling their interactions; provides a new generative approach to understanding the dynamics of emergence of collective intelligence behaviours. In this paper, we have presented an analytical account of nature, form and dynamics of collective intelligence, followed by some of our experimental work on evolution of collective intelligence. The paper concludes with a short discussion of the results and relevant implications for designing systems for achieving desired collective intelligence.",
isbn="978-3-642-04441-0"
}


@InProceedings{10.1007/978-3-540-89674-6_19,
author="Fujita, Katsuhide
and Ito, Takayuki
and Klein, Mark",
editor="Bui, The Duy
and Ho, Tuong Vinh
and Ha, Quang Thuy",
title="Preliminary Result on Secure Protocols for Multiple Issue Negotiation Problems",
booktitle="Intelligent Agents and Multi-Agent Systems",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="161--172",
abstract="Multi-issue negotiation protocols represent a promising field since most negotiation problems in the real world involve multiple issues. Our work focuses on negotiation with multiple interdependent issues in which agent utility functions are nonlinear. Existing works have not yet concerned with agents' private information that should be concealed from others in negotiations. In this paper, we propose Distributed Mediator Protocol and Take it or Leave it Protocol for negotiation that can reach agreements and protect agents' private information. Moreover, we propose Hybrid Secure Protocol that combines Distributed Mediator Protocol with Take it or Leave it Protocol. The Hybrid Secure Protocol can also reach agreements while completely concealing agents' private information. Furthermore, the Hybrid Secure Protocol achieves high optimality and uses less memory.",
isbn="978-3-540-89674-6"
}


@InProceedings{10.1007/BFb0053046,
author="Jagannathan, Suresh
and Agha, Gul",
editor="Madsen, Ole Lehrmann",
title="A reflective model of inheritance",
booktitle="ECOOP '92 European Conference on Object-Oriented Programming",
year="1992",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="350--371",
isbn="978-3-540-47268-1"
}


@InProceedings{10.1007/978-3-642-22863-6_22,
author="Norrish, Michael",
editor="van Eekelen, Marko
and Geuvers, Herman
and Schmaltz, Julien
and Wiedijk, Freek",
title="Mechanised Computability Theory",
booktitle="Interactive Theorem Proving",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="297--311",
abstract="This paper presents a mechanisation of some basic computability theory. The mechanisation uses two models: the recursive functions and the $\lambda$-calculus, and shows that they have equivalent computational power. Results proved include the Recursion Theorem, an instance of the s-m-n theorem, the existence of a universal machine, Rice's Theorem, and closure facts about the recursive and recursively enumerable sets. The mechanisation was performed in the HOL4 system and is available online.",
isbn="978-3-642-22863-6"
}


@InProceedings{10.1007/3-540-45614-7_14,
author="Marinov, Darko
and Khurshid, Sarfraz",
editor="Eriksson, Lars-Henrik
and Lindsay, Peter Alexander",
title="VAlloy --- Virtual Functions Meet a Relational Language",
booktitle="FME 2002:Formal Methods---Getting IT Right",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="234--251",
abstract="We propose VAlloy, a veneer onto the first order, relational language Alloy. Alloy is suitable for modeling structural properties of object-oriented software. However, Alloy lacks support for dynamic dispatch, i.e., function invocation based on actual parameter types. VAlloy introduces virtual functions in Alloy, which enables intuitive modeling of inheritance. Models in VAlloy are automatically translated into Alloy and can be automatically checked using the existing Alloy Analyzer. We illustrate the use of VAlloy by modeling object equality, such as in Java. We also give specifications for a part of the Java Collections Framework.",
isbn="978-3-540-45614-8"
}


@InProceedings{10.1007/978-3-540-30217-9_13,
author="Skinner, Cameron
and Riddle, Patricia",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="Expected Rates of Building Block Discovery, Retention and Combination Under 1-Point and Uniform Crossover",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="121--130",
abstract="Choosing the right crossover operator for the problem at hand is a difficult problem. We describe an experiment that shows a surprising result when comparing 1-point and uniform crossover on the Royal Road problem and derive equations for calculating the expected rates of building block discovery, retention and combination. These equations provide an explanation for the surprising results and suggest several directions for future research into hybrid operators.",
isbn="978-3-540-30217-9"
}


@InProceedings{10.1007/11844297_5,
author="Li, Rui
and Emmerich, Michael T. M.
and Eggermont, Jeroen
and Bovenkamp, Ernst G. P.
and B{\"a}ck, Thomas
and Dijkstra, Jouke
and Reiber, Johan H. C.",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Mixed-Integer NK Landscapes",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="42--51",
abstract="NK landscapes (NKL) are stochastically generated pseudo-boolean functions with N bits (genes) and K interactions between genes. By means of the parameter K ruggedness as well as the epistasis can be controlled. NKL are particularly useful to understand the dynamics of evolutionary search. We extend NKL from the traditional binary case to a mixed variable case with continuous, nominal discrete, and integer variables. The resulting test function generator is a suitable test model for mixed-integer evolutionary algorithms (MI-EA) -- i. e. instantiations of evolution algorithms that can deal with the aforementioned variable types. We provide a comprehensive introduction to mixed-integer NKL and characteristics of the model (global/local optima, computation, etc.). Finally, a first study of the performance of mixed-integer evolution strategies on this problem family is provided, the results of which underpin its applicability for optimization algorithm design.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-642-15651-9_16,
author="Svenningsson, Rickard
and Vinter, Jonny
and Eriksson, Henrik
and T{\"o}rngren, Martin",
editor="Schoitsch, Erwin",
title="MODIFI: A MODel-Implemented Fault Injection Tool",
booktitle="Computer Safety, Reliability, and Security",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="210--222",
abstract="Fault injection is traditionally divided into simulation-based and physical techniques depending on whether faults are injected into hardware models, or into an actual physical system or prototype. Another classification is based on how fault injection mechanisms are implemented. Well known techniques are hardware-implemented fault injection (HIFI) and software-implemented fault injection (SWIFI). For safety analyses during model-based development, fault injection mechanisms can be added directly into models of hardware, models of software or models of systems. This approach is denoted by the authors as model-implemented fault injection. This paper presents the MODIFI (MODel-Implemented Fault Injection) tool. The tool is currently targeting behaviour models in Simulink. Fault models used by MODIFI are defined using XML according to a specific schema file and the fault injection algorithm uses the concept of minimal cut sets (MCS) generation. First, a user defined set of single faults are injected to see if the system is tolerant against single faults. Single faults leading to a failure, i.e. a safety requirement violation, are stored in a MCS list together with the corresponding counterexample. These faults are also removed from the fault space used for subsequent experiments. When all single faults have been injected, the effects of multiple faults are investigated, i.e. two or more faults are introduced at the same time. The complete list of MCS is finally used to automatically generate test cases for efficient fault injection on the target system.",
isbn="978-3-642-15651-9"
}


@InProceedings{10.1007/978-3-642-18345-4_5,
author="Stonedahl, Forrest
and Wilensky, Uri",
editor="Bosse, Tibor
and Geller, Armando
and Jonker, Catholijn M.",
title="Finding Forms of Flocking: Evolutionary Search in ABM Parameter-Spaces",
booktitle="Multi-Agent-Based Simulation XI",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="61--75",
abstract="While agent-based models (ABMs) are becoming increasingly popular for simulating complex and emergent phenomena in many fields, understanding and analyzing ABMs poses considerable challenges. ABM behavior often depends on many model parameters, and the task of exploring a model's parameter space and discovering the impact of different parameter settings can be difficult and time-consuming. Exhaustively running the model with all combinations of parameter settings is generally infeasible, but judging behavior by varying one parameter at a time risks overlooking complex nonlinear interactions between parameters. Alternatively, we present a case study in computer-aided model exploration, demonstrating how evolutionary search algorithms can be used to probe for several qualitative behaviors (convergence, non-convergence, volatility, and the formation of vee shapes) in two different flocking models. We also introduce a new software tool (BehaviorSearch) for performing parameter search on ABMs created in the NetLogo modeling environment.",
isbn="978-3-642-18345-4"
}


@InProceedings{10.1007/978-3-540-73066-8_1,
author="Huima, Antti",
editor="Petrenko, Alexandre
and Veanes, Margus
and Tretmans, Jan
and Grieskamp, Wolfgang",
title="Implementing Conformiq Qtronic ",
booktitle="Testing of Software and Communicating Systems",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--12",
abstract="Conformiq Qtronic is a commercial tool for model driven testing. It derives tests automatically from behavioral system models. These are black-box tests [1] by nature, which means that they depend on the model and the interfaces of the system under test, but not on the internal structure (e.g. source code) of the implementation.",
isbn="978-3-540-73066-8"
}


@InProceedings{10.1007/978-3-540-31862-0_19,
author="Dan, Li
and Aichernig, Bernhard K.",
editor="Liu, Zhiming
and Araki, Keijiro",
title="Combining Algebraic and Model-Based Test Case Generation",
booktitle="Theoretical Aspects of Computing - ICTAC 2004",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="250--264",
abstract="The classical work on test case generation and formal methods focuses either on algebraic or model-based specifications. In this paper we propose an approach to derive test cases in the RAISE method whose specification language RSL combines the model-based and algebraic style. Our approach integrates the testing techniques of algebraic specifications and model-based specifications. In this testing strategy, first, every function definition is partitioned by Disjunctive Normal Form (DNF) rewriting and then test arguments are generated. Next, sequences of function calls are formed. Finally, the test cases are built by replacing the variables, on both sides of the axioms, with the sequences of functions calls. These kinds of test cases not only provide the data for testing, but also serve as test oracles. Based on this combined approach, a test case generation tool has been developed.",
isbn="978-3-540-31862-0"
}


@InProceedings{10.1007/978-3-642-15769-1_14,
author="Dalla Preda, Mila
and Giacobazzi, Roberto
and Debray, Saumya
and Coogan, Kevin
and Townsend, Gregg M.",
editor="Cousot, Radhia
and Martel, Matthieu",
title="Modelling Metamorphism by Abstract Interpretation",
booktitle="Static Analysis",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="218--235",
abstract="Metamorphic malware apply semantics-preserving transformations to their own code in order to foil detection systems based on signature matching. In this paper we consider the problem of automatically extract metamorphic signatures from these malware. We introduce a semantics for self-modifying code, later called phase semantics, and prove its correctness by showing that it is an abstract interpretation of the standard trace semantics. Phase semantics precisely models the metamorphic code behavior by providing a set of traces of programs which correspond to the possible evolutions of the metamorphic code during execution. We show that metamorphic signatures can be automatically extracted by abstract interpretation of the phase semantics, and that regular metamorphism can be modelled as finite state automata abstraction of the phase semantics.",
isbn="978-3-642-15769-1"
}


@InProceedings{10.1007/978-3-319-22183-0_22,
author="Jia, Yue
and Harman, Mark
and Langdon, William B.
and Marginean, Alexandru",
editor="Barros, M{\'a}rcio
and Labiche, Yvan",
title="Grow and Serve: Growing Django Citation Services Using SBSE",
booktitle="Search-Based Software Engineering",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="269--275",
abstract="We introduce a `grow and serve' approach to Genetic Improvement (GI) that grows new functionality as a web service running on the Django platform. Using our approach, we successfully grew and released a citation web service. This web service can be invoked by existing applications to introduce a new citation counting feature. We demonstrate that GI can grow genuinely useful code in this way, so we deployed the SBSE-grown web service into widely-used publications repositories, such as the GP bibliography. In the first 24 hours of deployment alone, the service was used to provide GP bibliography citation data 369 times from 29 countries.",
isbn="978-3-319-22183-0"
}


@InProceedings{10.1007/3-540-49099-X_2,
author="Benedikt, Michael
and Reps, Thomas
and Sagiv, Mooly",
editor="Swierstra, S. Doaitse",
title="A Decidable Logic for Describing Linked Data Structures",
booktitle="Programming Languages and Systems",
year="1999",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="2--19",
abstract="This paper aims to provide a better formalism for describing properties of linked data structures (e.g., lists, trees, graphs), as well as the intermediate states that arise when such structures are destructively updated. The paper defines a new logic that is suitable for these purposes (called Lr, for ``logic of reachability expressions''). We show that Lr is decidable, and explain how Lr relates to two previously defined structuredescription formalisms (``path matrices'' and ``static shape graphs'') by showing how an arbitrary shape descriptor from each of these formalisms can be translated into an Lr formula.",
isbn="978-3-540-49099-9"
}


@InProceedings{10.1007/978-3-540-87700-4_45,
author="Hu, Ting
and Banzhaf, Wolfgang",
editor="Rudolph, G{\"u}nter
and Jansen, Thomas
and Beume, Nicola
and Lucas, Simon
and Poloni, Carlo",
title="Nonsynonymous to Synonymous Substitution Ratio {\$}k{\_}{\{}{\backslash}mathrm a{\}}/k{\_}{\{}{\backslash}mathrm s{\}}{\$}: Measurement for Rate of Evolution in Evolutionary Computation",
booktitle="Parallel Problem Solving from Nature -- PPSN X",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="448--457",
abstract="Measuring fitness progression using numeric quantification in an Evolutionary Computation (EC) system may not be sufficient to capture the rate of evolution precisely. In this paper, we define the rate of evolution {\$}R{\_}{\{}{\backslash}mathrm e{\}}{\$}in an EC system based on the rate of efficient genetic variations being accepted by the EC population. This definition is motivated by the measurement of ``amino acid to synonymous substitution ratio'' {\$}k{\_}{\{}{\backslash}mathrm a{\}}/k{\_}{\{}{\backslash}mathrm s{\}}{\$}in biology, which has been widely accepted to measure the rate of gene sequence evolution. Experimental applications to investigate the effects of four major configuration parameters on our rate of evolution measurement show that {\$}R{\_}{\{}{\backslash}mathrm e{\}}{\$}well reflects how evolution proceeds underneath fitness development and provides some insights into the effectiveness of EC parameters in evolution acceleration.",
isbn="978-3-540-87700-4"
}


@InProceedings{10.1007/978-3-642-23896-3_31,
author="Gao, Wei",
editor="Deng, Hepu
and Miao, Duoqian
and Lei, Jingsheng
and Wang, Fu Lee",
title="Financial Data Forecasting by Evolutionary Neural Network Based on Ant Colony Algorithm",
booktitle="Artificial Intelligence and Computational Intelligence",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="262--269",
abstract="The financial system is generally a very complicated system. So, it is very hard to be predicted. For example, it is a hard work to forecast the stock market. Here, from analyses the mathematic description of stock market system, a new forecasting method based on new evolutionary neural network is proposed here. In this new evolutionary neural network, the traditional BP algorithm and immune continuous ant colony algorithm proposed by author is combined. In order to verify this new prediction method, the stock market data of Shanghai market in 1996 is used. The results show that, our new method is very good to real practice.",
isbn="978-3-642-23896-3"
}


@Article{Batkhin2015,
author="Batkhin, A. B.
and Bruno, A. D.",
title="Investigation of a real algebraic surface",
journal="Programming and Computer Software",
year="2015",
month="Mar",
day="01",
volume="41",
number="2",
pages="74--83",
abstract="A description of a real algebraic variety in ℝ3 is given. This variety plays an important role in the investigation of the Einstein metrics whose evolution is studied using the normalized Ricci flow. To reveal the internal structure of this variety, a description of all its singular points is given. Due to the internal symmetry of this variety, a part of the investigation uses elementary symmetric polynomials. All the computations are performed using computer algebra algorithms (in particular, Gr{\"o}bner bases) and algorithms for dealing with polynomial ideals. As an auxiliary result, a proposition about the structure of the discriminant surface of a cubic polynomial is proved.",
issn="1608-3261",
doi="10.1134/S0361768815020036",
url="https://doi.org/10.1134/S0361768815020036"
}


@InProceedings{10.1007/978-3-540-71618-1_74,
author="Oh, Sung-Kwun
and Lee, In-Tae
and Kim, Hyun-Ki
and Jang, Seong-Whan",
editor="Beliczynski, Bartlomiej
and Dzielinski, Andrzej
and Iwanowski, Marcin
and Ribeiro, Bernardete",
title="Fuzzy Relation-Based PNNs with the Aid of IG and Symbolic Gene Type-Based GAs",
booktitle="Adaptive and Natural Computing Algorithms",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="666--673",
abstract="In this paper, we propose a new design methodology of fuzzy-neural networks -- Fuzzy Relation--based Polynomial Neural Networks (FRPNN) with symbolic genetic algorithms and Information Granules (IG). We have developed a design methodology based on symbolic genetic algorithms to find the optimal structure for fuzzy-neural networks that expanded from Group Method of Data Handling (GMDH). Such parameters as the number of input variables, the order of the polynomial, the number of membership functions, and a collection of the specific subset of input variables are optimized for topology of FRPNN with the aid of symbolic genetic optimization that has search capability to find the optimal solution on the solution space. The augmented and genetically developed FRPNN (gFRPNN) results in a structurally optimized structure and comes with a higher level of flexibility in comparison to the one we encounter in the conventional FRPNNs. The GA-based design procedure being applied at each layer of FRPNN leads to the selection of the most suitable nodes (or FRPNs) available within the FRPNN. The performance of genetically optimized FRPNN (gFRPNN) is quantified through experimentation where we use a number of modeling benchmarks data which are already experimented with in fuzzy or neurofuzzy modeling.",
isbn="978-3-540-71618-1"
}


@InProceedings{10.1007/978-3-642-27337-7_33,
author="Khanli, Leily Mohammad
and Namyar, Sahar",
editor="Pichappan, Pit
and Ahmadi, Hojat
and Ariwa, Ezendu",
title="Advanced Dynamic Bayesian Network Optimization Model Applied in Decomposition Grid Task Scheduling",
booktitle="Innovative Computing Technology",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="346--361",
abstract="This paper uses Bayesian optimization algorithm and decomposition approach for solving task scheduling problem in probabilistic grid computing systems to overcome the efficiency problem since it belongs to NP-complete problems. This paper introduces a Bayesian Optimization model that combines Dynamic Bayesian networks to manage uncertainty and evolutionary algorithms to solve the problem. Dynamic Bayesian networks use because the performance, reliability and cost of resources vary with time simultaneously and their availability is uncertain. This method decomposes the global problem to make the scheduling process simpler and achieve the QoS objectives efficiently. Instead of sending the jobs to the all resources, some local areas of resources with a controller consider and send the jobs to them. With the use of GridSim toolkit it will be proven that this model cause to achieve the QoS objectives such as minimizing the cost and time more efficiently.",
isbn="978-3-642-27337-7"
}


@InProceedings{10.1007/978-3-642-16167-4_9,
author="Xiao, Jixian
and Lu, Fangling
and Xiao, Xin",
editor="Zhu, Rongbo
and Zhang, Yanchun
and Liu, Baoxiang
and Liu, Chunfeng",
title="Stochastic Newsboy Inventory Control Model and Its Solving on Multivariate Products Order and Pricing",
booktitle="Information Computing and Applications",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="65--72",
abstract="In this paper based on the traditional stochastic inventory control problem, namely, the Newsboy problem, considered the factor of inventory item which has an impact on the decision-making model, a new model is built up. While assuming the form of demand to meet the adding form, and considering the impact of the price on the demand rate and the impact of the demand rate on inventory item, we discuss a new subscription model, and give corresponding calculation methods to determine the optimal order quantity and optimal sales price. Model in this paper is an extension of existing models, while the known model is a special case of this model. At last an simple example is given.",
isbn="978-3-642-16167-4"
}


@InProceedings{10.1007/978-3-540-87700-4_13,
author="Beyer, Hans-Georg
and Sendhoff, Bernhard",
editor="Rudolph, G{\"u}nter
and Jansen, Thomas
and Beume, Nicola
and Lucas, Simon
and Poloni, Carlo",
title="Covariance Matrix Adaptation Revisited -- The CMSA Evolution Strategy --",
booktitle="Parallel Problem Solving from Nature -- PPSN X",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="123--132",
abstract="The covariance matrix adaptation evolution strategy (CMA-ES) rates among the most successful evolutionary algorithms for continuous parameter optimization. Nevertheless, it is plagued with some drawbacks like the complexity of the adaptation process and the reliance on a number of sophisticatedly constructed strategy parameter formulae for which no or little theoretical substantiation is available. Furthermore, the CMA-ES does not work well for large population sizes. In this paper, we propose an alternative -- simpler -- adaptation step of the covariance matrix which is closer to the ``traditional'' mutative self-adaptation. We compare the newly proposed algorithm, which we term the CMSA-ES, with the CMA-ES on a number of different test functions and are able to demonstrate its superiority in particular for large population sizes.",
isbn="978-3-540-87700-4"
}


@InProceedings{10.1007/978-3-319-42061-5_9,
author="Kessentini, Wael
and Sahraoui, Houari
and Wimmer, Manuel",
editor="W{\k{a}}sowski, Andrzej
and L{\"o}nn, Henrik",
title="Automated Metamodel/Model Co-evolution Using a Multi-objective Optimization Approach",
booktitle="Modelling Foundations and Applications",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="138--155",
abstract="We propose a generic automated approach for the metamodel/model co-evolution. The proposed technique refines an initial model to make it as conformant as possible to the new metamodel version by finding the best compromise between three objectives, namely minimizing (i) the non-conformities with new metamodel version, (ii) the changes to existing models, and (iii) the loss of information. Consequently, we view the co-evolution as a multi-objective optimization problem, and solve it using the NSGA-II algorithm. We successfully validated our approach on the evolution of the well-known UML state machine metamodel. The results confirm the effectiveness of our approach with average precision and recall respectively higher than 87 {\%} and 89 {\%}.",
isbn="978-3-319-42061-5"
}


@InProceedings{10.1007/978-3-642-39521-5_10,
author="Potapov, Alexey
and Rodionov, Sergey",
editor="K{\"u}hnberger, Kai-Uwe
and Rudolph, Sebastian
and Wang, Pei",
title="Universal Induction with Varying Sets of Combinators",
booktitle="Artificial General Intelligence",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="88--97",
abstract="Universal induction is a crucial issue in AGI. Its practical applicability can be achieved by the choice of the reference machine or representation of algorithms agreed with the environment. This machine should be updatable for solving subsequent tasks more efficiently. We study this problem on an example of combinatory logic as the very simple Turing-complete reference machine, which enables modifying program representations by introducing different sets of primitive combinators. Genetic programming system is used to search for combinator expressions, which are easily decomposed into sub-expressions being recombined in crossover. Our experiments show that low-complexity induction or prediction tasks can be solved by the developed system (much more efficiently than using brute force); useful combinators can be revealed and included into the representation simplifying more difficult tasks. However, optimal sets of combinators depend on the specific task, so the reference machine should be adaptively chosen in coordination with the search engine.",
isbn="978-3-642-39521-5"
}


@InProceedings{10.1007/978-3-642-41154-0_23,
author="Liang, Helan
and Du, Yanhua
and Li, Sujian",
editor="Lin, Xuemin
and Manolopoulos, Yannis
and Srivastava, Divesh
and Huang, Guangyan",
title="An Improved Genetic Algorithm for Service Selection under Temporal Constraints in Cloud Computing",
booktitle="Web Information Systems Engineering -- WISE 2013",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="309--318",
abstract="To guarantee the successful execution of service based processes in cloud computing, one important requirement is the QoS-driven selection of candidate services under temporal constraints. In this paper, a new approach based on improved genetic algorithm (HPGA) is proposed where the hamming similarity degree is used to avoid inbreeding and the pheromone strategy is designed with considering not only the individual fitness but also the global information of best chromosomes. Compared with the existing works, this approach is more precise and especially suitable for the service selection of large-scale and complex processes with vast amounts of candidate services.",
isbn="978-3-642-41154-0"
}


@InProceedings{10.1007/978-3-540-87700-4_49,
author="Laredo, Juan L. J.
and Castillo, Pedro A.
and Mora, Antonio M.
and Merelo, Juan J.
and Rosa, Agostinho
and Fernandes, Carlos",
editor="Rudolph, G{\"u}nter
and Jansen, Thomas
and Beume, Nicola
and Lucas, Simon
and Poloni, Carlo",
title="Evolvable Agents in Static and Dynamic Optimization Problems",
booktitle="Parallel Problem Solving from Nature -- PPSN X",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="488--497",
abstract="This paper investigates the behaviour of the Evolvable Agent model (EvAg) in static and dynamic environments. The EvAg is a spatially structured Genetic Algorithm (GA) designed to work on Peer-to-Peer (P2P) systems in which the population structure is a small-world graph built by newscast, a P2P protocol. Additionally to the profits in computing performance, EvAg maintains genetic diversity at the small-world relationships between individuals in a sort of social network. Experiments were conducted in order to assess how EvAg scales on deceptive and non-deceptive trap functions. In addition, the proposal was tested on dynamic environments. The results show that the EvAg scales and adapts better to dynamic environments than a standard GA and an improved version of the well-known Random Immigrants Genetic Algorithm.",
isbn="978-3-540-87700-4"
}


@Inbook{Mohr2016,
author="Mohr, Felix",
title="Template-Based Composition",
bookTitle="Automated Software and Service Composition: A Survey and Evaluating Review",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="23--59",
abstract="Approaches in this class have the property that the desired composition is specified in terms of a (possibly structured) set of tasks to be carried out. That is, the structure of the desired composition is already known in advance at least on an abstract level. The remaining problem is to concretize this structure with respect to some criterion such as optimization of quality or adherence to communication restrictions of existing services.",
isbn="978-3-319-34168-2",
doi="10.1007/978-3-319-34168-2_3",
url="https://doi.org/10.1007/978-3-319-34168-2_3"
}


@InProceedings{10.1007/978-3-642-35380-2_37,
author="Rathinam, Ananthanaryanan
and Phukan, Ripunjoy",
editor="Panigrahi, Bijaya Ketan
and Das, Swagatam
and Suganthan, Ponnuthurai Nagaratnam
and Nanda, Pradipta Kumar",
title="Solution to Economic Load Dispatch Problem Based on BFO,CBFO-S and CBFO-H Algorithms and Its Advantages over the PSO",
booktitle="Swarm, Evolutionary, and Memetic Computing",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="314--322",
abstract="The Economic Load Dispatch problem (ELD) decides the minimum economic cost of production in a given power system, while keeping the environmental constraints and the load demand to an acceptable level without compromising on the generator ratings. Analysis on this application have been made using multi-modal Bacteria Foraging Optimization(BFO) algorithm, where the bacterial motion is incorporated as a search algorithm in finding the optimum values for economic generation. An improvisation on this algorithm is the co-operative bacteria foraging optimization using serial decomposition (CBFO-s) and CBFO-hybrid that combines BFO and CBFO-s. The search space decomposition and stochastic analysis ensures greater precision and accuracy in cost functions compared to conventional methods of Lagrange's multipliers and Particle Swarm Optimization (PSO). This paper illustrates these points with the ELD problem as a reference.",
isbn="978-3-642-35380-2"
}


@InProceedings{10.1007/978-3-540-30233-9_26,
author="Bucchiarone, A.
and Muccini, H.
and Pelliccione, P.
and Pierini, P.",
editor="N{\'u}{\~{n}}ez, Manuel
and Maamar, Zakaria
and Pelayo, Fernando L.
and Pousttchi, Key
and Rubio, Fernando",
title="Model-Checking Plus Testing: From Software Architecture Analysis to Code Testing",
booktitle="Applying Formal Methods: Testing, Performance, and M/E-Commerce",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="351--365",
abstract="Software Model-Checking and Testing are some of the most used techniques to analyze software systems and identify hidden faults. While software model-checking allows for an exhaustive and automatic analysis of the system expressed through a model, software testing is based on a clever selection of ``relevant'' test cases, which may be manually or automatically run over the system.",
isbn="978-3-540-30233-9"
}


@InProceedings{10.1007/978-3-642-40925-7_11,
author="Rejer, Izabela
and G{\'o}rski, Pawe{\l}",
editor="Saeed, Khalid
and Chaki, Rituparna
and Cortesi, Agostino
and Wierzcho{\'{n}}, S{\l}awomir",
title="Independent Component Analysis for EEG Data Preprocessing - Algorithms Comparison",
booktitle="Computer Information Systems and Industrial Management",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="108--119",
abstract="Some scientific papers report that when Independent Component Analysis (ICA) is applied in the preprocessing step of designing a brain computer interface, the quality of this interface increases. At the same time, however, these papers do not provide information about the exact gain in classification precision obtained after applying different ICA algorithms. The aim of this paper is to compare three algorithms for Independent Component Analysis applied in the process of creating a brain computer interface in order to find out whether the choice of a specific ICA algorithm has an influence on the final classification precision of this interface. The comparison will be carried out with a set submitted to the second BCI Competition.",
isbn="978-3-642-40925-7"
}


@Inbook{Szuba2011,
author="Szuba, Tadeusz (Ted)
and Pola{\'{n}}ski, Pawe{\l}
and Schab, Pawe{\l}
and Wielicki, Pawe{\l}",
editor="Nguyen, Ngoc Thanh",
title="On Efficiency of Collective Intelligence Phenomena",
bookTitle="Transactions on Computational Collective Intelligence III",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="50--73",
abstract="This paper will attempt to formally analyze the problem of individual existence of a being versus its existence in a social structure, through evaluation of Collective Intelligence efficiency. On the basis of two simulation models of two very distant cases of Collective Intelligence, some results to this problem will be given and discussed. Cases are: survival abilities of a bacterial colony, and hunter and dog versus rabbit. This paper also presents the methodology of identification and translation of the mentioned cases of Collective Intelligence phenomena into simulation models. The results show a strong increase of the social structure ability when the Collective Intelligence is functioning. The problem of the Collective Intelligence is so complex, that the results presented here should be considered as a case study. In general, on the basis of presented results, the paper advertises and advocates the theory of Collective Intelligence based on molecular model of computations.",
isbn="978-3-642-19968-4",
doi="10.1007/978-3-642-19968-4_3",
url="https://doi.org/10.1007/978-3-642-19968-4_3"
}


@InProceedings{10.1007/978-3-540-30217-9_80,
author="Okabe, Tatsuya
and Jin, Yaochu
and Olhofer, Markus
and Sendhoff, Bernhard",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="On Test Functions for Evolutionary Multi-objective Optimization",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="792--802",
abstract="In order to evaluate the relative performance of optimization algorithms benchmark problems are frequently used. In the case of multi-objective optimization (MOO), we will show in this paper that most known benchmark problems belong to a constrained class of functions with piecewise linear Pareto fronts in the parameter space. We present a straightforward way to define benchmark problems with an arbitrary Pareto front both in the fitness and parameter spaces. Furthermore, we introduce a difficulty measure based on the mapping of probability density functions from parameter to fitness space. Finally, we evaluate two MOO algorithms for new benchmark problems.",
isbn="978-3-540-30217-9"
}


@InProceedings{10.1007/11779568_102,
author="Mitra, Debasis
and Samant, Gandhali
and Sengupta, Kuntal",
editor="Ali, Moonis
and Dapoigny, Richard",
title="Correlogram-Based Method for Comparing Biological Sequences",
booktitle="Advances in Applied Artificial Intelligence",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="953--961",
abstract="In this article we have proposed an abstract representation for a sequence using a constant sized 3D matrix. Subsequently the representation may be utilized for many analytical purposes. We have attempted to use it for comparing sequences, and analyzed the method's asymptotic complexity. Providing a metric for sequence comparison is an underlying operation to many bioinformatics applications. In order to show the effectiveness of the proposed sequence comparison technique we have generated some phylogeny over two sets of bio-sequences and compared them with the ones available in literature. The results prove that our technique is comparable to the standard ones. The technique, called the correlogram-based method, is borrowed from the image analysis area. We have also done some experiments with synthetically generated sequences in order to compare correlogram-based method with the well-known dynamic programming method. Finally, we have discussed some other possibilities on how our method can be used or extended.",
isbn="978-3-540-35454-3"
}


@InProceedings{10.1007/11784180_23,
author="Nishimura, Susumu",
editor="Johnson, Michael
and Vene, Varmo",
title="Reasoning About Data-Parallel Pointer Programs in a Modal Extension of Separation Logic",
booktitle="Algebraic Methodology and Software Technology",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="293--307",
abstract="This paper proposes a modal extension of Separation Logic [1,2] for reasoning about data-parallel programs that manipulate heap allocated linked data structures. Separation Logic provides a formal means for expressing allocation of disjoint substructures, which are to be processed in parallel. A modal operator is also introduced to relate the global property of a parallel operation with the local property of each sequential execution running in parallel. The effectiveness of the logic is demonstrated through a formal reasoning on the parallel list scan algorithm featuring the pointer jumping technique.",
isbn="978-3-540-35636-3"
}


@InProceedings{10.1007/978-3-642-32615-8_23,
author="Kamath, Uday
and Shehu, Amarda
and De Jong, Kenneth A.",
editor="Suzuki, Junichi
and Nakano, Tadashi",
title="Feature and Kernel Evolution for Recognition of Hypersensitive Sites in DNA Sequences",
booktitle="Bio-Inspired Models of Network, Information, and Computing Systems",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="213--228",
abstract="The annotation of DNA regions that regulate gene transcription is the first step towards understanding phenotypical differences among cells and many diseases. Hypersensitive (HS) sites are reliable markers of regulatory regions. Mapping HS sites is the focus of many statistical learning techniques that employ Support Vector Machines (SVM) to classify a DNA sequence as HS or non-HS. The contribution of this paper is a novel methodology inspired by biological evolution to automate the basic steps in SVM and improve classification accuracy. First, an evolutionary algorithm designs optimal sequence motifs used to associate feature vectors with the input sequences. Second, a genetic programming algorithm designs optimal kernel functions that map the feature vectors into a high-dimensional space where the vectors can be optimally separated into the HS and non-HS classes. Results show that the employment of evolutionary computation techniques improves classification accuracy and promises to automate the analysis of biological sequences.",
isbn="978-3-642-32615-8"
}


@Inbook{Pal2017,
author="Pal, Amrit
and Jain, Harsh
and Kumar, Manish",
editor="Mahmood, Zaigham",
title="Optimizing Software Error Proneness Prediction Using Bird Mating Algorithm",
bookTitle="Software Project Management for Distributed Computing: Life-Cycle Methods for Developing Scalable and Reliable Tools",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="257--287",
abstract="Designing, developing, and maintaining are the key phases of a software life cycle, and the most essential property of a software product is quality. The quality of a software product is dependent on various factors, e.g., reliability, security, and efficiency. But the most important aspect of a software quality is its proper function as described by functional requirements of the software. Errors often occur that are the mistakes which hamper the correct functionality of the software. Thus, to deliver high-quality software, errors must not occur, and if they do then these must be removed. In this chapter, we suggest that the process of identifying and removing errors can be optimized if prior information about the module's possible errors is known. Error proneness prediction can be modeled using classification and prediction techniques. In this context, artificial neural network is a classification model which can be used to predict error proneness. However, the neural network with gradient descent algorithm, e.g., backpropagation algorithm, has the inherent issue of getting stuck into local minima while training. To solve this issue, evolutionary algorithms such as genetic algorithm and bird mating algorithm focus on training of artificial neural. When the prediction model is formalized, receiver operating characteristic curve and accuracy curve are used to analyze the performance of the model. In this chapter, we present an error proneness approach using bird mating algorithm.",
isbn="978-3-319-54325-3",
doi="10.1007/978-3-319-54325-3_11",
url="https://doi.org/10.1007/978-3-319-54325-3_11"
}


@InProceedings{10.1007/978-3-642-35380-2_30,
author="Rakshit, Pratyusha
and Banerjee, Dhrubojyoti
and Konar, Amit
and Janarthanan, Ramadoss",
editor="Panigrahi, Bijaya Ketan
and Das, Swagatam
and Suganthan, Ponnuthurai Nagaratnam
and Nanda, Pradipta Kumar",
title="An Adaptive Memetic Algorithm for Multi-robot Path-Planning",
booktitle="Swarm, Evolutionary, and Memetic Computing",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="248--258",
abstract="This paper provides a novel approach to design an adaptive memetic algorithm by utilizing the composite benefits of Differential Evolution for global search and Q-learning for local refinement. The performance of the proposed adaptive memetic algorithm has been studied on a real-time multi-robot path-planning problem. Experimental results obtained for both simulation and real frameworks indicate that the proposed algorithm based path-planning scheme outperforms real coded Genetic Algorithm, Particle Swarm Optimization and Differential Evolution, particularly its currently best version with respect to two standard metrics defined in the literature.",
isbn="978-3-642-35380-2"
}


@InProceedings{10.1007/978-3-319-03753-0_59,
author="Ramalakshmi, A. P. S.
and Manoharan, P. S.
and Deepamangai, P.",
editor="Panigrahi, Bijaya Ketan
and Suganthan, Ponnuthurai Nagaratnam
and Das, Swagatam
and Dash, Shubhransu Sekhar",
title="PID Tuning and Control for 2-DOF Helicopter Using Particle Swarm Optimization",
booktitle="Swarm, Evolutionary, and Memetic Computing",
year="2013",
publisher="Springer International Publishing",
address="Cham",
pages="662--672",
abstract="This paper proposes a proportional-integral-derivative (PID) design of nonlinear multi-input multi-output (MIMO) system called 2 degree-of-freedom (2-DOF) helicopter using particle swarm optimization (PSO) algorithm. The control of 2-DOF helicopter is very challenging task due to its high nonlinearity and complexity. The objective of the control is to control aerodynamic force of 2-DOF helicopter by varying the speed of the pitch and yaw motor and thus tracking their reference position. Statistical measurement and convergence analysis is done for the optimization of gain parameters of the PID controller of 2-DOF helicopter using PSO, modified PSO (MPSO) and genetic algorithm (GA) for equal repetitions of the function evaluation by iteratively minimizing integral of squared error (ISE), integral of time multiplied by the squared error (ITSE) for 25 independent trials. The numerical simulation results analysis shows the effectiveness of MPSO and PSO compared to GA in controlling the positions of 2-DOF helicopter with consistent tracking.",
isbn="978-3-319-03753-0"
}


@InProceedings{10.1007/11609773_14,
author="Bingham, Jesse
and Rakamari{\'{c}}, Zvonimir",
editor="Emerson, E. Allen
and Namjoshi, Kedar S.",
title="A Logic and Decision Procedure for Predicate Abstraction of Heap-Manipulating Programs",
booktitle="Verification, Model Checking, and Abstract Interpretation",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="207--221",
abstract="An important and ubiquitous class of programs are heap-manipulating programs (HMP), which manipulate unbounded linked data structures by following pointers and updating links. Predicate abstraction has proved to be an invaluable technique in the field of software model checking; this technique relies on an efficient decision procedure for the underlying logic. The expression and proof of many interesting HMP safety properties require transitive closure predicates; such predicates express that some node can be reached from another node by following a sequence of (zero or more) links in the data structure. Unfortunately, adding support for transitive closure often yields undecidability, so one must be careful in defining such a logic. Our primary contributions are the definition of a simple transitive closure logic for use in predicate abstraction of HMPs, and a decision procedure for this logic. Through several experimental examples, we demonstrate that our logic is expressive enough to prove interesting properties with predicate abstraction, and that our decision procedure provides us with both a time and space advantage over previous approaches.",
isbn="978-3-540-31622-0"
}


@InProceedings{10.1007/978-3-540-73595-3_4,
author="Urban, Christian
and Berghofer, Stefan
and Norrish, Michael",
editor="Pfenning, Frank",
title="Barendregt's Variable Convention in Rule Inductions",
booktitle="Automated Deduction -- CADE-21",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="35--50",
abstract="Inductive definitions and rule inductions are two fundamental reasoning tools in logic and computer science. When inductive definitions involve binders, then Barendregt's variable convention is nearly always employed (explicitly or implicitly) in order to obtain simple proofs. Using this convention, one does not consider truly arbitrary bound names, as required by the rule induction principle, but rather bound names about which various freshness assumptions are made. Unfortunately, neither Barendregt nor others give a formal justification for the variable convention, which makes it hard to formalise such proofs. In this paper we identify conditions an inductive definition has to satisfy so that a form of the variable convention can be built into the rule induction principle. In practice this means we come quite close to the informal reasoning of ``pencil-and-paper'' proofs, while remaining completely formal. Our conditions also reveal circumstances in which Barendregt's variable convention is not applicable, and can even lead to faulty reasoning.",
isbn="978-3-540-73595-3"
}


@Inbook{Mycroft2013,
author="Mycroft, Alan
and Voigt, Janina",
editor="Clarke, Dave
and Noble, James
and Wrigstad, Tobias",
title="Notions of Aliasing and Ownership",
bookTitle="Aliasing in Object-Oriented Programming. Types, Analysis and Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="59--83",
abstract="We survey notions of aliasing and ownership. An extreme but conceptually useful model is that of pure linear languages where each object is constructed once and read, being consumed, once. We see more realistic programming languages as relaxing this to allow multiple references to an object (spatial aliasing) or multiple sequenced operations on a single live reference (temporal aliasing) before the object is deallocated. Concurrency complicates things (concurrent aliasing) because spatial aliasing may only happen under certain scheduling conditions. We argue that this view of aliasing is closely related to that of type tags in low-level implementations of dynamic types.",
isbn="978-3-642-36946-9",
doi="10.1007/978-3-642-36946-9_4",
url="https://doi.org/10.1007/978-3-642-36946-9_4"
}


@InProceedings{10.1007/978-3-540-70594-9_12,
author="L{\"a}mmel, Ralf
and Rypacek, Ondrej",
editor="Audebaud, Philippe
and Paulin-Mohring, Christine",
title="The Expression Lemma",
booktitle="Mathematics of Program Construction",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="193--219",
abstract="Algebraic data types and catamorphisms (folds) play a central role in functional programming as they allow programmers to define recursive data structures and operations on them uniformly by structural recursion. Likewise, in object-oriented (OO) programming, recursive hierarchies of object types with virtual methods play a central role for the same reason. There is a semantical correspondence between these two situations which we reveal and formalize categorically. To this end, we assume a coalgebraic model of OO programming with functional objects. The development may be helpful in deriving refactorings that turn sufficiently disciplined functional programs into OO programs of a designated shape and vice versa.",
isbn="978-3-540-70594-9"
}


@InProceedings{10.1007/BFb0018655,
author="Queinnec, Christian
and De Roure, David",
editor="Halstead, Robert H.
and Ito, Takayasu",
title="Design of a concurrent and distributed language",
booktitle="Parallel Symbolic Computing: Languages, Systems, and Applications",
year="1993",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="233--259",
abstract="This paper presents a new dialect of Scheme aimed towards concurrency and distribution. It offers a few primitives, including first-class continuations, with very simple semantics. Numerous examples are given showing how to program the classical concurrent control operators such as future, pcall and either. The implementation is sketched and presented along the lines of a metacircular interpreter.",
isbn="978-3-540-48133-1"
}


@Article{Hilken2018,
author="Hilken, Frank
and Gogolla, Martin
and Burgue{\~{n}}o, Loli
and Vallecillo, Antonio",
title="Testing models and model transformations using classifying terms",
journal="Software {\&} Systems Modeling",
year="2018",
month="Jul",
day="01",
volume="17",
number="3",
pages="885--912",
abstract="This paper proposes the use of equivalence partitioning techniques for testing models and model transformations. In particular, we introduce the concept of classifying terms, which are general OCL terms on a class model enriched with OCL constraints. Classifying terms permit defining equivalence classes, in particular for partitioning the source and target model spaces of the transformation, defining for each class a set of equivalent models with regard to the transformation. Using these classes, a model validator tool is able to automatically construct object models for each class, which constitute relevant test cases for the transformation. We show how this approach of guiding the construction of test cases in an orderly, systematic and efficient manner can be effectively used in combination with Tracts for testing both directional and bidirectional model transformations and for analyzing their behavior.",
issn="1619-1374",
doi="10.1007/s10270-016-0568-3",
url="https://doi.org/10.1007/s10270-016-0568-3"
}


@Inbook{Thévenod-Fosse1991,
author="Th{\'e}venod-Fosse, Pascale",
editor="Avi{\v{z}}ienis, Algirdas
and Laprie, Jean-Claude",
title="Software Validation by Means of Statistical Testing: Retrospect and Future Direction",
bookTitle="Dependable Computing for Critical Applications",
year="1991",
publisher="Springer Vienna",
address="Vienna",
pages="23--50",
abstract="Statistical testing is a practical approach to software validation, involving both fault removal and fault forecasting. It consists in stimulating a program by test samples which are randomly selected based on a defined probability distribution of the input data. The first part of the paper provides a short view of the current state of investigation in statistical testing area. Then a comparison of the strengths and weaknesses of statistical testing with those of deterministic testing allows to put forward the complementary, rather than competing, features of these two methods of generating test data. Hence, a validation strategy organized in three steps is proposed, which mixes statistical and deterministic test data. The first two steps aim at revealing faults, and the third one provides an assessment of operational reliability. Future work to support the strategy is outlined.",
isbn="978-3-7091-9123-1",
doi="10.1007/978-3-7091-9123-1_2",
url="https://doi.org/10.1007/978-3-7091-9123-1_2"
}


@InProceedings{10.1007/11894100_2,
author="Koopman, Pieter
and Plasmeijer, Rinus",
editor="Horv{\'a}th, Zolt{\'a}n",
title="Fully Automatic Testing with Functions as Specifications",
booktitle="Central European Functional Programming School",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="35--61",
abstract="Although computer systems penetrate all facets of society, the software running those systems may contain many errors. Producing high quality software appears to be difficult and very expensive. Even determining the quality of software is not easy. Testing is by far the most used way to estimate the quality of software. Testing itself is not easy and time consuming.",
isbn="978-3-540-46845-5"
}


@InProceedings{10.1007/978-3-319-03756-1_38,
author="Santana, Roberto
and Mendiburu, Alexander
and Lozano, Jose A.",
editor="Panigrahi, Bijaya Ketan
and Suganthan, Ponnuthurai Nagaratnam
and Das, Swagatam
and Dash, Shubhransu Sekhar",
title="Message Passing Methods for Estimation of Distribution Algorithms Based on Markov Networks",
booktitle="Swarm, Evolutionary, and Memetic Computing",
year="2013",
publisher="Springer International Publishing",
address="Cham",
pages="419--430",
abstract="Sampling methods are a fundamental component of estimation of distribution algorithms (EDAs). In this paper we propose new methods for generating solutions in EDAs based on Markov networks. These methods are based on the combination of message passing algorithms with decimation techniques for computing the maximum a posteriori solution of a probabilistic graphical model. The performance of the EDAs on a family of non-binary deceptive functions shows that the introduced approach improves results achieved with the sampling methods traditionally used by EDAs based on Markov networks.",
isbn="978-3-319-03756-1"
}


@InProceedings{10.1007/978-3-642-14891-0_13,
author="Jaskiewicz, Tomasz
and Aprile, Walter A.
and van der Helm, Aadjan",
editor="Balandin, Sergey
and Dunaytsev, Roman
and Koucheryavy, Yevgeni",
title="Creative Approach to the Design and Prototyping of Experimental Smart Spaces, Case Studies from the Interactive Environments Minor",
booktitle="Smart Spaces and Next Generation Wired/Wireless Networking",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="135--147",
abstract="This paper attempts to challenge the established practice of design and engineering of smart environments in two ways. Its first premise is that smart spaces should be formed by systems that comprise not only home or office appliances, but also embedded building component agents. The second premise of this paper is a consequent call for an interdisciplinary approach to creation of smart spaces. Experimental undergraduate course is used to provide a set of case studies to illustrate benefits and threats of such approach, as well as the relevance of the integration of iterative prototyping already in the earliest phases of design processes.",
isbn="978-3-642-14891-0"
}


@Inbook{Shepperd2003,
author="Shepperd, Martin",
editor="Aurum, Ayb{\"u}ke
and Jeffery, Ross
and Wohlin, Claes
and Handzic, Meliha",
title="Case-Based Reasoning and Software Engineering",
bookTitle="Managing Software Engineering Knowledge",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="181--198",
abstract="Case-based reasoning (CBR) is a technology that is based on the idea of analogy. Solutions from past problems (cases) can be retrieved and deployed, with adaptation where necessary, to solve new problems. It is argued that CBR as a technology has a number of strengths, since it deals well with poorly understood problem domains, does not require explicit knowledge elicitation and supports collaboration with users. This chapter provides some general background information on CBR and then considers how CBR has been deployed to solve problems in the domain of software engineering. These problems fall into two general categories, namely prediction and reuse. The main prediction problems are related to project characteristics such as effort and duration, whilst the chief reuse foci are related to learning from past experiences. The chapter concludes by identifying three research challenges. These are to be able to better adapt retrieved solutions to solve new problems, to explore richer forms of representation for complex problems and, last, to encourage better collaboration between the user and the CBR system.",
isbn="978-3-662-05129-0",
doi="10.1007/978-3-662-05129-0_9",
url="https://doi.org/10.1007/978-3-662-05129-0_9"
}


@InProceedings{10.1007/11745693_36,
author="Wang, Wei-Jen
and Varela, Carlos A.",
editor="Chung, Yeh-Ching
and Moreira, Jos{\'e} E.",
title="Distributed Garbage Collection for Mobile Actor Systems: The Pseudo Root Approach",
booktitle="Advances in Grid and Pervasive Computing",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="360--372",
abstract="Automatic distributed garbage collection (GC) gives abstraction to grid application development, promoting code quality and improving resource management. Unreachability of active objects or actors from the root set is not a sufficient condition to collect actor garbage, making passive object GC algorithms unsafe when directly used on actor systems. In practical actor languages, all actors have references to the root set since they can interact with users, e.g., through standard input or output streams. Based on this observation, we introduce pseudo roots: a dynamic set of actors that can be viewed as the root set. Pseudo roots use protected (undeletable) references to ensure that no actors are erroneously collected even with messages in transit. Following this idea, we introduce a new direction of actor GC, and demonstrate it by developing a distributed GC framework. The framework can thus be used for automatic life time management of mobile reactive processes with unordered asynchronous communication.",
isbn="978-3-540-33810-9"
}


@InProceedings{10.1007/11811305_52,
author="He, Zhi
and Tian, Shengfeng
and Huang, Houkuan",
editor="Li, Xue
and Za{\"i}ane, Osmar R.
and Li, Zhanhuai",
title="OMVD: An Optimization of MVD",
booktitle="Advanced Data Mining and Applications",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="473--484",
abstract="Most discretization algorithms are univariate and consider only one attribute at a time. Stephen D. Bay presented a multivariate discretization(MVD) method that considers the affects of all the attributes in the procedure of data mining. But as the author mentioned, any test of differences has a limited amount of power. We present OMVD by improving MVD on the power of testing differences with a genetic algorithm. OMVD is more powerful than MVD because the former does not suffer from setting the difference threshold and from seriously depending on the basic intervals. In addition, the former simultaneously searches partitions for multiple attributes. Our experiments with some synthetic and real datasets suggest that OMVD could obtain more interesting discretizations than could MVD.",
isbn="978-3-540-37026-0"
}


@Inbook{Aravinth2017,
author="Aravinth, Anto",
title="Functional Programming in Simple Terms",
bookTitle="Beginning Functional JavaScript: Functional Programming with JavaScript Using EcmaScript 6",
year="2017",
publisher="Apress",
address="Berkeley, CA",
pages="1--13",
abstract="Welcome to the functional programming world. The world, which has only functions, living happily without any outside world dependencies, without states, without mutations -- forever. Functional programming is a buzz in recent days. You might have heard about this term within your team, in your local group meeting, and have thought about this. If you're already aware of what that means, this is great! But for those who don't know the term, don't worry. This chapter is for that purpose: to introduce you to Functional terms in simple English.",
isbn="978-1-4842-2656-8",
doi="10.1007/978-1-4842-2656-8_1",
url="https://doi.org/10.1007/978-1-4842-2656-8_1"
}


@Inbook{Sutcliffe2002,
author="Sutcliffe, Alistair",
title="Future Directions",
bookTitle="User-Centred Requirements Engineering",
year="2002",
publisher="Springer London",
address="London",
pages="181--200",
abstract="In this final chapter I will speculate on the future courses that requirements engineering may take. This is not a matter of imagining the impact that future technology may have on RE, however; rather, it is motivated by revisiting the fundamental problems of RE: communicating, understanding and transforming needs into designs. RE will face more pressing problems as systems become more complex, distributed and ubiquitous. It will become increasingly difficult for any one person to understand such complexity and then specify requirements for it. We therefore have a dilemma of what I call the horizon of knowability: as technology advances so does our ability to design more complex systems, yet our ability to understand such systems is finite. We are limited by our cognitive capacity and the time taken to understand complex systems; this capacity can only change slowly as we devise better methods. In contrast, the rate of technological change is exponential, as it feeds progressively on its own baseline. We tend to acknowledge this as the accelerating pace of change in society. So where does the answer lie? I will argue that we should look in two possible directions: first toward artificial intelligence and learning machines, and secondly towards automated design environments that communicate with us in natural language and graphics. Both have a common implication: in the future, requirements engineering will become progressively concerned with the design environment, while what we currently consider to be requirements analysis will either be learned automatically or achieved by conversation with an application generator machine.",
isbn="978-1-4471-0217-5",
doi="10.1007/978-1-4471-0217-5_8",
url="https://doi.org/10.1007/978-1-4471-0217-5_8"
}


@InProceedings{10.1007/978-3-642-12156-2_13,
author="Blecic, Ivan
and Cecchini, Arnaldo
and Trunfio, Giuseppe A.",
editor="Taniar, David
and Gervasi, Osvaldo
and Murgante, Beniamino
and Pardede, Eric
and Apduhan, Bernady O.",
title="A Comparison of Evolutionary Algorithms for Automatic Calibration of Constrained Cellular Automata",
booktitle="Computational Science and Its Applications -- ICCSA 2010",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="166--181",
abstract="We present a comparative study of seven evolutionary algorithms (Generational Genetic, Elitist Genetic, Steady State Genetic, ($\mu$/$\rho$, $\lambda$) Evolution Strategy, ($\mu$/$\rho${\thinspace}+{\thinspace}$\lambda$) Evolution Strategy, generational and elitist Covariance Matrix Adaptation) for automatic calibration of a constrained cellular automaton (CCA), whose performance are assessed in terms of two fitness metrics (based on Kappa statistics and Lee-Salee Index). Two variations of the CCA (one with 14 and one 27 parameters) were tested jointly with different number of time steps targeted by the calibration procedures. Besides offering some methodological suggestions for this kind of comparative analysis, the findings provide useful hints on the calibration algorithms to be expected to perform better in the application of cellular automata of sort for the simulation of land-use dynamics.",
isbn="978-3-642-12156-2"
}


@Article{Cheng2018,
author="Cheng, Zheng
and Monahan, Rosemary
and Power, James F.",
title="Formalised EMFTVM bytecode language for sound verification of model transformations",
journal="Software {\&} Systems Modeling",
year="2018",
month="Oct",
day="01",
volume="17",
number="4",
pages="1197--1225",
abstract="Model-driven engineering is an effective approach for addressing the full life cycle of software development. Model transformation is widely acknowledged as one of its central ingredients. With the increasing complexity of model transformations, it is urgent to develop verification tools that prevent incorrect transformations from generating faulty models. However, the development of sound verification tools is a non-trivial task, due to unimplementable or erroneous execution semantics encoded for the target model transformation language. In this work, we develop a formalisation for the EMFTVM bytecode language by using the Boogie intermediate verification language. It ensures the model transformation language has an implementable execution semantics by reliably prototyping the implementation of the model transformation language. It also ensures the absence of erroneous execution semantics encoded for the target model transformation language by using a translation validation approach.",
issn="1619-1374",
doi="10.1007/s10270-016-0553-x",
url="https://doi.org/10.1007/s10270-016-0553-x"
}


@InProceedings{10.1007/3-540-45498-5_12,
author="Zigman, John
and Blackburn, Stephen M.
and Moss, J. Eliot B.",
editor="Kirby, Graham N. C.
and Dearle, Alan
and Sj{\o}berg, Dag I. K.",
title="TMOS: A Transactional Garbage Collector",
booktitle="Persistent Object Systems: Design, Implementation, and Use",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="138--156",
abstract="Defining persistence in terms of reachability is fundamental to achieving orthogonality of persistence. It is implicit to the principles of orthogonal persistence and is a part of the ODMG 3.0 data objects standard. Although space reclamation in the context of persistence by reachability can be achieved automatically using garbage collection, relatively few papers address the problem of implementing garbage collection in a transactional storage system. A transactional GC algorithm must operate correctly in the face of failure, and in particular must deal with the problem of transaction abort, which by undoing changes such as the deletion of references, subverts the GC reachability axiom of `once garbage always garbage'.",
isbn="978-3-540-45498-4"
}


@InProceedings{10.1007/978-3-540-30217-9_22,
author="Cho, Dong-Yeon
and Zhang, Byoung-Tak",
editor="Yao, Xin
and Burke, Edmund K.
and Lozano, Jos{\'e} A.
and Smith, Jim
and Merelo-Guerv{\'o}s, Juan Juli{\'a}n
and Bullinaria, John A.
and Rowe, Jonathan E.
and Ti{\v{n}}o, Peter
and Kab{\'a}n, Ata
and Schwefel, Hans-Paul",
title="Evolutionary Continuous Optimization by Distribution Estimation with Variational Bayesian Independent Component Analyzers Mixture Model",
booktitle="Parallel Problem Solving from Nature - PPSN VIII",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="212--221",
abstract="In evolutionary continuous optimization by building and using probabilistic models, the multivariate Gaussian distribution and their variants or extensions such as the mixture of Gaussians have been used popularly. However, this Gaussian assumption is often violated in many real problems. In this paper, we propose a new continuous estimation of distribution algorithms (EDAs) with the variational Bayesian independent component analyzers mixture model (vbICA-MM) for allowing any distribution to be modeled. We examine how this sophisticated density estimation technique has influence on the performance of the optimization by employing the same selection and population alternation schemes used in the previous EDAs. Our experimental results support that the presented EDAs achieve better performance than previous EDAs with ICA and Gaussian mixture- or kernel-based approaches.",
isbn="978-3-540-30217-9"
}


@InProceedings{10.1007/978-3-642-37288-9_14,
author="Su{\v{s}}il, Petr
and Vaudenay, Serge",
editor="Mangard, Stefan",
title="Multipurpose Cryptographic Primitive ARMADILLO3",
booktitle="Smart Card Research and Advanced Applications",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="203--218",
abstract="This paper describes a new design of the multipurpose cryptographic primitive ARMADILLO3 and analyses its security. The ARMADILLO3 family is oriented on small hardware such as smart cards and RFID chips. The original design ARMADILLO and its variants were analyzed by Sepehrdad et al. at CARDIS'11, the recommended variant ARMADILLO2 was analyzed by Plasencia et al. at FSE'12 and by Abdelraheem et al. at ASIACRYPT'11. The ARMADILLO3 design takes the original approach of combining a substitution and a permutation layer. The new family ARMADILLO3 introduces a reduced-size substitution layer with 3 {\texttimes}3 and 4 {\texttimes}4 S-boxes, which covers the substitution layer from 25{\%} to 100{\%} of state bits, depending on the security requirements. We propose an instance ARMADILLO3-A1/4 with a pair of permutations and S-boxes applied on 25{\%} of state bits at each stage.",
isbn="978-3-642-37288-9"
}


@InProceedings{10.1007/978-3-540-71618-1_34,
author="Choi, Se-Hyu",
editor="Beliczynski, Bartlomiej
and Dzielinski, Andrzej
and Iwanowski, Marcin
and Ribeiro, Bernardete",
title="Application of Micro-GA for an Optimal Direct Design Method of Steel Frame",
booktitle="Adaptive and Natural Computing Algorithms",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="306--313",
abstract="In this paper, an optimal direct design method of steel frame using advanced analysis and genetic algorithm is presented. The advanced analysis realistically assesses both strength and behavior of a structural system and its component members in a direct manner. The micro-GA is used for minimum weight optimization of steel frames. Constraint functions are load-carrying capacities and serviceability. The optimum designs determined by the proposed method are lighter than those given by other approaches.",
isbn="978-3-540-71618-1"
}


@InProceedings{10.1007/978-3-319-03542-0_8,
author="Trinh, Minh-Thai
and Le, Quang Loc
and David, Cristina
and Chin, Wei-Ngan",
editor="Shan, Chung-chieh",
title="Bi-Abduction with Pure Properties for Specification Inference",
booktitle="Programming Languages and Systems",
year="2013",
publisher="Springer International Publishing",
address="Cham",
pages="107--123",
abstract="Separation logic is a state-of-the-art logic for dealing with the program heap. Using its frame rule, initial works have strived towards automated modular verification for heap-manipulating programs against user-supplied specifications. Since manually writing specifications is a tedious and error-prone engineering process, the so-called bi-abduction (a combination of the frame rule and abductive inference) is proposed to automatically infer pre/post specifications on data structure shapes. However, it has omitted the inference of pure properties of data structures such as their size, sum, height, content and minimum/maximum value, which are needed to express a higher level of program correctness.",
isbn="978-3-319-03542-0"
}


@Article{Plaku2013,
author="Plaku, Erion
and Kavraki, Lydia E.
and Vardi, Moshe Y.",
title="Falsification of LTL safety properties in hybrid systems",
journal="International Journal on Software Tools for Technology Transfer",
year="2013",
month="Aug",
day="01",
volume="15",
number="4",
pages="305--320",
abstract="This paper develops a novel approach for the falsification of safety properties given by a syntactically safe linear temporal logic (LTL) formula {\$}{\$}{\{}{\backslash}phi{\}}{\$}{\$}for hybrid systems with nonlinear dynamics and input controls. When the hybrid system is unsafe, the approach computes a trajectory that indicates violation of {\$}{\$}{\{}{\backslash}phi{\}}{\$}{\$}. The approach is based on an effective combination of model checking and motion planning. Model checking searches on-the-fly the automaton of {\$}{\$}{\{}{\backslash}neg{\backslash}phi{\}}{\$}{\$}and an abstraction of the hybrid system for a sequence $\sigma$ of propositional assignments that violates {\$}{\$}{\{}{\backslash}phi{\}}{\$}{\$}. Motion planning incrementally extends trajectories that satisfy more and more of the propositional assignments in $\sigma$. Model checking and motion planning regularly exchange information to find increasingly useful sequences $\sigma$ for extending the current trajectories. Experiments that test LTL safety properties on a robot navigation benchmark modeled as a hybrid system with nonlinear dynamics and input controls demonstrate the computational efficiency of the approach. Experiments also indicate significant speedup when using minimized DFA instead of non-minimized NFA for representing {\$}{\$}{\{}{\backslash}neg{\backslash}phi{\}}{\$}{\$}.",
issn="1433-2787",
doi="10.1007/s10009-012-0233-2",
url="https://doi.org/10.1007/s10009-012-0233-2"
}


@InProceedings{10.1007/978-3-540-69738-1_16,
author="Lev-Ami, Tal
and Sagiv, Mooly
and Immerman, Neil
and Reps, Thomas",
editor="Cook, Byron
and Podelski, Andreas",
title="Constructing Specialized Shape Analyses for Uniform Change",
booktitle="Verification, Model Checking, and Abstract Interpretation",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="215--233",
abstract="This paper is concerned with one of the basic problems in abstract interpretation, namely, for a given abstraction and a given set of concrete transformers (that express the concrete semantics of a program), how does one create the associated abstract transformers? We develop a new methodology for addressing this problem, based on a syntactically restricted language for expressing concrete transformers. We use this methodology to produce best abstract transformers for abstractions of many important data structures.",
isbn="978-3-540-69738-1"
}


@InProceedings{10.1007/11844297_95,
author="Kern, Stefan
and Hansen, Nikolaus
and Koumoutsakos, Petros",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Local Meta-models for Optimization Using Evolution Strategies",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="939--948",
abstract="We employ local meta-models to enhance the efficiency of evolution strategies in the optimization of computationally expensive problems. The method involves the combination of second order local regression meta-models with the Covariance Matrix Adaptation Evolution Strategy. Experiments on benchmark problems demonstrate that the proposed meta-models have the potential to reliably account for the ranking of the offspring population resulting in significant computational savings. The results show that the use of local meta-models significantly increases the efficiency of already competitive evolution strategies.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-319-12154-3_1,
author="Banerjee, Anindya
and Naumann, David A.",
editor="Giannakopoulou, Dimitra
and Kroening, Daniel",
title="A Logical Analysis of Framing for Specifications with Pure Method Calls",
booktitle="Verified Software: Theories, Tools and Experiments",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="3--20",
abstract="For specifying and reasoning about object-based programs it is often attractive for contracts to be expressed using calls to pure methods. It is useful for pure methods to have contracts, including read effects to support local reasoning based on frame conditions. This leads to puzzles such as the use of a pure method in its own contract. These ideas have been explored in connection with verification tools based on axiomatic semantics, guided by the need to avoid logical inconsistency, and focusing on encodings that cater for first order automated provers. This paper adds pure methods and read effects to region logic, a first-order program logic that features frame-based local reasoning and a proof rule for linking of clients with modules to achieve end-to-end correctness by modular reasoning. Soundness is proved with respect to a conventional operational semantics and using the extensional (i.e., relational) interpretation of read effects.",
isbn="978-3-319-12154-3"
}


@InProceedings{10.1007/978-3-540-71629-7_25,
author="Dio{\c{s}}, Laura
and Oltean, Mihai
and Rogozan, Alexandrina
and Pecuchet, Jean-Pierre",
editor="Beliczynski, Bartlomiej
and Dzielinski, Andrzej
and Iwanowski, Marcin
and Ribeiro, Bernardete",
title="Improving SVM Performance Using a Linear Combination of Kernels",
booktitle="Adaptive and Natural Computing Algorithms",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="218--227",
abstract="Standard kernel-based classifiers use only a single kernel, but the real-world applications and the recent developments of various kernel methods have emphasized the need to consider a combination of multiple kernels. We propose an evolutionary approach for finding the optimal weights of a combined kernel used by the Support Vector Machines (SVM) algorithm for solving some particular problems. We use a genetic algorithm (GA) for evolving these weights. The numerical experiments show that the evolved combined kernels (ECKs) perform better than the convex combined kernels (CCKs) for several classification problems.",
isbn="978-3-540-71629-7"
}


@InProceedings{10.1007/11779568_117,
author="Rezaei, Jafar
and Davoodi, Mansoor",
editor="Ali, Moonis
and Dapoigny, Richard",
title="Genetic Algorithm for Inventory Lot-Sizing with Supplier Selection Under Fuzzy Demand and Costs",
booktitle="Advances in Applied Artificial Intelligence",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1100--1110",
abstract="In this paper a multi-period inventory lot sizing scenario, where there are multiple products and multiple suppliers, is solved with a Real Parameter Genetic Algorithm. We assume that demand of multiple discrete products is known, not exactly, over a planning horizon and transaction cost is supplier dependent, but does not depend on the variety nor quantity of products involved and holding cost is product-dependent and there are no capacity restrictions and no backlogging is allowed. Because of uncertainties in demand and inventory costs, we consider demand and all costs as fuzzy numbers. The problem is formulated as a fuzzy mixed integer programming and then converted to equivalent crisp decision making problems and is solved with a Real Parameter Genetic Algorithm. Finally, numerical example is provided to illustrate the solution procedure. The results determine what products to order in what quantities with which suppliers in which periods.",
isbn="978-3-540-35454-3"
}


@InProceedings{10.1007/978-3-319-03077-7_6,
author="von Styp, Sabrina
and Yu, Liyong",
editor="Bertacco, Valeria
and Legay, Axel",
title="Symbolic Model-Based Testing for Industrial Automation Software",
booktitle="Hardware and Software: Verification and Testing",
year="2013",
publisher="Springer International Publishing",
address="Cham",
pages="78--94",
abstract="In industrial automation software controls systems whose failure can be critical and expensive. Testing this software is very crucial but so far done manually, an expensive and not very thorough method. Model-based testing is an emerging concept in computer science for automatically testing a real implementation. It uses a formal specification describing the system behaviour. This specification is the blue print against which an implementation is tested. This paper presents how to use model-based testing in industrial automation. In detail it shows how the known concepts such as sequential function charts, used in industrial automation to describe a system, can be translated to a format that is required for model-based testing, including an automatic derivation of test-cases and its execution. A concrete case study illustrates the strength of this approach.",
isbn="978-3-319-03077-7"
}


@InProceedings{10.1007/978-3-642-21834-7_2,
author="Heiner, Monika
and Gilbert, David",
editor="Kristensen, Lars M.
and Petrucci, Laure",
title="How Might Petri Nets Enhance Your Systems Biology Toolkit",
booktitle="Applications and Theory of Petri Nets",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="17--37",
abstract="``How might Petri nets enhance my Systems Biology toolkit?'' -- this is one of the questions that we get on a regular basis, which motivated us to write an answer in the form of this paper.",
isbn="978-3-642-21834-7"
}


@InProceedings{10.1007/978-3-642-25959-3_7,
author="Ebnenasir, Ali
and Hajisheykhi, Reza
and Kulkarni, Sandeep S.",
editor="Bononi, Luciano
and Datta, Ajoy K.
and Devismes, St{\'e}phane
and Misra, Archan",
title="Facilitating the Design of Fault Tolerance in Transaction Level SystemC Programs",
booktitle="Distributed Computing and Networking",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="91--105",
abstract="Due to their increasing complexity, today's SoC (System on Chip) systems are subject to a variety of faults (e.g., soft errors, component crash, etc.), thereby making fault tolerance a highly important property of such systems. However, designing fault tolerance is a complex task in part due to the large scale of integration of SoC systems and different levels of abstraction provided by modern system design languages such as SystemC. Most existing methods enable fault injection and impact analysis as a means for increasing design dependability. Nonetheless, such methods provide little support for designing fault tolerance. To facilitate the design of fault tolerance in SoC systems, this paper propose an approach where fault tolerance is designed at the level of inter-component communication protocols in SystemC Transaction Level (TL) models. The proposed method includes four main steps, namely model extraction, fault modeling, addition of fault tolerance and refinement of synthesized fault tolerance to SystemC code. We demonstrate the proposed approach using a simple SystemC transaction level program that is subject to communication faults. We also provide a roadmap for future research at the intersection of fault tolerance and hardware-software co-design.",
isbn="978-3-642-25959-3"
}


@InProceedings{10.1007/3-540-45309-1_9,
author="Graunke, Paul
and Krishnamurthi, Shriram
and Van Der Hoeven, Steve
and Felleisen, Matthias",
editor="Sands, David",
title="Programming the Web with High-Level Programming Languages",
booktitle="Programming Languages and Systems",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="122--136",
abstract="Many modern programs provide operating system-style services to extension modules. A Web server, for instance, behaves like a simple OS kernel. It invokes programs that dynamically generate Web pages and manages their resource consumption. Most Web servers, however, rely on conventional operating systems to provide these services. As a result, the solutions are inefficient, and impose a serious overhead on the programmer of dynamic extensions.",
isbn="978-3-540-45309-3"
}


@Article{Semenov2010,
author="Semenov, V. A.
and Dragalov, K. V.
and Ilyin, D. V.
and Morozov, S. V.
and Sidyaka, O. V.",
title="On complementary principles of object-oriented constraint programming",
journal="Programming and Computer Software",
year="2010",
month="Sep",
day="01",
volume="36",
number="5",
pages="264--275",
abstract="The paper is devoted to the implementation of the paradigm of the object-oriented constraint programming (OOCP), which combines complementary ideas and principles of the object-oriented programming (OOP) and constraint logical programming (CLP). Although the idea looks attractive and there have been attempts to implement it with the use of logical and functional languages, its future outline is still not clear. In the paper, a survey of the existing technologies of the constraint programming is given, and a new systematic approach to the implementation of the object-oriented constraint programming based on the use of declarative data modeling languages is discussed. The advantages of the approach related to the expressiveness and generality of the constraint problem declarations are demonstrated on the example of the classical mathematical queen problem. A general algorithmic strategy of solving the constraint problems is also discussed.",
issn="1608-3261",
doi="10.1134/S0361768810050026",
url="https://doi.org/10.1134/S0361768810050026"
}


@InProceedings{10.1007/978-3-642-31762-0_2,
author="Bormer, Thorsten
and Brockschmidt, Marc
and Distefano, Dino
and Ernst, Gidon
and Filli{\^a}tre, Jean-Christophe
and Grigore, Radu
and Huisman, Marieke
and Klebanov, Vladimir
and March{\'e}, Claude
and Monahan, Rosemary
and Mostowski, Wojciech
and Polikarpova, Nadia
and Scheben, Christoph
and Schellhorn, Gerhard
and Tofan, Bogdan
and Tschannen, Julian
and Ulbrich, Mattias",
editor="Beckert, Bernhard
and Damiani, Ferruccio
and Gurov, Dilian",
title="The COST IC0701 Verification Competition 2011",
booktitle="Formal Verification of Object-Oriented Software",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="3--21",
abstract="This paper reports on the experiences with the program verification competition held during the FoVeOOS conference in October 2011. There were 6 teams participating in this competition. We discuss the three different challenges that were posed and the solutions developed by the teams. We conclude with a discussion about the value of such competitions and lessons learned from them.",
isbn="978-3-642-31762-0"
}


@InProceedings{10.1007/978-3-540-40018-9_19,
author="Simonet, Vincent",
editor="Ohori, Atsushi",
title="Type Inference with Structural Subtyping: A Faithful Formalization of an Efficient Constraint Solver",
booktitle="Programming Languages and Systems",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="283--302",
abstract="We are interested in type inference in the presence of structural subtyping from a pragmatic perspective. This work combines theoretical and practical contributions: first, it provides a faithful description of an efficient algorithm for solving and simplifying constraints; whose correctness is formally proved. Besides, the framework has been implemented in Objective Caml, yielding a generic type inference engine. Its efficiency is assessed by a complexity result and a series of experiments in realistic cases.",
isbn="978-3-540-40018-9"
}


@InProceedings{10.1007/978-3-642-39640-3_38,
author="El-Zawawy, Mohamed A.",
editor="Murgante, Beniamino
and Misra, Sanjay
and Carlini, Maurizio
and Torre, Carmelo M.
and Nguyen, Hong-Quang
and Taniar, David
and Apduhan, Bernady O.
and Gervasi, Osvaldo",
title="Detection of Probabilistic Dangling References in Multi-core Programs Using Proof-Supported Tools",
booktitle="Computational Science and Its Applications -- ICCSA 2013",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="516--530",
abstract="This paper presents a new technique for detection of probabilistic dangling references in multi-core programs. The technique has the form of a simply structured type system and provides a suitable framework for proof-carrying code applications like mobile code applications that have limited resources. The type derivation of each individual analysis serves as a proof for the correctness of the analysis. The type system is designed to analyze parallel programs with structured concurrent constructs: fork-join constructs, conditionally spawned cores, and parallel loops.",
isbn="978-3-642-39640-3"
}


@InProceedings{10.1007/978-3-642-22941-1_6,
author="Eastlund, Carl
and Felleisen, Matthias",
editor="Page, Rex
and Horv{\'a}th, Zolt{\'a}n
and Zs{\'o}k, Vikt{\'o}ria",
title="Hygienic Macros for ACL2",
booktitle="Trends in Functional Programming",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="84--101",
abstract="ACL2 is a theorem prover for a purely functional subset of Common Lisp. It inherits Common Lisp's unhygienic macros, which are used pervasively to eliminate repeated syntactic patterns. The lack of hygiene means that macros do not automatically protect their producers or consumers from accidental variable capture. This paper demonstrates how this lack of hygiene interferes with theorem proving. It then explains how to design and implement a hygienic macro system for ACL2. An evaluation of the ACL2 code base shows the potential impact of this hygienic macro system on existing libraries and practices.",
isbn="978-3-642-22941-1"
}


@Inbook{Schmidt1993,
author="Schmidt, Gunther
and Str{\"o}hlein, Thomas",
title="The Category of Graphs",
bookTitle="Relations and Graphs: Discrete Mathematics for Computer Scientists",
year="1993",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="142--171",
abstract="Given any mathematical structure, one is interested in homomorphisms, substructures, and congruences. There is a characteristic difference between algebraic and relational structures.",
isbn="978-3-642-77968-8",
doi="10.1007/978-3-642-77968-8_7",
url="https://doi.org/10.1007/978-3-642-77968-8_7"
}


@InProceedings{10.1007/978-3-642-31500-8_10,
author="Javed, Noman
and Loulergue, Fr{\'e}d{\'e}ric",
editor="Wyrzykowski, Roman
and Dongarra, Jack
and Karczewski, Konrad
and Wa{\'{s}}niewski, Jerzy",
title="Verification of a Heat Diffusion Simulation Written with Orl{\'e}ans Skeleton Library",
booktitle="Parallel Processing and Applied Mathematics",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="91--100",
abstract="Orl{\'e}ans Skeleton Library (OSL) provides a set of algorithmic skeletons as a C++ library on top of MPI. The parallel programming approach of OSL is a structured one, which eases the reasoning about the performance and correctness of the programs. In this paper we present the verification of a heat diffusion simulation program, written in OSL, using the Coq proof assistant. The specification used in proving the correctness is a discretisation of the heat equation.",
isbn="978-3-642-31500-8"
}


@Article{Wooley2010,
author="Wooley, John C.
and Ye, Yuzhen",
title="Metagenomics: Facts and Artifacts, and Computational Challenges",
journal="Journal of Computer Science and Technology",
year="2010",
month="Jan",
day="01",
volume="25",
number="1",
pages="71--81",
abstract="Metagenomics is the study of microbial communities sampled directly from their natural environment, without prior culturing. By enabling an analysis of populations including many (so-far) unculturable and often unknown microbes, metagenomics is revolutionizing the field of microbiology, and has excited researchers in many disciplines that could benefit from the study of environmental microbes, including those in ecology, environmental sciences, and biomedicine. Specific computational and statistical tools have been developed for metagenomic data analysis and comparison. New studies, however, have revealed various kinds of artifacts present in metagenomics data caused by limitations in the experimental protocols and/or inadequate data analysis procedures, which often lead to incorrect conclusions about a microbial community. Here, we review some of the artifacts, such as overestimation of species diversity and incorrect estimation of gene family frequencies, and discuss emerging computational approaches to address them. We also review potential challenges that metagenomics may encounter with the extensive application of next-generation sequencing (NGS) techniques.",
issn="1860-4749",
doi="10.1007/s11390-010-9306-4",
url="https://doi.org/10.1007/s11390-010-9306-4"
}


@InProceedings{10.1007/978-3-642-39038-8_4,
author="Lerner, Benjamin S.
and Elberty, Liam
and Li, Jincheng
and Krishnamurthi, Shriram",
editor="Castagna, Giuseppe",
title="Combining Form and Function: Static Types for JQuery Programs",
booktitle="ECOOP 2013 -- Object-Oriented Programming",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="79--103",
abstract="The jQuery library defines a powerful query language for web applications' scripts to interact with Web page content. This language is exposed as jQuery's api, which is implemented to fail silently so that incorrect queries will not cause the program to halt. Since the correctness of a query depends on the structure of a page, discrepancies between the page's actual structure and what the query expects will also result in failure, but with no error traces to indicate where the mismatch occurred.",
isbn="978-3-642-39038-8"
}


@Inbook{Andreychenko2014,
author="Andreychenko, Alexander
and Kr{\"u}ger, Thilo
and Spieler, David",
editor="Remke, Anne
and Stoelinga, Mari{\"e}lle",
title="Analyzing Oscillatory Behavior with Formal Methods",
bookTitle="Stochastic Model Checking. Rigorous Dependability Analysis Using Model Checking Techniques for Stochastic Systems: International Autumn School, ROCKS 2012, Vahrn, Italy, October 22-26, 2012, Advanced Lectures",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--25",
abstract="An important behavioral pattern that can be witnessed in many systems is periodic re-occurrence. For example, most living organisms that we know are governed by a 24 hours rhythm that determines whether they are awake or not. On a larger scale, also whole population numbers of organisms fluctuate in a cyclic manner as in predator-prey relationships. When treating such systems in a deterministic way, i.e., assuming that stochastic effects are negligible, the analysis is a well-studied topic. But if those effects play an important role, recent publications suggest that at least a part of the system should be modeled stochastically. However, in that case, one quickly realizes that characterizing and defining oscillatory behavior is not a straightforward task, which can be solved once and for all. Moreover, efficiently checking whether a given system oscillates or not and if so determining the amplitude of the fluctuations and the time in-between is intricate. This paper shall give an overview of the existing literature on different modeling formalisms for oscillatory systems, definitions of oscillatory behavior, and the respective analysis methods.",
isbn="978-3-662-45489-3",
doi="10.1007/978-3-662-45489-3_1",
url="https://doi.org/10.1007/978-3-662-45489-3_1"
}


@InProceedings{10.1007/978-3-319-47151-8_11,
author="Bortolussi, Luca
and Policriti, Alberto
and Silvetti, Simone",
editor="Cinquemani, Eugenio
and Donz{\'e}, Alexandre",
title="Logic-Based Multi-objective Design of Chemical Reaction Networks",
booktitle="Hybrid Systems Biology",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="164--178",
abstract="The design of genetic or protein networks that satisfy a given set of behavioural specifications is one of the main challenges of synthetic biology. Model-based design is a natural choice in this respect. Here we consider the problem of tuning parameters of a stochastic model to force one or more behavioural goals to hold. In particular, we consider several objectives specified by signal temporal logic formulae, and we look for a parameter set making their satisfaction probability as large as possible. This formalisation results in a multi-objective optimisation problem, which we solve by considering an optimisation scheme combining satisfaction probability and average robustness of STL properties, leveraging state of the art multi-objective optimisation routines.",
isbn="978-3-319-47151-8"
}


@InProceedings{10.1007/11561347_19,
author="Eckhardt, Jason
and Kaiabachev, Roumen
and Pa{\v{s}}ali{\'{c}}, Emir
and Swadi, Kedar
and Taha, Walid",
editor="Gl{\"u}ck, Robert
and Lowry, Michael",
title="Implicitly Heterogeneous Multi-stage Programming",
booktitle="Generative Programming and Component Engineering",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="275--292",
abstract="Previous work on semantics-based multi-stage programming (MSP) language design focused on homogeneous designs, where the generating and the generated languages are the same. Homogeneous designs simply add a hygienic quasi-quotation and evaluation mechanism to a base language. An apparent disadvantage of this approach is that the programmer is bound to both the expressivity and performance characteristics of the base language. This paper proposes a practical means to avoid this by providing specialized translations from subsets of the base language to different target languages. This approach preserves the homogeneous ``look'' of multi-stage programs, and, more importantly, the static guarantees about the generated code. In addition, compared to an explicitly heterogeneous approach, it promotes reuse of generator source code and systematic exploration of the performance characteristics of the target languages.",
isbn="978-3-540-31977-1"
}


@InProceedings{10.1007/11844297_10,
author="Shapiro, Jonathan L.",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="Diversity Loss in General Estimation of Distribution Algorithms",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="92--101",
abstract="A very general class of EDAs is defined, on which universal results on the rate of diversity loss can be derived. This EDA class, denoted SML-EDA, requires two restrictions: 1) in each generation, the new probability model is build using only data sampled from the current probability model; and 2) maximum likelihood is used to set model parameters. This class is very general; it includes simple forms of many well-known EDAs, e.g. BOA, MIMIC, FDA, UMDA, etc. To study the diversity loss in SML-EDAs, the trace of the empirical covariance matrix is the proposed statistic. Two simple results are derived. Let N be the number of data vectors evaluated in each generation. It is shown that on a flat landscape, the expected value of the statistic decreases by a factor 1--1/N in each generation. This result is used to show that for the Needle problem, the algorithm will with a high probability never find the optimum unless the population size grows exponentially in the number of search variables.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-662-02933-6_2,
author="Foster, Harold D.",
editor="Wise, John A.
and Hopkin, V. David
and Stager, Paul",
title="Resilience Theory and System Evaluation",
booktitle="Verification and Validation of Complex Systems: Human Factors Issues",
year="1993",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="35--60",
abstract="King Ozymandias clearly failed to appreciate that, in a changing world, it is very difficult to achieve even a semblance of permanence. Despite the virtual impossibility of accurately predicting the future, every decision --- for example, whether to manufacture a new technology, open or close a school, hospital, or mine --- implies a vision of futurity. Either implicitly or explicitly, those involved are making assumptions about such variables as social values, population growth, energy demand, prices, environmental stability, competing innovations, and political trends. None of these factors are fixed. If the past is modeled by a single straight line, then the present can be considered a dot at one end. Beyond this lies the future, not one but a multiplicity of possible alternative lines.",
isbn="978-3-662-02933-6"
}


@InProceedings{10.1007/978-3-642-33167-1_4,
author="Birgisson, Arnar
and Hedin, Daniel
and Sabelfeld, Andrei",
editor="Foresti, Sara
and Yung, Moti
and Martinelli, Fabio",
title="Boosting the Permissiveness of Dynamic Information-Flow Tracking by Testing",
booktitle="Computer Security -- ESORICS 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="55--72",
abstract="Tracking information flow in dynamic languages remains an open challenge. It might seem natural to address the challenge by runtime monitoring. However, there are well-known fundamental limits of dynamic flow-sensitive tracking of information flow, where paths not taken in a given execution contribute to information leaks. This paper shows how to overcome the permissiveness limit for dynamic analysis by a novel use of testing. We start with a program supervised by an information-flow monitor. The security of the execution is guaranteed by the monitor. Testing boosts the permissiveness of the monitor by discovering paths where the monitor raises security exceptions. Upon discovering a security error, the program is modified by injecting an annotation that prevents the same security exception on the next run of the program. The elegance of the approach is that it is sound no matter how much coverage is provided by the testing. Further, we show that when the mechanism has discovered the necessary annotations, then we have an accuracy guarantee: the results of monitoring a program are at least as accurate as flow-sensitive static analysis. We illustrate our approach for a simple imperative language with records and exceptions. Our experiments with the QuickCheck tool indicate that random testing accurately discovers annotations for a collection of scenarios with rich information flows.",
isbn="978-3-642-33167-1"
}


@InProceedings{10.1007/978-3-319-21365-1_34,
author="Potapov, Alexey
and Batishcheva, Vita
and Rodionov, Sergey",
editor="Bieger, Jordi
and Goertzel, Ben
and Potapov, Alexey",
title="Optimization Framework with Minimum Description Length Principle for Probabilistic Programming",
booktitle="Artificial General Intelligence",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="331--340",
abstract="Application of the Minimum Description Length principle to optimization queries in probabilistic programming was investigated on the example of the C++ probabilistic programming library under development. It was shown that incorporation of this criterion is essential for optimization queries to behave similarly to more common queries performing sampling in accordance with posterior distributions and automatically implementing the Bayesian Occam's razor. Experimental validation was conducted on the task of blood cell detection on microscopic images. Detection appeared to be possible using genetic programming query, and automatic penalization of candidate solution complexity allowed to choose the number of cells correctly avoiding overfitting.",
isbn="978-3-319-21365-1"
}


@InProceedings{10.1007/978-3-642-33296-8_7,
author="Carvalho, Gustavo
and Falc{\~a}o, Diogo
and Mota, Alexandre
and Sampaio, Augusto",
editor="Gheyi, Rohit
and Naumann, David",
title="A Process Algebra Based Strategy for Generating Test Vectors from SCR Specifications",
booktitle="Formal Methods: Foundations and Applications",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="67--82",
abstract="SCR is a formal requirements language and method designed to detect and correct errors during the requirements phase. In this paper we start with an SCR specification, translate it into a CSP model (particularly the CSP{\#} variant) and then apply LTL model checking on the CSP{\#} specification to generate test vectors as counter-examples. Before the actual test vector generation, our strategy supports the verification of properties like completeness and determinism of the model; this is one of the advantages of using a process algebra for an intermediate model representation. Our strategy has been assessed by considering typical system requirements of the Aviation Industry. We compared the test vectors generated by our strategy with test vectors written manually by specialists. With respect to the examples used, our strategy has proven to be feasible and was able to generate the same test vectors.",
isbn="978-3-642-33296-8"
}


@InProceedings{10.1007/11693017_29,
author="Ramanathan, Murali Krishna
and Jagannathan, Suresh
and Grama, Ananth",
editor="Baresi, Luciano
and Heckel, Reiko",
title="Trace-Based Memory Aliasing Across Program Versions",
booktitle="Fundamental Approaches to Software Engineering",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="381--395",
abstract="One of the major costs of software development is associated with testing and validation of successive versions of software systems. An important problem encountered in testing and validation is memory aliasing, which involves correlation of variables across program versions. This is useful to ensure that existing invariants are preserved in newer versions and to match program execution histories. Recent work in this area has focused on trace-based techniques to better isolate affected regions. A variation of this general approach considers memory operations to generate more refined impact sets. The utility of such an approach eventually relies on the ability to effectively recognize aliases.",
isbn="978-3-540-33094-3"
}


@InProceedings{10.1007/978-3-642-14052-5_5,
author="Huffman, Brian
and Urban, Christian",
editor="Kaufmann, Matt
and Paulson, Lawrence C.",
title="A New Foundation for Nominal Isabelle",
booktitle="Interactive Theorem Proving",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="35--50",
abstract="Pitts et al introduced a beautiful theory about names and binding based on the notions of permutation and support. The engineering challenge is to smoothly adapt this theory to a theorem prover environment, in our case Isabelle/HOL. We present a formalisation of this work that differs from our earlier approach in two important respects: First, instead of representing permutations as lists of pairs of atoms, we now use a more abstract representation based on functions. Second, whereas the earlier work modeled different sorts of atoms using different types, we now introduce a unified atom type that includes all sorts of atoms. Interestingly, we allow swappings, that is permutations build from two atoms, to be ill-sorted. As a result of these design changes, we can iron out inconveniences for the user, considerably simplify proofs and also drastically reduce the amount of custom ML-code. Furthermore we can extend the capabilities of Nominal Isabelle to deal with variables that carry additional information. We end up with a pleasing and formalised theory of permutations and support, on which we can build an improved and more powerful version of Nominal Isabelle.",
isbn="978-3-642-14052-5"
}


@InProceedings{10.1007/978-3-540-40018-9_4,
author="Gadducci, Fabio",
editor="Ohori, Atsushi",
title="Term Graph Rewriting for the $\pi$-Calculus",
booktitle="Programming Languages and Systems",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="37--54",
abstract="We propose a graphical implementation for (possibly) recursive processes of the $\pi$-calculus, encoding each process into a term graph. Our implementation is sound and complete with respect to the standard structural congruence for the calculus: Two processes are equivalent if and only if they are mapped into isomorphic term graphs. Most importantly, the encoding allows for using standard graph rewriting mechanisms in modelling the reduction semantics of the calculus.",
isbn="978-3-540-40018-9"
}


@InProceedings{10.1007/978-3-319-47958-3_15,
author="Kiselyov, Oleg
and Kameyama, Yukiyoshi
and Sudo, Yuto",
editor="Igarashi, Atsushi",
title="Refined Environment Classifiers",
booktitle="Programming Languages and Systems",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="271--291",
abstract="Generating high-performance code and applying typical optimizations within the bodies of loops and functions involves moving or storing open code for later use, often in a different binding environment. There are ample opportunities for variables being left unbound or accidentally captured. It has been a tough challenge to statically ensure that by construction the generated code is nevertheless well-typed and well-scoped: all free variables in manipulated and stored code fragments shall eventually be bound, by their intended binders.",
isbn="978-3-319-47958-3"
}


@InProceedings{10.1007/978-3-540-68237-0_15,
author="Chetali, Boutheina
and Nguyen, Quang-Huy",
editor="Cuellar, Jorge
and Maibaum, Tom
and Sere, Kaisa",
title="Industrial Use of Formal Methods for a High-Level Security Evaluation",
booktitle="FM 2008: Formal Methods",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="198--213",
abstract="This paper presents an effective use of formal methods for the development and for the security certification of smart card software. The approach is based on the Common Criteria's methodology that requires the use of formal methods to prove that a product implements the claimed security level. This work led to the world-first certification of a commercial Java CardTMproduct involving all formal assurances needed to reach the highest security level. For this certification, formal methods have been used for the design and the implementation of the security functions of the Java Card system embedded in the product. We describe the refinement scheme used to meet the Common Criteria's requirements on formal models and proofs. In particular, we show how to build the proof that the implementation ensures the security objectives claimed in the security specification. We also provide some lessons learned from this important application of formal methods to the smart cards industry.",
isbn="978-3-540-68237-0"
}


@Inbook{André2010,
author="Andr{\'e}, Fran{\c{c}}oise
and Brandic, Ivona
and Daubert, Erwan
and Gauvrit, Guillaume
and Giordano, Maurizio
and Kecskemeti, Gabor
and Kert{\'e}sz, Attila
and Di Napoli, Claudia
and Nemeth, Zsolt
and Pazat, Jean-Louis
and Psaier, Harald
and Renz, Wolfgang
and Sudeikat, Jan",
editor="Papazoglou, Mike P.
and Pohl, Klaus
and Parkin, Michael
and Metzger, Andreas",
title="Architectures {\&} Infrastructure",
bookTitle="Service Research Challenges and Solutions for the Future Internet: S-Cube -- Towards Engineering, Managing and Adapting Service-Based Systems",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="85--116",
abstract="The third of the S-Cube technology layers provides infrastructure capabilities for defining basic communication patterns and interactions involving as well as providing facilities for providing, for example, contextual and qualitative information about a service's and their client's environment and performance. Providing these capabilities to other layers allows service developers to use contextual information when building service based systems and provide cross layer and pro-active monitoring and adaptation of services (see research challenges). This chapter provides an overview of service infrastructures for the adaptation, monitoring and management of services which will provide these functions and concludes with a discussion of more detailed research challenges in the context of service infrastructures and their management.",
isbn="978-3-642-17599-2",
doi="10.1007/978-3-642-17599-2_4",
url="https://doi.org/10.1007/978-3-642-17599-2_4"
}


@Inbook{Jackson2003,
author="Jackson, Daniel",
editor="McIver, Annabelle
and Morgan, Carroll",
title="Object models as heap invariants",
bookTitle="Programming Methodology",
year="2003",
publisher="Springer New York",
address="New York, NY",
pages="247--268",
abstract="Object models are widely used for describing structural properties of object-oriented programs, but they suffer from two problems. First, their semantics is usually unclear. Second, the textual constraints that are often used to annotate diagrams are not integrated with the diagrammatic notation itself. In this paper, we show how to interpret an object model as a heap invariant by translation to a small relational logic. With a few additional shorthands, this logic can be used for textual constraints, so that annotation is just conjunction. Our semantics is simpler than those proposed by others, and accounts for features of the object model that have not been addressed in treatments that focus on more abstract models.",
isbn="978-0-387-21798-7",
doi="10.1007/978-0-387-21798-7_12",
url="https://doi.org/10.1007/978-0-387-21798-7_12"
}


@InProceedings{10.1007/978-3-540-87873-5_10,
author="Weide, Bruce W.
and Sitaraman, Murali
and Harton, Heather K.
and Adcock, Bruce
and Bucci, Paolo
and Bronish, Derek
and Heym, Wayne D.
and Kirschenbaum, Jason
and Frazier, David",
editor="Shankar, Natarajan
and Woodcock, Jim",
title="Incremental Benchmarks for Software Verification Tools and Techniques",
booktitle="Verified Software: Theories, Tools, Experiments",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="84--98",
abstract="This paper proposes an initial catalog of easy-to-state, relatively simple, and incrementally more and more challenging benchmark problems for the Verified Software Initiative. These benchmarks support assessment of verification tools and techniques to prove total correctness of functionality of sequential object-based and object-oriented software. The problems are designed to help evaluate the state-of-the-art and the pace of progress toward verified software in the near term, and in this sense, they are just the beginning. They will allow researchers to illustrate and explain how proposed tools and techniques deal with known pitfalls and well-understood issues, as well as how they can be used to discover and attack new ones. Unlike currently available benchmarks based on ``real-world'' software systems, the proposed challenge problems are expected to be amenable to ``push-button'' verification that leverages current technology.",
isbn="978-3-540-87873-5"
}


@Inbook{Müller2008,
author="M{\"u}ller, Mark
and Pfahl, Dietmar",
editor="Shull, Forrest
and Singer, Janice
and Sj{\o}berg, Dag I. K.",
title="Simulation Methods",
bookTitle="Guide to Advanced Empirical Software Engineering",
year="2008",
publisher="Springer London",
address="London",
pages="117--152",
abstract="This chapter aims to raise awareness about the usefulness and importance of simulation in support of software engineering. Simulation is applied in many critical engineering areas and enables one to address issues before they become problems. Simulation -- in particular process simulation -- is a state of the art technology to analyze process behaviour, risks and complex systems with their inherent uncertainties. Simulation provides insights into the designs of development processes and projects before significant time and cost has been invested, and can be of great benefit in support of training. The systematic combination of simulation methods with empirical research has the potential for becoming a powerful tool in applied software engineering research. The creation of virtual software engineering laboratories helps to allocate available resources of both industry and academia more effectively.",
isbn="978-1-84800-044-5",
doi="10.1007/978-1-84800-044-5_5",
url="https://doi.org/10.1007/978-1-84800-044-5_5"
}


@InProceedings{10.1007/978-3-319-45279-1_5,
author="Firsov, Denis
and Jeltsch, Wolfgang",
editor="Castor, Fernando
and Liu, Yu David",
title="Purely Functional Incremental Computing",
booktitle="Programming Languages",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="62--77",
abstract="Many applications have to maintain evolving data sources as well as views on these sources. If sources change, the corresponding views have to be adapted. Complete recomputation of views is typically too expensive. An alternative is to convert source changes into view changes and apply these to the views. This is the key idea of incremental computing. In this paper, we use Haskell to develop an incremental computing framework. We illustrate the concepts behind this framework by implementing several example computations on sequences. Our framework allows the user to implement incremental computations using arbitrary monad families that encapsulate mutable state. This makes it possible to use highly efficient algorithms for core computations.",
isbn="978-3-319-45279-1"
}


@Article{Jacobs2015,
author="Jacobs, Bart
and Smans, Jan
and Piessens, Frank",
title="Solving the VerifyThis 2012 challenges with VeriFast",
journal="International Journal on Software Tools for Technology Transfer",
year="2015",
month="Nov",
day="01",
volume="17",
number="6",
pages="659--676",
abstract="We describe our experience solving the VerifyThis 2012 challenges with our program verification tool VeriFast, including detailed explanations of our solutions. We also describe some alternative solutions that we developed after the competition. VeriFast is a modular verifier that takes Java or C source code annotated with function/method specifications written in a variant of separation logic, and verifies that the code complies with the annotations through symbolic execution.",
issn="1433-2787",
doi="10.1007/s10009-014-0310-9",
url="https://doi.org/10.1007/s10009-014-0310-9"
}


@InProceedings{10.1007/978-3-642-23881-9_28,
author="Gao, Ying
and Hu, Xiao
and Liu, Huiliang
and Li, Fufang
and Peng, Lingxi",
editor="Deng, Hepu
and Miao, Duoqian
and Lei, Jingsheng
and Wang, Fu Lee",
title="Opposition-Based Learning Estimation of Distribution Algorithm with Gaussian Copulas and Its Application to Placement of RFID Readers",
booktitle="Artificial Intelligence and Computational Intelligence",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="219--227",
abstract="Estimation of distribution algorithms are a class of optimization algorithms based on probability distribution model. In this paper, we propose an improved estimation of distribution algorithm using opposition-based learning and Gaussian copulas. The improved algorithm employs multivariate Gaussian copulas to construct probability distribution model and uses opposition-based learning for population initialization and new population generation. By estimating Kendall's tau and using the relationship of Kendall's tau and correlation matrix, Gaussian copula parameters are firstly estimated, thus, joint distribution is estimated. Afterwards, the Monte Carte simulation is used to generate new individuals. Then, the opposite numbers have also been utilized to improve the convergence performances. The improved algorithm is applied to some benchmark functions and optimal placement of readers in RFID networks. The relative experimental results show that the improved algorithm has better performance than original version of estimation of distribution algorithm and is effective in the optimal placement of readers in RFID networks.",
isbn="978-3-642-23881-9"
}


@Inbook{George2007,
author="George, Chris",
editor="George, Chris W.
and Liu, Zhiming
and Woodcock, Jim",
title="Applicative Modelling with RAISE",
bookTitle="Domain Modeling and the Duration Calculus: International Training School, Shanghai, China, September 17-21. 2007, Advanced Lectures",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="51--118",
abstract="In this chapter we provide an introduction to the RAISE Specification Language and to the RAISE method. We concentrate on the applicative style of RAISE, the style most commonly used initially in development.",
isbn="978-3-540-74964-6",
doi="10.1007/978-3-540-74964-6_2",
url="https://doi.org/10.1007/978-3-540-74964-6_2"
}


@InProceedings{10.1007/978-3-642-33666-9_29,
author="Gonz{\'a}lez, Carlos A.
and Cabot, Jordi",
editor="France, Robert B.
and Kazmeier, J{\"u}rgen
and Breu, Ruth
and Atkinson, Colin",
title="ATLTest: A White-Box Test Generation Approach for ATL Transformations",
booktitle="Model Driven Engineering Languages and Systems",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="449--464",
abstract="MDE is being applied to the development of increasingly complex systems that require larger model transformations. Given that the specification of such transformations is an error-prone task, techniques to guarantee their quality must be provided. Testing is a well-known technique for finding errors in programs. In this sense, adoption of testing techniques in the model transformation domain would be helpful to improve their quality. So far, testing of model transformations has focused on black-box testing techniques. Instead, in this paper we provide a white-box test model generation approach for ATL model transformations.",
isbn="978-3-642-33666-9"
}


@InProceedings{10.1007/978-3-642-31075-1_36,
author="Blecic, Ivan
and Cecchini, Arnaldo
and Trunfio, Giuseppe A.",
editor="Murgante, Beniamino
and Gervasi, Osvaldo
and Misra, Sanjay
and Nedjah, Nadia
and Rocha, Ana Maria A. C.
and Taniar, David
and Apduhan, Bernady O.",
title="Selection and Scheduling Problem in Continuous Time with Pairwise-Interdependencies",
booktitle="Computational Science and Its Applications -- ICCSA 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="481--491",
abstract="We propose a general framework for modelling selection-and-scheduling problem with interdependencies in continuous time. Such problem may frequently arise in many real-world evaluation and decision-making contexts, such as project portfolio selection and scheduling in organisations, urban planning, and scheduling of public policies. For the purpose of conducting computational experiments, we further formulate a specific example model to optimise, whose benefit is to require a relatively limited number of input data. Given the NP-hardness of the problem, we employ the Covariance Matrix Adaptation Evolutionary strategy for solving it, and discuss few results.",
isbn="978-3-642-31075-1"
}


@Article{Raffelt2009,
author="Raffelt, Harald
and Steffen, Bernhard
and Berg, Therese
and Margaria, Tiziana",
title="LearnLib: a framework for extrapolating behavioral models",
journal="International Journal on Software Tools for Technology Transfer",
year="2009",
month="Apr",
day="10",
volume="11",
number="5",
pages="393",
abstract="In this paper, we present the LearnLib, a library of tools for automata learning, which is explicitly designed for the systematic experimental analysis of the profile of available learning algorithms and corresponding optimizations. Its modular structure allows users to configure their own tailored learning scenarios, which exploit specific properties of their envisioned applications. As has been shown earlier, exploiting application-specific structural features enables optimizations that may lead to performance gains of several orders of magnitude, a necessary precondition to make automata learning applicable to realistic scenarios.",
issn="1433-2787",
doi="10.1007/s10009-009-0111-8",
url="https://doi.org/10.1007/s10009-009-0111-8"
}


@InProceedings{10.1007/978-3-642-11319-2_27,
author="Yessenov, Kuat
and Piskac, Ruzica
and Kuncak, Viktor",
editor="Barthe, Gilles
and Hermenegildo, Manuel",
title="Collections, Cardinalities, and Relations",
booktitle="Verification, Model Checking, and Abstract Interpretation",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="380--395",
abstract="Logics that involve collections (sets, multisets), and cardinality constraints are useful for reasoning about unbounded data structures and concurrent processes. To make such logics more useful in verification this paper extends them with the ability to compute direct and inverse relation and function images. We establish decidability and complexity bounds for the extended logics.",
isbn="978-3-642-11319-2"
}


@Article{Ehrig2009,
author="Ehrig, Karsten
and K{\"u}ster, Jochen Malte
and Taentzer, Gabriele",
title="Generating instance models from meta models",
journal="Software {\&} Systems Modeling",
year="2009",
month="Sep",
day="01",
volume="8",
number="4",
pages="479--500",
abstract="Meta modeling is a wide-spread technique to define visual languages, with the UML being the most prominent one. Despite several advantages of meta modeling such as ease of use, the meta modeling approach has one disadvantage: it is not constructive, i.e., it does not offer a direct means of generating instances of the language. This disadvantage poses a severe limitation for certain applications. For example, when developing model transformations, it is desirable to have enough valid instance models available for large-scale testing. Producing such a large set by hand is tedious. In the related problem of compiler testing, a string grammar together with a simple generation algorithm is typically used to produce words of the language automatically. In this paper, we introduce instance-generating graph grammars for creating instances of meta models, thereby overcoming the main deficit of the meta modeling approach for defining languages.",
issn="1619-1374",
doi="10.1007/s10270-008-0095-y",
url="https://doi.org/10.1007/s10270-008-0095-y"
}


@InProceedings{10.1007/978-3-642-33119-0_1,
author="Deb, Kalyanmoy",
editor="Fraser, Gordon
and Teixeira de Souza, Jerffeson",
title="Advances in Evolutionary Multi-objective Optimization",
booktitle="Search Based Software Engineering",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--26",
abstract="Started during 1993-95 with three different algorithms, evolutionary multi-objective optimization (EMO) has come a long way in a quick time to establish itself as a useful field of research and application. Till to date, there exist numerous textbooks and edited books, commercial softwares dedicated to EMO algorithms, freely downloadable codes in most-used computer languages, a biannual conference series (called EMO conference series) running successfully since 2001, and special sessions and workshops held in almost all major evolutionary computing conferences. In this paper, we discuss briefly the principles of EMO through an illustration of one specific algorithm.Thereafter, we focus on mentioning a few recent research and application developments of EMO. Specifically, we discuss EMO's use with multiple criterion decision making (MCDM) procedures and EMO's applicability in handling of a large number of objectives. Besides, the concept of multi-objectivization and innovization -- which are practically motivated, is discussed next. A few other key advancements are also highlighted. The development and application of EMO to multi-objective optimization problems and their continued extensions to solve other related problems have elevated the EMO research to a level which may now undoubtedly be termed as an active field of research with a wide range of theoretical and practical research and application opportunities. EMO concepts are ready to be applied to search based software engineering (SBSE) problems.",
isbn="978-3-642-33119-0"
}


@Inbook{Gärdenfors2012,
author="G{\"a}rdenfors, Peter",
editor="van Eijck, Jan
and Verbrugge, Rineke",
title="The Cognitive and Communicative Demands of Cooperation",
bookTitle="Games, Actions and Social Software: Multidisciplinary Aspects",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="164--183",
abstract="I argue that the analysis of different kinds of cooperation will benefit from an account of the cognitive and communicative functions required for that cooperation. I review different models of cooperation in game theory---reciprocal altruism, indirect reciprocity, cooperation about future goals, and conventions---with respect to their cognitive and communicative prerequisites. The cognitive factors considered include recognition of individuals, memory capacity, temporal discounting, prospective cognition, and theory of mind. Whereas many forms of cooperation require no communication or just simple communication, more advanced forms that are unique to humans presuppose full symbolic communication.",
isbn="978-3-642-29326-9",
doi="10.1007/978-3-642-29326-9_9",
url="https://doi.org/10.1007/978-3-642-29326-9_9"
}


@InProceedings{10.1007/978-3-540-68982-9_1,
author="Fiems, Dieter
and Inghelbrecht, Veronique
and Steyaert, Bart
and Bruneel, Herwig",
editor="Al-Begain, Khalid
and Heindl, Armin
and Telek, Mikl{\'o}s",
title="Markovian Characterisation of H.264/SVC Scalable Video",
booktitle="Analytical and Stochastic Modeling Techniques and Applications",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--15",
abstract="In this paper, a multivariate Markovian traffic model is proposed to characterise H.264/SVC scalable video traces. Parametrisation by a genetic algorithm results in models with a limited state space which accurately capture both the temporal and the inter-layer correlation of the traces. A simulation study further shows that the model is capable of predicting performance of video streaming in various networking scenarios.",
isbn="978-3-540-68982-9"
}


@InProceedings{10.1007/11504894_88,
author="Blecic, Ivan
and Cecchini, Arnaldo
and Trunfio, Giuseppe A.",
editor="Ali, Moonis
and Esposito, Floriana",
title="A Decision Support Tool Coupling a Causal Model and a Multi-objective Genetic Algorithm",
booktitle="Innovations in Applied Artificial Intelligence",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="628--637",
abstract="The knowledge-driven causal models, implementing some inferential techniques, can prove useful in the assessment of effects of actions in contexts with complex probabilistic chains. Such exploratory tools can thus help in ``forevisioning'' of future scenarios, but frequently the inverse analysis is required, that is to say, given a desirable future scenario, to discover the ``best'' set of actions. This paper explores a case of such ``future-retrovisioning'', coupling a causal model with a multi-objective genetic algorithm. We show how a genetic algorithm is able to solve the strategy-selection problem, assisting the decision-maker in choosing an adequate strategy within the possibilities offered by the decision space. The paper outlines the general framework underlying an effective knowledge-based decision support system engineered as a software tool.",
isbn="978-3-540-31893-4"
}


@InProceedings{10.1007/978-3-642-31500-8_55,
author="D'Ambrosio, Donato
and Rongo, Rocco
and Spataro, William
and Trunfio, Giuseppe A.",
editor="Wyrzykowski, Roman
and Dongarra, Jack
and Karczewski, Konrad
and Wa{\'{s}}niewski, Jerzy",
title="Meta-model Assisted Evolutionary Optimization of Cellular Automata: An Application to the SCIARA Model",
booktitle="Parallel Processing and Applied Mathematics",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="533--542",
abstract="The automatic optimization of Cellular Automata (CA) models often requires a large number of time-consuming simulations before an acceptable solution can be found. As a result, CA optimization processes may involve significant computational resources. In this paper we investigate the possibility of speeding up a CA calibration through the approach of meta-model assisted search, which is widely used in many fields. The adopted technique relies on inexpensive surrogate functions able to approximate the fitness corresponding to the CA simulations. The calibration exercise presented here refers to SCIARA, a CA for the simulation of lava flows. According to the preliminary results, the use of meta-models enables to achieve a significant gain in computational time.",
isbn="978-3-642-31500-8"
}


@Article{Bodik2013,
author="Bodik, Rastislav
and Jobstmann, Barbara",
title="Algorithmic program synthesis: introduction",
journal="International Journal on Software Tools for Technology Transfer",
year="2013",
month="Oct",
day="01",
volume="15",
number="5",
pages="397--411",
abstract="Program synthesis is a process of producing an executable program from a specification. Algorithmic synthesis produces the program automatically, without an intervention from an expert. While classical compilation falls under the definition of algorithmic program synthesis, with the source program being the specification, the synthesis literature is typically concerned with producing programs that cannot be (easily) obtained with the deterministic transformations of a compiler. To this end, synthesis algorithms often perform a search, either in a space of candidate programs or in a space of transformations that might be composed to transform the specification into a desired program. In this introduction to the special journal issue, we survey the history of algorithmic program synthesis and introduce the contributed articles. We divide the field into reactive synthesis, which is concerned with automata-theoretic techniques for controllers that handle an infinite stream of requests, and functional synthesis, which produces programs consuming finite input. Contributed articles are divided analogously. We also provide pointers to synthesis work outside these categories and list many applications of synthesis.",
issn="1433-2787",
doi="10.1007/s10009-013-0287-9",
url="https://doi.org/10.1007/s10009-013-0287-9"
}


@InProceedings{10.1007/978-3-642-28717-6_5,
author="Accattoli, Beniamino
and Kesner, Delia",
editor="Bj{\o}rner, Nikolaj
and Voronkov, Andrei",
title="The Permutative $\lambda$-Calculus",
booktitle="Logic for Programming, Artificial Intelligence, and Reasoning",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="23--36",
abstract="We introduce the permutative $\lambda$-calculus, an extension of $\lambda$-calculus with three equations and one reduction rule for permuting constructors, generalising many calculi in the literature, in particular Regnier's sigma-equivalence and Moggi's assoc-equivalence. We prove confluence modulo the equations and preservation of beta-strong normalisation (PSN) by means of an auxiliary substitution calculus. The proof of confluence relies on M-developments, a new notion of development for $\lambda$-terms.",
isbn="978-3-642-28717-6"
}


@InProceedings{10.1007/978-3-642-04921-7_24,
author="Ferariu, Lavinia
and Patelli, Alina",
editor="Kolehmainen, Mikko
and Toivanen, Pekka
and Beliczynski, Bartlomiej",
title="Multiobjective Genetic Programming for Nonlinear System Identification",
booktitle="Adaptive and Natural Computing Algorithms",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="233--242",
abstract="The paper presents a novel identification method, which makes use of genetic programming for concomitant flexible selection of models structure and parameters. The case of nonlinear models, linear in parameters is addressed. To increase the convergence speed, the proposed algorithm considers customized genetic operators and a local optimization procedure, based on QR decomposition, able to efficiently exploit the linearity of the model subject to its parameters. Both the model accuracy and parsimony are improved via a multiobjective optimization, considering different priority levels for the involved objectives. An enhanced Pareto loop is implemented, by means of a special fitness assignment technique and a migration mechanism, in order to evolve accurate and compact representations of dynamic nonlinear systems. The experimental results reveal the benefits of the proposed methodology within the framework of an industrial system identification.",
isbn="978-3-642-04921-7"
}


@InProceedings{10.1007/3-540-45484-5_22,
author="Gordon, Diana F.",
editor="Rash, James L.
and Truszkowski, Walt
and Hinchey, Michael G.
and Rouff, Christopher A.
and Gordon, Diana",
title="APT Agents: Agents That Are Adaptive Predictable and Timely",
booktitle="Formal Approaches to Agent-Based Systems",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="278--293",
abstract="The increased prevalence of agents raises numerous practical considerations. This paper addresses three of these - adaptability to unforeseen conditions, behavioral assurance, and timeliness of agent responses. Although these requirements appear contradictory, this paper introduces a paradigm in which all three are simultaneously satisfied. Agent strategies are initially verified. Then they are adapted by learning and formally reverified for behavioral assurance. This paper focuses on improving the time efficiency of reverification after learning. A priori proofs are presented that certain learning operators are guaranteed to preserve important classes of properties. In this case, efficiency is maximal because no reverification is needed. For those learning operators with negative a priori results, we present incremental algorithms that can substantially improve the efficiency of reverification.",
isbn="978-3-540-45484-7"
}


@InProceedings{10.1007/11779568_116,
author="Srikasam, Wasan
and Chaiyaratana, Nachol
and Kuntanapreeda, Suwat",
editor="Ali, Moonis
and Dapoigny, Richard",
title="Nonlinear Discrete System Stabilisation by an Evolutionary Neural Network",
booktitle="Advances in Applied Artificial Intelligence",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1090--1099",
abstract="This paper presents the application of an evolutionary neural network controller in a stabilisation problem involving an inverted pendulum. It is guaranteed that the resulting closed-loop discrete system is asymptotically stable. The process of training the neural network controller can be treated as a constrained optimisation problem where the equality constraint is derived from the Lyapunov stability criteria. The decision variables in this investigation are made up from the connection weights in the neural network, a positive definite matrix required for the Lyapunov function and matrices for the stability constraint while the objective value is calculated from the closed-loop system performance. The optimisation technique chosen for the task is a variant of genetic algorithms called a cooperative coevolutionary genetic algorithm (CCGA). Two control strategies are explored: model-reference control and optimal control. In the model-reference control, the simulation results indicate that the tracking performance of the system stabilised by the evolutionary neural network is superior to that controlled by a neural network, which is trained via a neural network emulator. In addition, the system stabilised by the evolutionary neural network requires the energy in the level which is comparable to that found in the system that uses a linear quadratic regulator in optimal control. This confirms the usefulness of the CCGA in nonlinear discrete system stabilisation applications.",
isbn="978-3-540-35454-3"
}


@InProceedings{10.1007/11504894_45,
author="Belli, Fevzi
and G{\"u}ldali, Baris",
editor="Ali, Moonis
and Esposito, Floriana",
title="A Holistic Approach to Test-Driven Model Checking",
booktitle="Innovations in Applied Artificial Intelligence",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="321--331",
abstract="Testing is the most common validation method in the soft ware in dustry. It entails the execu tion of the software system in the real envi ron ment. Nevertheless, testing is a cost-in tensive process. Be cause of its conceptual simplicity the combination of formal methods and test methods has been widely advocated. Model checking be longs to the promising candidates for this marriage. The present paper modifies and ex tends the existing approaches in that, after the test case gen eration, a model checking step supports the manual test process. Based on the holistic approach to specifi cation-based construction of test suites, this paper proposes to generate test cases to cover both the specifi cation model and its com ple ment. This helps also to clearly differ enti ate the correct system outputs from the faulty ones as the test cases based on the specifi ca tion are to succeed the test, and the ones based on the complement of the specifica tion are to fail. Thus, the ap proach handles the oracle problem in an effective manner.",
isbn="978-3-540-31893-4"
}


@InProceedings{10.1007/11844297_4,
author="Teytaud, Olivier
and Gelly, Sylvain
and Mary, J{\'e}r{\'e}mie",
editor="Runarsson, Thomas Philip
and Beyer, Hans-Georg
and Burke, Edmund
and Merelo-Guerv{\'o}s, Juan J.
and Whitley, L. Darrell
and Yao, Xin",
title="On the Ultimate Convergence Rates for Isotropic Algorithms and the Best Choices Among Various Forms of Isotropy",
booktitle="Parallel Problem Solving from Nature - PPSN IX",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="32--41",
abstract="In this paper, we show universal lower bounds for isotropic algorithms, that hold for any algorithm such that each new point is the sum of one already visited point plus one random isotropic direction multiplied by any step size (whenever the step size is chosen by an oracle with arbitrarily high computational power). The bound is 1--O(1/d) for the constant in the linear convergence (i.e. the constant C such that the distance to the optimum after n steps is upper bounded by Cn), as already seen for some families of evolution strategies in [19,12], in contrast with 1--O(1) for the reverse case of a random step size and a direction chosen by an oracle with arbitrary high computational power. We then recall that isotropy does not uniquely determine the distribution of a sample on the sphere and show that the convergence rate in isotropic algorithms is improved by using stratified or antithetic isotropy instead of naive isotropy. We show at the end of the paper that beyond the mathematical proof, the result holds on experiments. We conclude that one should use antithetic-isotropy or stratified-isotropy, and never standard-isotropy.",
isbn="978-3-540-38991-0"
}


@InProceedings{10.1007/978-3-642-34691-0_5,
author="Johansen, Martin Fagereng
and Haugen, {\O}ystein
and Fleurey, Franck
and Carlson, Erik
and Endresen, Jan
and Wien, Tormod",
editor="Nielsen, Brian
and Weise, Carsten",
title="A Technique for Agile and Automatic Interaction Testing for Product Lines",
booktitle="Testing Software and Systems",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="39--54",
abstract="Product line developers must ensure that existing and new features work in all products. Adding to or changing a product line might break some of its features. In this paper, we present a technique for automatic and agile interaction testing for product lines. The technique enables developers to know if features work together with other features in a product line, and it blends well into a process of continuous integration. The technique is evaluated with two industrial applications, testing a product line of safety devices and the Eclipse IDEs. The first case shows how existing test suites are applied to the products of a 2-wise covering array to identify two interaction faults. The second case shows how over 400,000 test executions are performed on the products of a 2-wise covering array using over 40,000 existing automatic tests to identify potential interactions faults.",
isbn="978-3-642-34691-0"
}


@InProceedings{10.1007/978-3-642-22306-8_3,
author="Yu, Fang
and Bultan, Tevfik
and Hardekopf, Ben",
editor="Groce, Alex
and Musuvathi, Madanlal",
title="String Abstractions for String Verification",
booktitle="Model Checking Software",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="20--37",
abstract="Verifying string manipulating programs is a crucial problem in computer security. String operations are used extensively within web applications to manipulate user input, and their erroneous use is the most common cause of security vulnerabilities in web applications. Unfortunately, verifying string manipulating programs is an undecidable problem in general and any approximate string analysis technique has an inherent tension between efficiency and precision. In this paper we present a set of sound abstractions for strings and string operations that allow for both efficient and precise verification of string manipulating programs. Particularly, we are able to verify properties that involve implicit relations among string variables. We first describe an abstraction called regular abstraction which enables us to perform string analysis using multi-track automata as a symbolic representation. We then introduce two other abstractions---alphabet abstraction and relation abstraction---that can be used in combination to tune the analysis precision and efficiency. We show that these abstractions form an abstraction lattice that generalizes the string analysis techniques studied previously in isolation, such as size analysis or non-relational string analysis. Finally, we empirically evaluate the effectiveness of these abstraction techniques with respect to several benchmarks and an open source application, demonstrating that our techniques can improve the performance without loss of accuracy of the analysis when a suitable abstraction class is selected.",
isbn="978-3-642-22306-8"
}


@InProceedings{10.1007/978-3-540-87700-4_22,
author="Jiang, Fei
and Berry, Hugues
and Schoenauer, Marc",
editor="Rudolph, G{\"u}nter
and Jansen, Thomas
and Beume, Nicola
and Lucas, Simon
and Poloni, Carlo",
title="Supervised and Evolutionary Learning of Echo State Networks",
booktitle="Parallel Problem Solving from Nature -- PPSN X",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="215--224",
abstract="A possible alternative to topology fine-tuning for Neural Network (NN) optimization is to use Echo State Networks (ESNs), recurrent NNs built upon a large reservoir of sparsely randomly connected neurons. The promises of ESNs have been fulfilled for supervised learning tasks, but unsupervised ones, e.g. control problems, require more flexible optimization methods -- such as Evolutionary Algorithms. This paper proposes to apply CMA-ES, the state-of-the-art method in evolutionary continuous parameter optimization, to the evolutionary learning of ESN parameters. First, a standard supervised learning problem is used to validate the approach and compare it to the standard one. But the flexibility of Evolutionary optimization allows us to optimize not only the outgoing weights but also, or alternatively, other ESN parameters, sometimes leading to improved results. The classical double pole balancing control problem is then used to demonstrate the feasibility of evolutionary (i.e. reinforcement) learning of ESNs. We show that the evolutionary ESN obtain results that are comparable with those of the best topology-learning methods.",
isbn="978-3-540-87700-4"
}


@InProceedings{10.1007/11691372_2,
author="Deshmukh, Jyotirmoy V.
and Emerson, E. Allen
and Gupta, Prateek",
editor="Hermanns, Holger
and Palsberg, Jens",
title="Automatic Verification of Parameterized Data Structures",
booktitle="Tools and Algorithms for the Construction and Analysis of Systems",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="27--41",
abstract="Verifying correctness of programs operating on data structures has become an integral part of software verification. A method is a program that acts on an input data structure (modeled as a graph) and produces an output data structure. The parameterized correctness problem for such methods can be defined as follows: Given a method and a property of the input graphs, we wish to verify that for all input graphs, parameterized by their size, the output graphs also satisfy the property. We present an automated approach to verify that a given method preserves a given property for a large class of methods. Examples include reversals of linked lists, insertion, deletion and iterative modification of nodes in directed graphs. Our approach draws on machinery from automata theory and temporal logic. For a useful class of data structures and properties, our solution is polynomial in the size of the method and size of the property specification.",
isbn="978-3-540-33057-8"
}


@InProceedings{10.1007/978-3-540-69738-1_8,
author="Rakamari{\'{c}}, Zvonimir
and Bingham, Jesse
and Hu, Alan J.",
editor="Cook, Byron
and Podelski, Andreas",
title="An Inference-Rule-Based Decision Procedure for Verification of Heap-Manipulating Programs with Mutable Data and Cyclic Data Structures",
booktitle="Verification, Model Checking, and Abstract Interpretation",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="106--121",
abstract="Research on the automatic verification of heap-manipulating programs (HMPs) --- programs that manipulate unbounded linked data structures via pointers --- has blossomed recently, with many different approaches all showing leaps in performance and expressiveness. A year ago, we proposed a small logic for specifying predicates about HMPs and demonstrated that an inference-rule-based decision procedure could be performance-competitive, and in many cases superior to other methods known at the time. That work, however, was a proof-of-concept, with a logic fragment too small to verify most real programs. In this work, we generalize our previous results to be practically useful: we allow the data in heap nodes to be mutable, we allow more than a single pointer field, and we add new primitives needed to verify cyclic structures. Each of these extensions necessitates new or changed inference rules, with the concomitant changes to the proofs and decision procedure. Yet, our new decision procedure, with the more general logic, actually runs as fast as our previous results. With these generalizations, we can automatically verify many more HMP examples, including three small container functions from the Linux kernel.",
isbn="978-3-540-69738-1"
}


@InProceedings{10.1007/978-3-662-48899-7_42,
author="Fedyukovich, Grigory
and Gurfinkel, Arie
and Sharygina, Natasha",
editor="Davis, Martin
and Fehnker, Ansgar
and McIver, Annabelle
and Voronkov, Andrei",
title="Automated Discovery of Simulation Between Programs",
booktitle="Logic for Programming, Artificial Intelligence, and Reasoning",
year="2015",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="606--621",
abstract="The paper presents SimAbs, the first fully automated SMT-based approach to synthesize an abstraction of one program (called target) that simulates another program (called source). SimAbs iteratively traverses the search space of existential abstractions of the target and choses the strongest abstraction among them that simulates the source. Deciding whether a given relation is a simulation relation is reduced to solving validity of {\$}{\$}{\backslash}forall {\backslash}exists {\$}{\$}-formulas iteratively. We present a novel algorithm for dealing with such formulas using an incremental SMT solver. In addition to deciding validity, our algorithm extracts witnessing Skolem relations which further drive simulation synthesis in SimAbs. Our evaluation confirms that SimAbs is able to efficiently discover both, simulations and abstractions, for C programs from the Software Verification Competition.",
isbn="978-3-662-48899-7"
}


@InProceedings{10.1007/978-3-642-22540-6_44,
author="Tarsauliya, Anupam
and Kala, Rahul
and Tiwari, Ritu
and Shukla, Anupam",
editor="Wyld, David C.
and Wozniak, Michal
and Chaki, Nabendu
and Meghanathan, Natarajan
and Nagamalai, Dhinaharan",
title="Financial Time Series Volatility Forecast Using Evolutionary Hybrid Artificial Neural Network",
booktitle="Advances in Network Security and Applications",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="463--471",
abstract="Financial time series forecast has been classified as standard problem in forecasting due to its high non-linearity and high volatility in data. Statistical methods such as GARCH, GJR, EGARCH and Artificial Neural Networks (ANNs) based on standard learning algorithms such as backpropagation have been widely used for forecasting time series volatility of various fields. In this paper, we propose hybrid model of statistical methods with ANNs. Statistical methods require assumptions about the market, they do not reflect all market variables and they may not capture the non-linearity. Shortcoming of ANNs is their process of identifying inputs insignificantly through which network produces output. The attempt for hybrid system is to outperform the forecast results and overcome the shortcomings by extracting input variables from statistical methods and include them in ANNs learning process. Further genetic algorithm is used for evolution of proposed hybrid models. Experimental results confirm the lesser root mean square error (RMSE) results obtained from proposed evolutionary hybrid ANN models EANN-GARCH, EANN-GJR, EANN-EGARCH than conventional ANNs and statistical methods.",
isbn="978-3-642-22540-6"
}


@InProceedings{10.1007/978-3-540-24730-2_39,
author="Yorsh, G.
and Reps, Thomas
and Sagiv, Mooly",
editor="Jensen, Kurt
and Podelski, Andreas",
title="Symbolically Computing Most-Precise Abstract Operations for Shape Analysis",
booktitle="Tools and Algorithms for the Construction and Analysis of Systems",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="530--545",
abstract="Shape analysis concerns the problem of determining ``shape invariants'' for programs that perform destructive updating on dynamically allocated storage. This paper presents a new algorithm that takes as input an abstract value (a 3-valued logical structure describing some set of concrete stores X) and a precondition p, and computes the most-precise abstract value for the stores in X that satisfy p. This algorithm solves several open problems in shape analysis: (i) computing the most-precise abstract value of a set of concrete stores specified by a logical formula; (ii) computing best transformers for atomic program statements and conditions; (iii) computing best transformers for loop-free code fragments (i.e., blocks of atomic program statements and conditions); (iv) performing interprocedural shape analysis using procedure specifications and assume-guarantee reasoning; and (v) computing the most-precise overapproximation of the meet of two abstract values.",
isbn="978-3-540-24730-2"
}


@InProceedings{10.1007/978-3-319-03871-1_2,
author="Blumenstein, Jiri
and Marsalek, Roman
and Prokes, Ales
and Mecklenbr{\"a}uker, Christoph",
editor="Jonsson, Magnus
and Vinel, Alexey
and Bellalta, Boris
and Marina, Ninoslav
and Dimitrova, Desislava
and Fiems, Dieter",
title="Impulse Noise Mitigation for OFDM by Time-Frequency Spreading",
booktitle="Multiple Access Communcations",
year="2013",
publisher="Springer International Publishing",
address="Cham",
pages="8--20",
abstract="This paper deals with the impulse interferences in modern vehicles and assesses the suitability of establishing in-vehicle wireless links replacing standard data cable bundles. According to our experiments, the standard UMTS Long Term Evolution (LTE) is highly affected by impulse noise. We compare it with a novel 2D signal spreading method exploiting the orthogonal Walsh-Hadamard sequences in order to spread the transmitted signal in time and frequency. This method requires minor modification of the 3GPP LTE standard while no additional bandwidth nor noticeable computational power is required. In the presence of impulse noise, the novel 2D spreading method outperforms the standard compliant LTE significantly.",
isbn="978-3-319-03871-1"
}


@InProceedings{10.1007/978-1-4471-3227-1_16,
author="Berghammer, R.
and Haeberer, A.
and Schmidt, G.
and Veloso, P.",
editor="Nivat, Maurice
and Rattray, Charles
and Rus, Teodor
and Scollo, Giuseppe",
title="Comparing Two Different Approaches to Products in Abstract Relation Algebra",
booktitle="Algebraic Methodology and Software Technology (AMAST'93)",
year="1994",
publisher="Springer London",
address="London",
pages="167--176",
abstract="During the development of relation algebra as a formal programming tool, the need of some form of ``categorical product'' of relations became apparent, whether as a type or as an operation. Two approaches arose in the late 70's and the early 80's which will be referred here as the ``Munich approach'' (see, e.g., [18, 7]) and the ``Rio approach'' (see, e.g., [13, 12, 22]).",
isbn="978-1-4471-3227-1"
}


@InProceedings{10.1007/978-3-642-12104-3_21,
author="Reinecke, Philipp
and Telek, Mikl{\'o}s
and Wolter, Katinka",
editor="M{\"u}ller-Clostermann, Bruno
and Echtle, Klaus
and Rathgeb, Erwin P.",
title="Reducing the Cost of Generating APH-Distributed Random Numbers",
booktitle="Measurement, Modelling, and Evaluation of Computing Systems and Dependability and Fault Tolerance",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="274--286",
abstract="Phase-type (PH) distributions are proven to be very powerful tools in modelling and analysis of a wide range of phenomena in computer systems. The use of these distributions in simulation studies requires efficient methods for generating PH-distributed random numbers. In this work, we discuss algorithms for generating random numbers from PH distributions and propose two algorithms for reducing the cost associated with generating random numbers from Acyclic Phase-Type distributions (APH).",
isbn="978-3-642-12104-3"
}


@Inbook{ref1,
editor="Nagl, Manfred",
title="Realization: Derivation of efficient tools",
bookTitle="Building Tightly Integrated Software Development Environments: The IPSEN Approach",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="379--501",
isbn="978-3-540-49578-9",
doi="10.1007/BFb0035688",
url="https://doi.org/10.1007/BFb0035688"
}


@Inbook{Eusgeld2008,
author="Eusgeld, Irene
and Fechner, Bernhard
and Salfner, Felix
and Walter, Max
and Limbourg, Philipp
and Zhang, Lijun",
editor="Eusgeld, Irene
and Freiling, Felix C.
and Reussner, Ralf",
title="Hardware Reliability",
bookTitle="Dependability Metrics: Advanced Lectures",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="59--103",
abstract="Reliability is an important part of dependability. This chapter aims at supporting readers in the usage of the classical definitions, modelling and measures of (hardware) reliability metrics.",
isbn="978-3-540-68947-8",
doi="10.1007/978-3-540-68947-8_9",
url="https://doi.org/10.1007/978-3-540-68947-8_9"
}


@InProceedings{10.1007/978-3-319-13206-8_17,
author="Kobets, Vitaliy
and Poltoratskiy, Maksim",
editor="Ermolayev, Vadim
and Mayr, Heinrich C.
and Nikitchenko, Mykola
and Spivakovsky, Aleksander
and Zholtkevych, Grygoriy",
title="Forming an Evolutionarily Stable Firm Strategy Under Cournot Competition Using Social Preferences",
booktitle="Information and Communication Technologies in Education, Research, and Industrial Applications",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="343--361",
abstract="The paper investigates what kinds of firms' social preferences (egoists, altruists or punishers) prove to be evolutionarily stable strategies under Cournot competition in the market of homogeneous product. Combining the traditional and evolutionary approaches to competition we define the conditions that forecast the attitude and profit dynamics of competitors under Cournot competition and adaptive behavior of rivals.",
isbn="978-3-319-13206-8"
}


@Inbook{vanderAalst2016,
author="van der Aalst, Wil",
title="Conformance Checking",
bookTitle="Process Mining: Data Science in Action",
year="2016",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="243--274",
abstract="After covering control-flow discovery in depth in Part III, this chapter looks at the situation in which both a process model and an event log are given. The model may have been constructed by hand or may have been discovered. Moreover, the model may be normative or descriptive. Conformance checking relates events in the event log to activities in the process model and compares both. The goal is to find commonalities and discrepancies between the modeled behavior and the observed behavior. Conformance checking is relevant for business alignment and auditing. For example, the event log can be replayed on top of the process model to find undesirable deviations suggesting fraud or inefficiencies. Moreover, conformance checking techniques can also be used for measuring the performance of process discovery algorithms and to repair models that are not aligned well with reality.",
isbn="978-3-662-49851-4",
doi="10.1007/978-3-662-49851-4_8",
url="https://doi.org/10.1007/978-3-662-49851-4_8"
}


@InProceedings{10.1007/11495628_3,
author="Muscholl, Anca
and Peled, Doron",
editor="Leue, Stefan
and Syst{\"a}, Tarja Johanna",
title="Deciding Properties of Message Sequence Charts",
booktitle="Scenarios: Models, Transformations and Tools",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="43--65",
abstract="Message Sequence Charts (MSCs) is a notation used in practice by protocol designers and system engineers. It is defined within an international standard (ITU Z120), and is also included, in a slightly different form, in the popular UML standard (called there sequence diagrams). We present some of the main results related to this notation, in the context of specification and automatic verification of communication protocols. We look at issues related to specification and verification. In particular, we look at automatic verification (model checking) of MSCs. We study the expressiveness of MSCs, in particular the ability to express communication protocols, and appropriate formalisms for specifying properties of MSC systems.",
isbn="978-3-540-32032-6"
}


@Inbook{vanderAalst2011,
author="van der Aalst, Wil M. P.",
title="Conformance Checking",
bookTitle="Process Mining: Discovery, Conformance and Enhancement of Business Processes",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="191--213",
abstract="After covering control-flow discovery in depth in Part II, this chapter looks at the situation in which both a process model and an event log are given. The model may have been constructed by hand or may have been discovered. Moreover, the model may be normative or descriptive. Conformance checking relates events in the event log to activities in the process model and compares both. The goal is to find commonalities and discrepancies between the modeled behavior and the observed behavior. Conformance checking is relevant for business alignment and auditing. For example, the event log can be replayed on top of the process model to find undesirable deviations suggesting fraud or inefficiencies. Moreover, conformance checking techniques can also be used for measuring the performance of process discovery algorithms and to repair models that are not aligned well with reality.",
isbn="978-3-642-19345-3",
doi="10.1007/978-3-642-19345-3_7",
url="https://doi.org/10.1007/978-3-642-19345-3_7"
}


@Inbook{Schwartz1986,
author="Schwartz, J. T.
and Dewar, R. B. K.
and Schonberg, E.
and Dubinsky, E.",
title="Procedures",
bookTitle="Programming with Sets: An Introduction to SETL",
year="1986",
publisher="Springer US",
address="New York, NY",
pages="159--238",
abstract="A procedure in SETL is a sequence of computational steps which have been given a name and which, using one or more data items passed to it for processing, will compute and deliver a value. Most of the built-in SETL operators, for example max, which returns the maximum of two values x and y, and cos, which returns the cosine of a floating-point number x passed to it, are procedures in this sense. However, since no finite collection will ever exhaust the whole catalog of procedures that a programmer may want to use, it is important to have a way of defining, and then using, as many additional operations as are helpful.",
isbn="978-1-4613-9575-1",
doi="10.1007/978-1-4613-9575-1_5",
url="https://doi.org/10.1007/978-1-4613-9575-1_5"
}


@Article{Lu2002,
author="Lu, Ruqian
and Jin, Zhi",
title="Formal ontology: Foundation of domain knowledge sharing and reusing",
journal="Journal of Computer Science and Technology",
year="2002",
month="Sep",
day="01",
volume="17",
number="5",
pages="535--548",
abstract="Domain analysis is the activity of identifying and representing the relevant information in a domain, so that the information can be shared and reused in similar systems. But until now, no efficient approaches are available for capturing and representing the results of domain analysis and then for sharing and reusing the domain knowledge. This paper proposes an ontology-oriented approach for formalizing the domain models. The architecture for the multiple-layer structure of the domain knowledge base is also discussed. And finally, some genetic algorithm-based methods have been given for supporting the knowledge sharing and reusing.",
issn="1860-4749",
doi="10.1007/BF02948822",
url="https://doi.org/10.1007/BF02948822"
}


@Article{Abramov2011,
author="Abramov, S. A.
and Bogolyubskaya, A. A.
and Edneral, V. F.
and Rostovtsev, V. A.",
title="The research seminar on computer algebra in 2009--2010",
journal="Programming and Computer Software",
year="2011",
month="Mar",
day="01",
volume="37",
number="2",
pages="57--61",
abstract="An annual report on meetings of the scientific research seminar on computer algebra is presented.",
issn="1608-3261",
doi="10.1134/S0361768811020010",
url="https://doi.org/10.1134/S0361768811020010"
}


@Inbook{McBride2016,
author="McBride, Conor",
editor="Lindley, Sam
and McBride, Conor
and Trinder, Phil
and Sannella, Don",
title="I Got Plenty o' Nuttin'",
bookTitle="A List of Successes That Can Change the World: Essays Dedicated to Philip Wadler on the Occasion of His 60th Birthday",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="207--233",
abstract="Work to date on combining linear types and dependent types has deliberately and successfully avoided doing so. Entirely fit for their own purposes, such systems wisely insist that types depend only on the replicable sublanguage, thus sidestepping the issue of counting uses of limited-use data either within types or in ways which are only really needed to shut the typechecker up. As a result, the linear implication (`lollipop') stubbornly remains a non-dependent {\$}{\$}S {\backslash}multimap T{\$}{\$}S⊸T. This paper defines and establishes the basic metatheory of a type theory supporting a `dependent lollipop' {\$}{\$}(x{\backslash}!:{\backslash}!S){\backslash}multimap T[x]{\$}{\$}(x:S)⊸T[x], where what the input used to be is in some way commemorated by the type of the output. For example, we might convert list to length-indexed vectors in place by a function with type {\$}{\$}(l{\backslash}!:{\backslash}!{\backslash}mathsf {\{}List{\}}{\backslash},X){\backslash}multimap {\backslash}mathsf {\{}Vector{\}}{\backslash},X{\backslash},({\backslash}mathsf {\{}length{\}}{\backslash},l){\$}{\$}(l:ListX)⊸VectorX(lengthl). Usage is tracked with resource annotations belonging to an arbitrary rig, or `riNg without Negation'. The key insight is to use the rig's zero to mark information in contexts which is present for purposes of contemplation rather than consumption, like a meal we remember fondly but cannot eat twice. We need no runtime copies of l to form the above vector type. We can have plenty of nothing with no additional runtime resource, and nothing is plenty for the construction of dependent types.",
isbn="978-3-319-30936-1",
doi="10.1007/978-3-319-30936-1_12",
url="https://doi.org/10.1007/978-3-319-30936-1_12"
}


